{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Deep Learning for Deciphering Traffic Signs\n",
        "## Fixing Test Data Notebook\n",
        "_________________________________________________________________________________________________________________________________________________________________________________\n",
        "\n",
        "##### Contributors:\n",
        " Victor Floriano, Yifan Fan, Jose Salerno"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Problem Statement & Motivation\n",
        "As the world advances towards autonomous vehicles, our team has observed the remarkable efforts of large car manufacturers, who are working with data scientists to develop fully autonomous cars. Our team is excited to contribute to the development of this technology by creating a neural network model that will be able to classify different traffic signs. Our ultimate goal is to assist car makers in overcoming the challenges they may face in implementing neural network models that effectively read traffic signs and further their efforts toward a fully autonomous car or assisted driving. We believe autonomous driving to be an important problem to solve due to the great economic benefits it can generate for car manufacturers and the improvement of general driving safety.\n",
        "\n",
        "## Data Preparation\n",
        " We've selected the German Traffic Sign Recognition Benchmark (GTSRB) as our primary dataset. It's renowned for its complexity, featuring over 50,000 images across more than 40 classes of traffic signs. The GTSRB is publicly accessible through two resources. To efficiently manage the extensive and complex GTSRB dataset, our strategy integrates preprocessing for uniformity, data augmentation for robustness, and batch processing for computational efficiency. We'll employ distributed computing to parallelize operations, enhancing processing speed, and use stratified sampling for quick experimentation without compromising representativeness.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fixing Test Dataset\n",
        "\n",
        " We encountered an issue where the test images were in one folder, which included 12629 images and needed to be organized into specific class folders like the Training dataset folders. We had the availability of a CSV file with the path location and class label for each test observation. To fix the issue, we iterated over values on the CSV file and created a loop where it would create a new folder directory for each different image and copy them into the correct class folder.\n",
        "________________________________________________________________________________________________________________________________________________\n",
        "\n",
        "Results: \n",
        "    - Created a new test folder that contained 43 class folders for the test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "752SutZ_4Z0M"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "#Image related\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#Time\n",
        "import time\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6DwpIi5h4odm"
      },
      "outputs": [],
      "source": [
        "data = []\n",
        "labels = []\n",
        "\n",
        "#Define total number of classes in the datasets\n",
        "classes = 43\n",
        "\n",
        "#Retrieves the current working directory - to be used later to load the data\n",
        "cur_path = os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EF88WqxM5jR6",
        "outputId": "0a541a29-19a1-4954-f9a6-9e5b5718ee62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AELM_nuKJe1",
        "outputId": "a6bd9325-3a19-43cd-8813-0c2f5744c4a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed 100 images\n",
            "Processed 200 images\n",
            "Processed 300 images\n",
            "Processed 400 images\n",
            "Processed 500 images\n",
            "Processed 600 images\n",
            "Processed 700 images\n",
            "Processed 800 images\n",
            "Processed 900 images\n",
            "Processed 1000 images\n",
            "Processed 1100 images\n",
            "Processed 1200 images\n",
            "Processed 1300 images\n",
            "Processed 1400 images\n",
            "Processed 1500 images\n",
            "Processed 1600 images\n",
            "Processed 1700 images\n",
            "Processed 1800 images\n",
            "Processed 1900 images\n",
            "Processed 2000 images\n",
            "Processed 2100 images\n",
            "Processed 2200 images\n",
            "Processed 2300 images\n",
            "Processed 2400 images\n",
            "Processed 2500 images\n",
            "Processed 2600 images\n",
            "Processed 2700 images\n",
            "Processed 2800 images\n",
            "Processed 2900 images\n",
            "Processed 3000 images\n",
            "Processed 3100 images\n",
            "Processed 3200 images\n",
            "Processed 3300 images\n",
            "Processed 3400 images\n",
            "Processed 3500 images\n",
            "Processed 3600 images\n",
            "Processed 3700 images\n",
            "Processed 3800 images\n",
            "Processed 3900 images\n",
            "Processed 4000 images\n",
            "Processed 4100 images\n",
            "Processed 4200 images\n",
            "Processed 4300 images\n",
            "Processed 4400 images\n",
            "Processed 4500 images\n",
            "Processed 4600 images\n",
            "Processed 4700 images\n",
            "Processed 4800 images\n",
            "Processed 4900 images\n",
            "Processed 5000 images\n",
            "Processed 5100 images\n",
            "Processed 5200 images\n",
            "Processed 5300 images\n",
            "Processed 5400 images\n",
            "Processed 5500 images\n",
            "Processed 5600 images\n",
            "Processed 5700 images\n",
            "Processed 5800 images\n",
            "Processed 5900 images\n",
            "Processed 6000 images\n",
            "Processed 6100 images\n",
            "Processed 6200 images\n",
            "Processed 6300 images\n",
            "Processed 6400 images\n",
            "Processed 6500 images\n",
            "Processed 6600 images\n",
            "Processed 6700 images\n",
            "Processed 6800 images\n",
            "Processed 6900 images\n",
            "Processed 7000 images\n",
            "Processed 7100 images\n",
            "Processed 7200 images\n",
            "Processed 7300 images\n",
            "Processed 7400 images\n",
            "Processed 7500 images\n",
            "Processed 7600 images\n",
            "Processed 7700 images\n",
            "Processed 7800 images\n",
            "Processed 7900 images\n",
            "Processed 8000 images\n",
            "Processed 8100 images\n",
            "Processed 8200 images\n",
            "Processed 8300 images\n",
            "Processed 8400 images\n",
            "Processed 8500 images\n",
            "Processed 8600 images\n",
            "Processed 8700 images\n",
            "Processed 8800 images\n",
            "Processed 8900 images\n",
            "Processed 9000 images\n",
            "Processed 9100 images\n",
            "Processed 9200 images\n",
            "Processed 9300 images\n",
            "Processed 9400 images\n",
            "Processed 9500 images\n",
            "Processed 9600 images\n",
            "Processed 9700 images\n",
            "Processed 9800 images\n",
            "Processed 9900 images\n",
            "Processed 10000 images\n",
            "Processed 10100 images\n",
            "Processed 10200 images\n",
            "Processed 10300 images\n",
            "Processed 10400 images\n",
            "Processed 10500 images\n",
            "Processed 10600 images\n",
            "Processed 10700 images\n",
            "Processed 10800 images\n",
            "Processed 10900 images\n",
            "Processed 11000 images\n",
            "Processed 11100 images\n",
            "Processed 11200 images\n",
            "Processed 11300 images\n",
            "Processed 11400 images\n",
            "Processed 11500 images\n",
            "Processed 11600 images\n",
            "Processed 11700 images\n",
            "Processed 11800 images\n",
            "Processed 11900 images\n",
            "Processed 12000 images\n",
            "Processed 12100 images\n",
            "Processed 12200 images\n",
            "Processed 12300 images\n",
            "Processed 12400 images\n",
            "Processed 12500 images\n",
            "Processed 12600 images\n",
            "Image organization complete.\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import pandas as pd\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "#Load the CSV to get image paths and labels\n",
        "csv_path = '/content/drive/MyDrive/BU_MSBA/BA865 - Neural Networks/BA865 - Group Project/GTSRBkaggle/Test.csv'\n",
        "y_test_df = pd.read_csv(csv_path)\n",
        "\n",
        "#Define the base path where the original test images are stored\n",
        "base_path = '/content/drive/MyDrive/BU_MSBA/BA865 - Neural Networks/BA865 - Group Project/GTSRBkaggle/'\n",
        "\n",
        "#Define the path for the new organized test images (without resizing)\n",
        "new_base_path = os.path.join(base_path, 'Test_organized')\n",
        "\n",
        "#Create the new base directory if it does not exist\n",
        "if not os.path.exists(new_base_path):\n",
        "    os.makedirs(new_base_path)\n",
        "\n",
        "#Iterate over the DataFrame rows\n",
        "for i, row in y_test_df.iterrows():\n",
        "    img_path, label = row['Path'], row['ClassId']\n",
        "    full_path = os.path.join(base_path, img_path)\n",
        "    new_dir_path = os.path.join(new_base_path, str(label))\n",
        "\n",
        "    #Create a directory for the class if it does not exist\n",
        "    if not os.path.exists(new_dir_path):\n",
        "        os.makedirs(new_dir_path)\n",
        "\n",
        "    try:\n",
        "        #Define the new image path\n",
        "        new_img_path = os.path.join(new_dir_path, os.path.basename(img_path))\n",
        "\n",
        "        #Copy the original image to the new path without altering its size\n",
        "        shutil.copy(full_path, new_img_path)\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing image {full_path}: {e}\")\n",
        "\n",
        "    #Print progress\n",
        "    if (i + 1) % 100 == 0:\n",
        "        print(f\"Processed {i + 1} images\")\n",
        "\n",
        "print(\"Image organization complete.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f7g-QIh_MM0"
      },
      "source": [
        "# References: \n",
        "- Generative AI was utilized for Debugging, code improvement, sentence structure and grammar.\n",
        "- Chollet, Francois. “The Keras Blog.” The Keras Blog ATOM, blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html.  Accessed 24 Apr. 2024. \n",
        "- Elhamod, Mohammad. “Transfer_Learning.Ipynb.” GitHub, 2024, github.com/elhamod/BA865-2024.git.  \n",
        "- Mykola. “GTSRB - German Traffic Sign Recognition Benchmark.” Kaggle, 25 Nov. 2018, www.kaggle.com/datasets/meowmeowmeowmeowmeow/gtsrb-german-traffic-sign. \n",
        "- Poojahira, Hiranandani. “Poojahira/Gtsrb-Pytorch: Pytorch Implementation of Kaggle GTSRB Challenge with 99.8% Accuracy.” GitHub, 2018, github.com/poojahira/gtsrb-pytorch. \n",
        "- Psomas, Bill. “Billpsomas/Traffic_signs_classification: German Traffic Signs Classification Using Neural Networks (MLP, Lenet, Alexnet, Vggnet, RestrictNet) in Tensorflow Framework.” GitHub, 2019, github.com/billpsomas/Traffic_Signs_Classification. \n",
        "- Saglani, Vatsal. “Multi-Class Image Classification Using CNN over Pytorch, and the Basics of CNN.” Medium, Medium, 20 Apr. 2020, thevatsalsaglani.medium.com/multi-class-image-classification-using-cnn-over-pytorch-and-the-basics-of-cnn-fdf425a11dc0. \n",
        "- Stallkamp, Johannes, et al. “German Traffic Sign Recognition Benchmark GTSRB.” Public Archive: DAAEAC0D7CE1152AEA9B61D9F1E19370, May 2019, sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/published-archive.html.\n",
        "- Tantai, Hengtao. “Use Weighted Loss Function to Solve Imbalanced Data Classification Problems.” Medium, Medium, 27 Feb. 2023, medium.com/@zergtant/use-weighted-loss-function-to-solve-imbalanced-data-classification-problems-749237f38b75. \n",
        "- Weights & Bias. “Sweep Configuration Structure: Weights & Biases Documentation.” Define Sweep Configuration for Hyperparameter Tuning., 2024, docs.wandb.ai/guides/sweeps/define-sweep-configuration."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
