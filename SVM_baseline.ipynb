{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNF5aonB+ico0C6eJMc2kiK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Baseline model - SVM\n","\n","To have a baseline to compare out Neural Networks models against we used a SVM to classify the traffic sign images.\n","\n","*ADD limitations"],"metadata":{"id":"O5T8o0_NeT8q"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0J1sZg4mXKoN","executionInfo":{"status":"ok","timestamp":1713362535401,"user_tz":180,"elapsed":27088,"user":{"displayName":"Victor Floriano","userId":"16962368443903150562"}},"outputId":"c847fcbf-dc5b-4a81-c275-e6ddf357ba78"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["#Runtime ~22min\n","import os\n","import cv2\n","import numpy as np\n","\n","def load_images_and_labels(base_path, max_images=100000):\n","    data = []\n","    labels = []\n","    image_count = 0  # Initialize a counter for the images\n","    classes = sorted(os.listdir(base_path))\n","    total_classes = len(classes)\n","\n","    for label, cls in enumerate(classes):\n","        cls_folder = os.path.join(base_path, cls)\n","        if os.path.isdir(cls_folder):\n","            image_files = os.listdir(cls_folder)\n","            total_images = len(image_files)\n","\n","            for idx, img_filename in enumerate(image_files):\n","                if image_count >= max_images:\n","                    print(\"Reached the maximum number of images to process.\")\n","                    return np.array(data), np.array(labels)  # Return the data collected so far\n","\n","                img_path = os.path.join(cls_folder, img_filename)\n","                img = cv2.imread(img_path)\n","                if img is not None:\n","                    img = cv2.resize(img, (32, 32))\n","                    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","                    img = img.flatten() /255 #Flattens and normalizes the images\n","                    data.append(img)\n","                    labels.append(label)\n","                    image_count += 1  # Increment the counter\n","\n","                #Print progress for each class every 100 images\n","                if (idx + 1) % 1000 == 0 or idx == total_images - 1:\n","                    print(f\"Processed {idx + 1}/{total_images} images in class {label + 1}/{total_classes} ({cls})\")\n","\n","    return np.array(data), np.array(labels)\n","\n","\n","base_path = '/content/drive/MyDrive/BU_MSBA/BA865 - Neural Networks/BA865 - Group Project/GTSRBkaggle/Train'\n","\n","#Load data\n","train_data, train_labels = load_images_and_labels(base_path)\n"],"metadata":{"id":"8bPelh25Y9Jx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","#Split data into training and vaidation sets\n","X_train, X_validation, y_train, y_validation = train_test_split(train_data, train_labels, test_size=0.2, random_state=42)\n"],"metadata":{"id":"adwbK1QZZQ-D","executionInfo":{"status":"ok","timestamp":1713367867614,"user_tz":180,"elapsed":661,"user":{"displayName":"Victor Floriano","userId":"16962368443903150562"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["#Runtime ~9min\n","from sklearn.svm import SVC\n","\n","#Since your features are already scaled to [0,1] we skipped the StandardScaler()\n","svm_classifier = SVC(kernel='rbf', random_state=42) #rbf seems to be the standard kernell for image classification\n","\n","#Train the model on test data\n","svm_classifier.fit(X_train, y_train)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":74},"id":"S-kcfrMkZbnZ","executionInfo":{"status":"ok","timestamp":1713368415416,"user_tz":180,"elapsed":545397,"user":{"displayName":"Victor Floriano","userId":"16962368443903150562"}},"outputId":"b781b0c3-2b25-4997-e443-761975f432eb"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["SVC(random_state=42)"],"text/html":["<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(random_state=42)</pre></div></div></div></div></div>"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["#Runtime ~ 4min\n","from sklearn.metrics import accuracy_score, classification_report\n","\n","#Genarate predictions on validation data\n","y_val_pred = svm_classifier.predict(X_validation)\n","\n","#Calculate accuracy\n","accuracy = accuracy_score(y_validation, y_val_pred)\n","print(f\"Validation Accuracy: {accuracy:.2f}\")"],"metadata":{"id":"O3E5p3qhcnV5","executionInfo":{"status":"ok","timestamp":1713368999727,"user_tz":180,"elapsed":252,"user":{"displayName":"Victor Floriano","userId":"16962368443903150562"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["#Check accuracy by class\n","class_report = classification_report(y_validation, y_val_pred)\n","print(\"Classification Report by Class:\\n\", class_report)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"losS6702v2k4","executionInfo":{"status":"ok","timestamp":1713369003099,"user_tz":180,"elapsed":262,"user":{"displayName":"Victor Floriano","userId":"16962368443903150562"}},"outputId":"ded79e9f-431c-4b16-cfd0-1d8aeffade6a"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Classification Report by Class:\n","               precision    recall  f1-score   support\n","\n","           0       1.00      0.71      0.83        38\n","           1       0.91      0.89      0.90       496\n","           2       0.86      0.85      0.86       451\n","           3       0.69      0.73      0.71       281\n","           4       0.85      0.83      0.84       417\n","           5       0.67      0.75      0.71       357\n","           6       0.84      0.75      0.80        65\n","           7       0.90      0.77      0.83       254\n","           8       0.57      0.83      0.68       303\n","           9       0.99      0.89      0.94       276\n","          10       0.65      0.92      0.76       395\n","          11       0.89      0.92      0.90       252\n","          12       0.83      0.93      0.87       442\n","          13       0.98      0.96      0.97       457\n","          14       0.99      0.92      0.96       143\n","          15       0.94      0.87      0.90       108\n","          16       1.00      0.81      0.90        86\n","          17       0.99      0.91      0.95       217\n","          18       0.89      0.87      0.88       239\n","          19       1.00      0.47      0.64        32\n","          20       0.93      0.58      0.71        73\n","          21       0.96      0.74      0.84        66\n","          22       0.99      0.95      0.97        80\n","          23       0.97      0.82      0.89       109\n","          24       1.00      0.61      0.76        51\n","          25       0.91      0.94      0.92       312\n","          26       0.89      0.81      0.85       109\n","          27       0.97      0.58      0.73        48\n","          28       0.96      0.86      0.91       113\n","          29       0.96      0.84      0.90        58\n","          30       0.88      0.77      0.82       101\n","          31       0.85      0.82      0.83       157\n","          32       0.84      0.78      0.81        41\n","          33       0.99      0.90      0.94       138\n","          34       1.00      0.85      0.92        78\n","          35       1.00      0.92      0.96       234\n","          36       1.00      0.87      0.93        87\n","          37       1.00      0.93      0.97        45\n","          38       0.88      0.98      0.93       413\n","          39       1.00      0.74      0.85        53\n","          40       1.00      0.65      0.79        72\n","          41       0.97      0.78      0.87        46\n","          42       1.00      0.57      0.72        51\n","\n","    accuracy                           0.86      7844\n","   macro avg       0.92      0.81      0.85      7844\n","weighted avg       0.88      0.86      0.86      7844\n","\n"]}]}]}