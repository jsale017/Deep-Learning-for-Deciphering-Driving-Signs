{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Learning for Deciphering Traffic Signs\n",
        "_________________________________________________________________________________________________________________________________________________________________________________\n",
        "\n",
        "##### Contributors:\n",
        " Victor Floriano, Yifan Fan, Jose Salerno"
      ],
      "metadata": {
        "id": "OKlU1qk4Zly7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem Statement & Motivation\n",
        "As the world advances towards autonomous vehicles, our team has observed the remarkable efforts of large car manufacturers, who are working with data scientists to develop fully autonomous cars. Our team is excited to contribute to the development of this technology by creating a neural network model that will be able to classify different traffic signs. Our ultimate goal is to assist car makers in overcoming the challenges they may face in implementing neural network models that effectively read traffic signs and further their efforts toward a fully autonomous car or assisted driving. We believe autonomous driving to be an important problem to solve due to the great economic benefits it can generate for car manufacturers and the improvement of general driving safety.\n",
        "\n",
        "## Data Preparation\n",
        " We've selected the German Traffic Sign Recognition Benchmark (GTSRB) as our primary dataset. It's renowned for its complexity, featuring over 50,000 images across more than 40 classes of traffic signs. The GTSRB is publicly accessible through two resources. To efficiently manage the extensive and complex GTSRB dataset, our strategy integrates preprocessing for uniformity, data augmentation for robustness, and batch processing for computational efficiency. We'll employ distributed computing to parallelize operations, enhancing processing speed, and use stratified sampling for quick experimentation without compromising representativeness.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2iFnzTGUdjrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project Breakdown Summary\n",
        "1. Data Cleaning and Transformation\n",
        "3. MLP Models\n",
        "4. CNN Model\n",
        "5. Pre-trained Model\n",
        "6. SVM\n",
        "7. Results\n",
        "8. Future Work\n",
        "9. Conclusions"
      ],
      "metadata": {
        "id": "0oACpv-ndpXW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Data Cleaning and Transformation"
      ],
      "metadata": {
        "id": "gSMk02Bq8CVQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Packages"
      ],
      "metadata": {
        "id": "JXPh9xcKdsh3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DaPgqKKKZlaG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvoyQffZ2-HM",
        "outputId": "dc0934d8-959a-4884-97e9-b4f691ae5c47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enable_wandb = True\n",
        "use_gpu = True\n",
        "gpu_available = torch.cuda.is_available()\n",
        "gpu_available"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96uEXO-WNvkS",
        "outputId": "1736f229-77cc-40fb-9631-8f83abb5e818"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if enable_wandb:\n",
        "  !pip install wandb -qU\n",
        "  import wandb\n",
        "  wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "xcvmiWVbdlUg",
        "outputId": "3ebe4b79-9177-4cd1-c876-73ab718bc2d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.1/267.1 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading images - from Datacamp CNN course (cloud example)\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import transforms\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize((32,32))\n",
        "])\n",
        "\n",
        "dataset_train = ImageFolder(\n",
        "    '/content/drive/MyDrive/BA865 - Group Project/GTSRBkaggle/Train',\n",
        "    transform = train_transforms\n",
        ")"
      ],
      "metadata": {
        "id": "TjZBv1zw2_xN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing Data"
      ],
      "metadata": {
        "id": "1Nkdw0AbTfQ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "#Trying to display images\n",
        "dataloader_train = DataLoader(\n",
        "    dataset_train,\n",
        "    shuffle=True,\n",
        "    batch_size=1,\n",
        ")\n",
        "\n",
        "image, label = next(iter(dataloader_train))\n",
        "print(image.shape)\n",
        "print('Label:',label)\n",
        "print(label)\n",
        "\n",
        "#Change image into right shape for visualization\n",
        "image = image.squeeze().permute(1,2,0)\n",
        "\n",
        "plt.imshow(image)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "id": "FTvmTS6RQB5T",
        "outputId": "30cc690a-d2ac-4ae6-cb4e-3e2bf3f094c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 3, 32, 32])\n",
            "Label: tensor([3])\n",
            "tensor([3])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAArbElEQVR4nO3df5BV5X3H8c+5d3evIOwSBHbZsBDQBGMIdEqV7JhQE6hAZxxRnDE/OsXU0ZEuTpWmSegkGtvOrNUZY5Ih+ken0swETe0EHZ1RqxjWSQu0UBliUhmhpGBhV0PDXlzk7u49T/9AN90Iej7LHp7d5f3K3InsffbZ7/lx73fvnnM+JwkhBAEAcI4VYhcAADg/0YAAAFHQgAAAUdCAAABR0IAAAFHQgAAAUdCAAABR0IAAAFHUxC7gt6VpqsOHD2vixIlKkiR2OQAAUwhBx48fV3NzswqFM3/OGXEN6PDhw2ppaYldBgDgLB06dEgzZsw44/O5NaANGzbo/vvvV2dnpxYsWKDvfe97uuKKKz7w+yZOnChJapo243075/+XptnThKqhmnmsJBWL2VdRMWO9Q+N9GrQ+PZppTEFuepNRi/upN01zm9rhrpPE3Z7G9NWQfZ1IsipPUu/10+8sp/Fak6SisUETcx+3dxVjnafu680Y7/7VyNoPjZ0wTVN1vvE/A+/nZ5JLA/rRj36kdevW6eGHH9aiRYv04IMPatmyZdq7d6+mTZv2vt/77gosFAqZG5DzEnKj77LX4I310YDO1vnSgNx0R6sBmctZcJbTfP0URlQDcsaO/QY08C0fUE8u75gPPPCAbrnlFn35y1/WZZddpocffljjx4/X3//93+fx4wAAo9CwN6De3l7t2rVLS5cu/c0PKRS0dOlSbdu27T3jK5WKyuXyoAcAYOwb9gb0q1/9StVqVY2NjYO+3tjYqM7OzveMb29vV0NDw8CDExAA4PwQ/Tqg9evXq7u7e+Bx6NCh2CUBAM6BYT8JYcqUKSoWi+rq6hr09a6uLjU1Nb1nfKlUUqlUGu4yAAAj3LB/Aqqrq9PChQu1ZcuWga+laaotW7aotbV1uH8cAGCUyuU07HXr1mn16tX6vd/7PV1xxRV68MEH1dPToy9/+ct5/DgAwCiUSwO68cYb9eabb+quu+5SZ2enfud3fkfPPvvse05MAACcv5LgXpmZs3K5rIaGBk1vmpk9CcFYhNS8krtgXJ1dWyxac1urPvHmdv626q6TPC9EdS8A9C7S8+ZOCtm/IRhpHO/Mbo12tqe7fVLjKn737aLf2sW934drrAtRvXQIl7NenOSWd2Y3xroXrDtVmEkIXa+ru7tb9fX1ZxwX/Sw4AMD5iQYEAIiCBgQAiIIGBACIggYEAIiCBgQAiIIGBACIggYEAIiCBgQAiIIGBACIIpcsuOGQJEFJxnuQezEb+SUP+alG2ce7vyk4ERsZE48GpKkXaxKsGCEzL8dY5cHM4sm4+7llnJrbXE4rBiXX2Bl3+xi1mHUHo5bcE8es+c1agrPO3W2fU90ZtyWfgAAAUdCAAABR0IAAAFHQgAAAUdCAAABR0IAAAFHQgAAAUdCAAABR0IAAAFHQgAAAUdCAAABRjNwsuHf+l21sfqwMKTPiqWBkkyV2fpQz1k8yy0ua5pjZZS6nk7+Wd9SYt8rzy1SzGSsmrXorsVBwtk+eGWlScPIR3f3QimCrWnOnOWXYZc0j5BMQACAKGhAAIAoaEAAgChoQACAKGhAAIAoaEAAgChoQACAKGhAAIAoaEAAgChoQACCKERvFE0KiEDJGhCTZ+6gTryJ5CShuGosTg2FH8Th1mPE3/jp0ltOLhUmdCJTEXU5nsDe3mTqjYiG/fdza/ua+UjWiYdy6rfGhz5o7a5TMwHhjvbivZCcOzA7VMuLArPfZjIXwCQgAEAUNCAAQBQ0IABAFDQgAEAUNCAAQBQ0IABAFDQgAEAUNCAAQBQ0IABAFDQgAEAUNCAAQxYjNgqtWQ+YMpKSQX2JbMDKhgt3Pjbnzi4LzmcVY6zBr/t8QaknMLDhn7mq/mTXmRY0pGFlw1ZA9f+1ULU4WnFd41ckxS/qtub390KvbykiTlBSKmccWi97bbsGYu1D06q4pZt+vnDrSNFW5+38/eM7MMwIAMIyGvQF961vfUpIkgx6XXnrpcP8YAMAol8uf4D7xiU/ohRde+M0PqRmxf+kDAESSS2eoqalRU1NTHlMDAMaIXI4Bvfbaa2pubtacOXP0pS99SQcPHjzj2EqlonK5POgBABj7hr0BLVq0SBs3btSzzz6rhx56SAcOHNBnPvMZHT9+/LTj29vb1dDQMPBoaWkZ7pIAACNQEpz7vQ7BsWPHNGvWLD3wwAO6+eab3/N8pVJRpVIZ+He5XFZLS4sap85UIeOpp8adYtWfeqfLJsbkNebplYl1amiOJyzmeFr1KdlPDc31NOyCeStxY+7+nE/DzvpakEbzadj5bfuRdBp24Tw5Dft/Xv+luru7VV9ff+afn3nGIZo0aZI+9rGPad++fad9vlQqqVQq5V0GAGCEyf06oLfeekv79+/X9OnT8/5RAIBRZNgb0Fe+8hV1dHTol7/8pf71X/9V1113nYrFor7whS8M948CAIxiw/4nuNdff11f+MIXdPToUU2dOlWf/vSntX37dk2dOtWaJzX+Zltwjhu4aSzG37xTuVEizt/qvd8VrMU0/66fmscYvOM63nImiRHz0+ttn7SafTmt4yhS5pipIXGPpRjjneNiknlsxBgrScXa7G9fxdpaa273sECNcYwuqfGW07mOssaKJZMKxnhn+1SrVf3P67/8wHHD3oAee+yx4Z4SADAGkQUHAIiCBgQAiIIGBACIggYEAIiCBgQAiIIGBACIggYEAIiCBgQAiIIGBACIggYEAIgi99sxDFUSUiUZY6eCkcMVUi8PrFrNnjVm3hJGqX1fHYdxDx4zOszNm6o1fkB/6uXM9ae9mcemVW/bWxl2drSbmanmzOxmwTl15De1iuZ9cmqK2fPdJk5ssOa+8MILzVqyjw3utjfuSebdY8y8t1cw7h00zOMAABhWNCAAQBQ0IABAFDQgAEAUNCAAQBQ0IABAFDQgAEAUNCAAQBQ0IABAFDQgAEAUIzaKp6+/okLGCAonTiINXgxGsEJQzIia2pIxNnvsiCQVCtmzQZyoD0kK1ZPW+L4TPZnHVvu9KJ6qGd3jMbanHVHjfYMX32LnAmWf2Zw6GPFHbkSNkuyv+1LvBdbUpQu88YVC9tdQ1YyEKhSyv/ZrikYmkGRt0H4ja6xazfa65BMQACAKGhAAIAoaEAAgChoQACAKGhAAIAoaEAAgChoQACAKGhAAIAoaEAAgChoQACAKGhAAIIoRmwVXLJYy5ysFI/estuhlcBWN8U4elCTV1mXPmxo/bpw1d52xmH0n37Lm/vXRijW+tz979lWaZs/3OiX7Ok+M/USSCkauVmJu+ySxw+MMXqZamjG3yx176huM3DMzI62/kn05u7t/bc2dmttn4vjsuY5ufmFNTfblDFVvP0yD8drsz/66JwsOADCi0YAAAFHQgAAAUdCAAABR0IAAAFHQgAAAUdCAAABR0IAAAFHQgAAAUdCAAABR0IAAAFGM2Cy4Ut14FTJmd427sD77vCUzr602ew5TKi/jKSlmX/2lmjpr7sLbxzOPPdb9pjX3ibe9LDgn3i0k3i5ZrKnNPLa2xtzdnXw3N9steHltwch3S+TVUihmX4dptc+a24qCs3Pmso+vVt62pj5hZscl1fGZxxYK3vap1mRfid7WkXr7TmYfWzmReWzWTEc+AQEAorAb0EsvvaRrrrlGzc3NSpJETzzxxKDnQwi66667NH36dI0bN05Lly7Va6+9Nlz1AgDGCLsB9fT0aMGCBdqwYcNpn7/vvvv03e9+Vw8//LB27NihCy+8UMuWLdPJk9k/6gEAxj77GNCKFSu0YsWK0z4XQtCDDz6ob3zjG7r22mslST/4wQ/U2NioJ554Qp///OfPrloAwJgxrMeADhw4oM7OTi1dunTgaw0NDVq0aJG2bdt22u+pVCoql8uDHgCAsW9YG1BnZ6ckqbGxcdDXGxsbB577be3t7WpoaBh4tLS0DGdJAIARKvpZcOvXr1d3d/fA49ChQ7FLAgCcA8PagJqamiRJXV1dg77e1dU18NxvK5VKqq+vH/QAAIx9w9qAZs+eraamJm3ZsmXga+VyWTt27FBra+tw/igAwChnnwX31ltvad++fQP/PnDggHbv3q3Jkydr5syZuuOOO/Q3f/M3+uhHP6rZs2frm9/8ppqbm7Vy5crhrBsAMMrZDWjnzp367Gc/O/DvdevWSZJWr16tjRs36qtf/ap6enp066236tixY/r0pz+tZ599VhdccIH1c5JCUFLIFj9Sqsv+Qa5Um2cUjxev0lftzTy22pd9rCT1lLNHiZzoMeNVjGidU7Kv86IZOVRTm1+alLU1zWidxNxXnKSf4Mb8OMMLZlSS8XpLEi/iqdqXfb8NVW+n7at4tbxlZA4Varz3oGLGSLJTvOXs789ed9Z4HSn7PpgEd2/NWblcVkNDg2Z8+OLMWXANDR/KPL/TrKR8s+D6qtk3vrMLStLJ//3fzGPfeNPLvTrZ7+3kwWhAhdqSNbfTgMy0NgU3383gNiCnePcVnec7QBKy7ytpf44NyNz6iZExKEk1tdlfoedLA/r1r4+pu7v7fY/rRz8LDgBwfqIBAQCioAEBAKKgAQEAoqABAQCioAEBAKKgAQEAoqABAQCioAEBAKKgAQEAosgvSOsspdVq5oyQ3srbmeetKXpRLwUjMqVqZLtJUsWou1r18tp6erLPXTGjdVyFmuy7WdEYK0mJE5eTelFJaZp92ydFs24zGiYYtff3e/tKtWpk8ZjpRMWCkQNoRc54sXRVI3JGkoIRkyVJVSMCJ029lehUEozoI1/2urMmvPEJCAAQBQ0IABAFDQgAEAUNCAAQBQ0IABAFDQgAEAUNCAAQBQ0IABAFDQgAEAUNCAAQxciN4kmzR0r09layTxy8uJzUiOToMyNQQsg+d3+/V/fbJ05mHmskzkjyY2ecKJ6CGfUS0uzr0I1jqRoxPzVOLoykYC9n9iie1IwckhGB40RTSWaEVI0Xk1Wsyf77s7tOskbJ/Gb+7OMLifd7f5BRu7lfWVFW5vtEFnwCAgBEQQMCAERBAwIAREEDAgBEQQMCAERBAwIAREEDAgBEQQMCAERBAwIAREEDAgBEQQMCAEQxYrPgqtU+hZCtP544kT0L7m15eWBOxlPVzVRz+n/q5cxVnYA3M5sqSWrN8dmzxpRkzwCU3Iw0bwM5mXeJvLrNyC4rG1GJ97Iu1mbfnjXBW85Kr7F9zPy1opFhl5ghg6E/h+Czd1ive5kvTzdj0NieIcm+TkLG4Dg+AQEAoqABAQCioAEBAKKgAQEAoqABAQCioAEBAKKgAQEAoqABAQCioAEBAKKgAQEAohixUTzhnUemsUYcSwheFE/ViAcJwcvBKBazR4kE83eFYMTOuKEjbqxJkhjjzWJSZ9t7U6vGyEAxV4lkxs54GStmMc72Med2tn1irhNn7oIRqyRJadWLvnJKtyOHrO3jze2MLhSyvx5CxmXkExAAIAoaEAAgCrsBvfTSS7rmmmvU3NysJEn0xBNPDHr+pptuUpIkgx7Lly8frnoBAGOE3YB6enq0YMECbdiw4Yxjli9friNHjgw8Hn300bMqEgAw9tgnIaxYsUIrVqx43zGlUklNTU1DLgoAMPblcgxo69atmjZtmubOnas1a9bo6NGjZxxbqVRULpcHPQAAY9+wN6Dly5frBz/4gbZs2aK//du/VUdHh1asWKFq9fSny7a3t6uhoWHg0dLSMtwlAQBGoCRkPWH7dN+cJNq8ebNWrlx5xjH/9V//pYsvvlgvvPCClixZ8p7nK5WKKpXf3FK7XC6rpaVFUy6anvm882DcrjoE89bWuV4HVJd9bvO6hP5K9tuUBxm3zJZUU3uBNb5Y69zaOvt1PZLU3599Oc/wO9AZ1dRkX07zMhP7OqBqf/br1/rN/bBQl98tuXt7T2Yem5i3Eq81biWeVnutuft73euAjGuSasxbplvDvf0qNbanc/1fCEHHft2t7u5u1dfXn3Fc7qdhz5kzR1OmTNG+fftO+3ypVFJ9ff2gBwBg7Mu9Ab3++us6evSopk+fnvePAgCMIvZZcG+99dagTzMHDhzQ7t27NXnyZE2ePFn33HOPVq1apaamJu3fv19f/epXdckll2jZsmXDWjgAYHSzG9DOnTv12c9+duDf69atkyStXr1aDz30kPbs2aN/+Id/0LFjx9Tc3Kyrr75af/3Xf61SqWT9nERO6lT2kVXziJdziMw9muZ8/HTrtjK7EnNyd7zxd2l3HaZG5p0x9J25sx80SlIzI80rRYlxjME9rGvt41YumcevO5+xQ5E4x15y3D65xgBax5eyjbUb0FVXXfW+K+S5555zpwQAnIfIggMAREEDAgBEQQMCAERBAwIAREEDAgBEQQMCAERBAwIAREEDAgBEQQMCAERBAwIARGFH8Zw7QZmzh5w8oxwzofyYrBESZpVzTlZwsuCM/DVJStPs9zMJ5u9b/cY9ZKrebXJUU5P9XjaSVMx4byxJCv3mjY+c+weZOYAF40Xh3k8rOGmR5ovTynYza7Ffb854czlzi5nLOC+fgAAAUdCAAABR0IAAAFHQgAAAUdCAAABR0IAAAFHQgAAAUdCAAABR0IAAAFHQgAAAUYzgKJ58uHE5TvKIFcchKQ1OjEzOeTkOOxbIiOIx1okkKcn+O1RN0dvdi8bO0teXPbZHkqrmOiwUjEibHPeVxPyd1YnAcTe9s1+50Toua3bzPcgNBcpLMPbZrGP5BAQAiIIGBACIggYEAIiCBgQAiIIGBACIggYEAIiCBgQAiIIGBACIggYEAIiCBgQAiIIGBACIYuRmwSVJ9uA2K6/NLiSXoZKZ2WVkgZ2qxZg79eZ2MqFOfYMztxcIVjCy4IqFojV3jbHOq/3e73KpuyMamWqJs+0lhdRY52aYYmosaHCDGo39MK16+5W7jzsZec4+K0lJYmRGmq8fZ7yT65f1Rc8nIABAFDQgAEAUNCAAQBQ0IABAFDQgAEAUNCAAQBQ0IABAFDQgAEAUNCAAQBQ0IABAFCM4ikd2tE0urBq8+I40VLOX4SbxON+QZ3SLqVDwfieq9vdnHpuakUNpyF6Ln6zj1eKML5r7SrXam3lsb/ZdVpKUGpE2RS8pSYmyF5OmZuFu3JTzGjKidU6V4tRi74nGzM7YbPgEBACIwmpA7e3tuvzyyzVx4kRNmzZNK1eu1N69eweNOXnypNra2nTRRRdpwoQJWrVqlbq6uoa1aADA6Gc1oI6ODrW1tWn79u16/vnn1dfXp6uvvlo9PT0DY+6880499dRTevzxx9XR0aHDhw/r+uuvH/bCAQCjWxLsbP3fePPNNzVt2jR1dHRo8eLF6u7u1tSpU7Vp0ybdcMMNkqRXX31VH//4x7Vt2zZ96lOf+sA5y+WyGhoaNHXq9MzHA0I1+3GAfuPv3ZJ3y4Qhr8gM3MNhaW/2dWImuCsp1Frja0p1Ri191tzOMaCk6B3yrDFi83uNOiRJZi11NdnXeV/fSWvuqnNXEGtmKTV2rmLR3K+MYqq9FWvutGoeM0qyH8Aq1JqH3q1jtObxJasO4xhQCCp3l9Xd3a36+vozjjurY0Dd3d2SpMmTJ0uSdu3apb6+Pi1dunRgzKWXXqqZM2dq27Ztp52jUqmoXC4PegAAxr4hN6A0TXXHHXfoyiuv1Lx58yRJnZ2dqqur06RJkwaNbWxsVGdn52nnaW9vV0NDw8CjpaVlqCUBAEaRITegtrY2vfLKK3rsscfOqoD169eru7t74HHo0KGzmg8AMDoM6TqgtWvX6umnn9ZLL72kGTNmDHy9qalJvb29Onbs2KBPQV1dXWpqajrtXKVSSaVSaShlAABGMesTUAhBa9eu1ebNm/Xiiy9q9uzZg55fuHChamtrtWXLloGv7d27VwcPHlRra+vwVAwAGBOsT0BtbW3atGmTnnzySU2cOHHguE5DQ4PGjRunhoYG3XzzzVq3bp0mT56s+vp63X777Wptbc10BhwA4PxhNaCHHnpIknTVVVcN+vojjzyim266SZL07W9/W4VCQatWrVKlUtGyZcv0/e9/f1iKBQCMHWd1HVAehnYdUPZz9p3cK8m9DsjNj3KGeueLpH1GRlq/ec2DvNCuonGMr8bMgus1rnmppu72yV5LYl6pVazNfm2UJNUaQWmpey2V8fpJzXWYGNuzWDCvdkuz7+PVXu917+8qxnVAzgVMUq55lM5oJ48whKDuvK8DAgBgqGhAAIAoaEAAgChoQACAKGhAAIAoaEAAgChoQACAKGhAAIAoaEAAgChoQACAKIZ0O4Zzob+/X0nWKJQ0+21oq8ZYSUqMeBBnrHQqriIvTjSId8tf2ffwrvZmj4Yp1Hm35qitvSD73Oa2T43tUyh4L6WsMVPvsiJTzFpqjNtJ23ussQ5D6sXlVPuy71cheK/NzO897ygUjfFm4pDDfk8xltNZh1nL4BMQACAKGhAAIAoaEAAgChoQACAKGhAAIAoaEAAgChoQACAKGhAAIAoaEAAgChoQACAKGhAAIIoRmwVXOXlSSZIxe8jJmzLTrIq12XOyasz8KIebweVkwSUFc/ZqvzU8hGrmsX29FWvumtrazGOLRSMfT1Ix6/43FDlO7U6e+XUm2TmAIc2e1+ZkBtqlmNvSzerz5nfz2pyh+WUM5oFPQACAKGhAAIAoaEAAgChoQACAKGhAAIAoaEAAgChoQACAKGhAAIAoaEAAgChoQACAKEZsFM+pnI1sGRQFIwYjdbMn0ux5H6GQXwRKMOKGTk2efXyhxouoSc04FmcdKvVifvr7ss9dDN7u7sSxFMyYn+Bm8YT8ol7SqrGPm9un2p89WinYL05nnZjr23wtO+yljJ2XkyM+AQEAoqABAQCioAEBAKKgAQEAoqABAQCioAEBAKKgAQEAoqABAQCioAEBAKKgAQEAoqABAQCiGLFZcCEJmeObgpGu5EaqVavZx4bEy0grFo2sMSM3TpISJ0DKndvNPTNWepCbM5d9A/X3GhtTXhZckni/ywV3nTtzmzt5MNahm2Tm1OJkI54ab6zzgvlWV3CX08jTM9+DnOF2gp25zocbn4AAAFFYDai9vV2XX365Jk6cqGnTpmnlypXau3fvoDFXXXWVkiQZ9LjtttuGtWgAwOhnNaCOjg61tbVp+/btev7559XX16err75aPT09g8bdcsstOnLkyMDjvvvuG9aiAQCjn/WH0WeffXbQvzdu3Khp06Zp165dWrx48cDXx48fr6ampuGpEAAwJp3VMaDu7m5J0uTJkwd9/Yc//KGmTJmiefPmaf369Tpx4sQZ56hUKiqXy4MeAICxb8hnwaVpqjvuuENXXnml5s2bN/D1L37xi5o1a5aam5u1Z88efe1rX9PevXv14x//+LTztLe365577hlqGQCAUSoJ9r2eT1mzZo2eeeYZ/fSnP9WMGTPOOO7FF1/UkiVLtG/fPl188cXveb5SqahS+c1te8vlslpaWjRu3PjMp2U6H+Ocu0NLsk5TLNR4HyjzPQ07v9sVp/3eSkz7s9/G2Tmd9dQ3eMMdnIZ92tHe3KP0NOykmONp2NbMnnxPw84+NoSgcrlb3d3dqq+vP+O4IX0CWrt2rZ5++mm99NJL79t8JGnRokWSdMYGVCqVVCqVhlIGAGAUsxpQCEG33367Nm/erK1bt2r27Nkf+D27d++WJE2fPn1IBQIAxiarAbW1tWnTpk168sknNXHiRHV2dkqSGhoaNG7cOO3fv1+bNm3SH/7hH+qiiy7Snj17dOedd2rx4sWaP39+LgsAABidrGNAZ/ob7SOPPKKbbrpJhw4d0h/90R/plVdeUU9Pj1paWnTdddfpG9/4xvv+HfD/K5fL7zQ0jgENmptjQGf4Bm+4g2NApx3tzc0xoPeOtWb2jLZjQEM+CSEv7zagC0rZG5DDXVinhKTo1Vtbkz1TzW1AHnNuN8sqNbLgjLGSlFazNzc3hKtgNRXzDctc5060n5ON+O53ZB9p7ivOL3DGL2SS95oIBbdub7i1DvN8x81zcmd9h6ByufyBDYgsOABAFDQgAEAUNCAAQBQ0IABAFDQgAEAUNCAAQBQ0IABAFDQgAEAUNCAAQBQ0IABAFEO+IV3evEAJKynLK8SIn0jceBVrtBv14tThVmJuHScGxcxUKzgZNWbMj7WY7m7lDbe+wZ67kD0Syo7HMranuenlrPTED+HKqRIzfk1muk6OGYN54BMQACAKGhAAIAoaEAAgChoQACAKGhAAIAoaEAAgChoQACAKGhAAIAoaEAAgChoQACAKGhAAIIoRmwVXKBQy5055WWZmjpkxdcHI1HIFKxBKfuBUjqzsOCfbTV5+WDDDxhLj97N8cwAlZ79195XUyZnLc7fKNSPNm9sO97OY+4rxmnDfJmLjExAAIAoaEAAgChoQACAKGhAAIAoaEAAgChoQACAKGhAAIAoaEAAgChoQACAKGhAAIIoRG8VzwQXjVShk7I9G/kQIVasOd7w1txOvYv6ukDXG6NTk+eZ3OMvpJqZYlbtRL2YskMeMYwnZx1dD6s2dZ75OjlOHHPfxPFeJH6tlDB05CVyZ8AkIABAFDQgAEAUNCAAQBQ0IABAFDQgAEAUNCAAQBQ0IABAFDQgAEAUNCAAQBQ0IABAFDQgAEMWIzYKrKdZkz4JzMtVSLywpTbPPXTVz4xIj5MnO6zLiptxsKnd8rlFjmfeRvJnrxA6mszaoWUteg/OVZ93BeN1L3tZ3shEl833CfT1YOZrDP+1IefUCAM4zVgN66KGHNH/+fNXX16u+vl6tra165plnBp4/efKk2tradNFFF2nChAlatWqVurq6hr1oAMDoZzWgGTNm6N5779WuXbu0c+dOfe5zn9O1116rn//855KkO++8U0899ZQef/xxdXR06PDhw7r++utzKRwAMLolwb45xWCTJ0/W/fffrxtuuEFTp07Vpk2bdMMNN0iSXn31VX384x/Xtm3b9KlPfSrTfOVyWQ0NDZo6pTmnY0DecZo07cs81j0GlOuNPqy/13r3jxlJx4BG3Q1Q3lFw//ptHJPor3r7YaHo7IfW1KPWiDoGZOzj2d8z3y0mr2NAQeVyWd3d3aqvrz/juCEfA6pWq3rsscfU09Oj1tZW7dq1S319fVq6dOnAmEsvvVQzZ87Utm3bzjhPpVJRuVwe9AAAjH12A/rZz36mCRMmqFQq6bbbbtPmzZt12WWXqbOzU3V1dZo0adKg8Y2Njers7DzjfO3t7WpoaBh4tLS02AsBABh97AY0d+5c7d69Wzt27NCaNWu0evVq/eIXvxhyAevXr1d3d/fA49ChQ0OeCwAwetjXAdXV1emSSy6RJC1cuFD//u//ru985zu68cYb1dvbq2PHjg36FNTV1aWmpqYzzlcqlVQqlfzKAQCj2llfB5SmqSqVihYuXKja2lpt2bJl4Lm9e/fq4MGDam1tPdsfAwAYY6xPQOvXr9eKFSs0c+ZMHT9+XJs2bdLWrVv13HPPqaGhQTfffLPWrVunyZMnq76+XrfffrtaW1sznwEHADh/WA3ojTfe0B//8R/ryJEjamho0Pz58/Xcc8/pD/7gDyRJ3/72t1UoFLRq1SpVKhUtW7ZM3//+94dUWJIkmU8/dE4LtiNtzBMsc2NPbZxe6U6d46nP9ine1mCv7sRZh26ckX0qrjHW/LuGM7dbd76sws2p3X3FGWu+fhJnP/QuqbBrGWZnfR3QcHv3OqBpUz+c+Zx2a6WbG6harWQfm+d1QPaOkn2zmpc82JzK/WuM8ruWKs8GlJh//XYqr5rXuhUK2Wc/XxrQSFpKpwHZUxvrcERdBwQAwNmgAQEAoqABAQCioAEBAKKgAQEAoqABAQCioAEBAKKgAQEAoqABAQCisNOw8/buFeVpmj2xIM8khNS6Y+BIun46nzsd5m30rkO37vyW044Fcq5wH1kZAdmN5iSEEVKNm4Tw////TEZcAzp+/Lgk6VdHj0SuBABwNo4fP66GhoYzPj/isuDSNNXhw4c1ceLEQTlf5XJZLS0tOnTo0PtmC412LOfYcT4so8RyjjXDsZwhBB0/flzNzc3vm+k54j4BFQoFzZgx44zP19fXj+mN/y6Wc+w4H5ZRYjnHmrNdzvf75PMuTkIAAERBAwIARDFqGlCpVNLdd9+tUqkUu5RcsZxjx/mwjBLLOdacy+UccSchAADOD6PmExAAYGyhAQEAoqABAQCioAEBAKIYNQ1ow4YN+shHPqILLrhAixYt0r/927/FLmlYfetb31KSJIMel156aeyyzspLL72ka665Rs3NzUqSRE888cSg50MIuuuuuzR9+nSNGzdOS5cu1WuvvRan2LPwQct50003vWfbLl++PE6xQ9Te3q7LL79cEydO1LRp07Ry5Urt3bt30JiTJ0+qra1NF110kSZMmKBVq1apq6srUsVDk2U5r7rqqvdsz9tuuy1SxUPz0EMPaf78+QMXm7a2tuqZZ54ZeP5cbctR0YB+9KMfad26dbr77rv1H//xH1qwYIGWLVumN954I3Zpw+oTn/iEjhw5MvD46U9/Gruks9LT06MFCxZow4YNp33+vvvu03e/+109/PDD2rFjhy688EItW7ZMJ0+ePMeVnp0PWk5JWr58+aBt++ijj57DCs9eR0eH2tratH37dj3//PPq6+vT1VdfrZ6enoExd955p5566ik9/vjj6ujo0OHDh3X99ddHrNqXZTkl6ZZbbhm0Pe+7775IFQ/NjBkzdO+992rXrl3auXOnPve5z+naa6/Vz3/+c0nncFuGUeCKK64IbW1tA/+uVquhubk5tLe3R6xqeN19991hwYIFscvIjaSwefPmgX+naRqamprC/fffP/C1Y8eOhVKpFB599NEIFQ6P317OEEJYvXp1uPbaa6PUk5c33ngjSAodHR0hhFPbrra2Njz++OMDY/7zP/8zSArbtm2LVeZZ++3lDCGE3//93w9/9md/Fq+onHzoQx8Kf/d3f3dOt+WI/wTU29urXbt2aenSpQNfKxQKWrp0qbZt2xaxsuH32muvqbm5WXPmzNGXvvQlHTx4MHZJuTlw4IA6OzsHbdeGhgYtWrRozG1XSdq6daumTZumuXPnas2aNTp69Gjsks5Kd3e3JGny5MmSpF27dqmvr2/Q9rz00ks1c+bMUb09f3s53/XDH/5QU6ZM0bx587R+/XqdOHEiRnnDolqt6rHHHlNPT49aW1vP6bYccWGkv+1Xv/qVqtWqGhsbB329sbFRr776aqSqht+iRYu0ceNGzZ07V0eOHNE999yjz3zmM3rllVc0ceLE2OUNu87OTkk67XZ997mxYvny5br++us1e/Zs7d+/X3/5l3+pFStWaNu2bSoWi7HLs6VpqjvuuENXXnml5s2bJ+nU9qyrq9OkSZMGjR3N2/N0yylJX/ziFzVr1iw1Nzdrz549+trXvqa9e/fqxz/+ccRqfT/72c/U2tqqkydPasKECdq8ebMuu+wy7d69+5xtyxHfgM4XK1asGPjv+fPna9GiRZo1a5b+8R//UTfffHPEynC2Pv/5zw/89yc/+UnNnz9fF198sbZu3aolS5ZErGxo2tra9Morr4z6Y5Qf5EzLeeuttw789yc/+UlNnz5dS5Ys0f79+3XxxRef6zKHbO7cudq9e7e6u7v1T//0T1q9erU6OjrOaQ0j/k9wU6ZMUbFYfM8ZGF1dXWpqaopUVf4mTZqkj33sY9q3b1/sUnLx7rY737arJM2ZM0dTpkwZldt27dq1evrpp/WTn/xk0G1Tmpqa1Nvbq2PHjg0aP1q355mW83QWLVokSaNue9bV1emSSy7RwoUL1d7ergULFug73/nOOd2WI74B1dXVaeHChdqyZcvA19I01ZYtW9Ta2hqxsny99dZb2r9/v6ZPnx67lFzMnj1bTU1Ng7ZruVzWjh07xvR2laTXX39dR48eHVXbNoSgtWvXavPmzXrxxRc1e/bsQc8vXLhQtbW1g7bn3r17dfDgwVG1PT9oOU9n9+7dkjSqtufppGmqSqVybrflsJ7SkJPHHnsslEqlsHHjxvCLX/wi3HrrrWHSpEmhs7MzdmnD5s///M/D1q1bw4EDB8K//Mu/hKVLl4YpU6aEN954I3ZpQ3b8+PHw8ssvh5dffjlICg888EB4+eWXw3//93+HEEK49957w6RJk8KTTz4Z9uzZE6699towe/bs8Pbbb0eu3PN+y3n8+PHwla98JWzbti0cOHAgvPDCC+F3f/d3w0c/+tFw8uTJ2KVntmbNmtDQ0BC2bt0ajhw5MvA4ceLEwJjbbrstzJw5M7z44oth586dobW1NbS2tkas2vdBy7lv377wV3/1V2Hnzp3hwIED4cknnwxz5swJixcvjly55+tf/3ro6OgIBw4cCHv27Alf//rXQ5Ik4Z//+Z9DCOduW46KBhRCCN/73vfCzJkzQ11dXbjiiivC9u3bY5c0rG688cYwffr0UFdXFz784Q+HG2+8Mezbty92WWflJz/5SZD0nsfq1atDCKdOxf7mN78ZGhsbQ6lUCkuWLAl79+6NW/QQvN9ynjhxIlx99dVh6tSpoba2NsyaNSvccssto+6Xp9Mtn6TwyCOPDIx5++23w5/+6Z+GD33oQ2H8+PHhuuuuC0eOHIlX9BB80HIePHgwLF68OEyePDmUSqVwySWXhL/4i78I3d3dcQs3/cmf/EmYNWtWqKurC1OnTg1LliwZaD4hnLttye0YAABRjPhjQACAsYkGBACIggYEAIiCBgQAiIIGBACIggYEAIiCBgQAiIIGBACIggYEAIiCBgQAiIIGBACIggYEAIji/wBZ7HMiP/wdgwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# classes = { 0:'Speed limit (20km/h)',\n",
        "#             1:'Speed limit (30km/h)',\n",
        "#             2:'Speed limit (50km/h)',\n",
        "#             3:'Speed limit (60km/h)',\n",
        "#             4:'Speed limit (70km/h)',\n",
        "#             5:'Speed limit (80km/h)',\n",
        "#             6:'End of speed limit (80km/h)',\n",
        "#             7:'Speed limit (100km/h)',\n",
        "#             8:'Speed limit (120km/h)',\n",
        "#             9:'No passing',\n",
        "#             10:'No passing veh over 3.5 tons',\n",
        "#             11:'Right-of-way at intersection',\n",
        "#             12:'Priority road',\n",
        "#             13:'Yield',\n",
        "#             14:'Stop',\n",
        "#             15:'No vehicles',\n",
        "#             16:'Veh > 3.5 tons prohibited',\n",
        "#             17:'No entry',\n",
        "#             18:'General caution',\n",
        "#             19:'Dangerous curve left',\n",
        "#             20:'Dangerous curve right',\n",
        "#             21:'Double curve',\n",
        "#             22:'Bumpy road',\n",
        "#             23:'Slippery road',\n",
        "#             24:'Road narrows on the right',\n",
        "#             25:'Road work',\n",
        "#             26:'Traffic signals',\n",
        "#             27:'Pedestrians',\n",
        "#             28:'Children crossing',\n",
        "#             29:'Bicycles crossing',\n",
        "#             30:'Beware of ice/snow',\n",
        "#             31:'Wild animals crossing',\n",
        "#             32:'End speed + passing limits',\n",
        "#             33:'Turn right ahead',\n",
        "#             34:'Turn left ahead',\n",
        "#             35:'Ahead only',\n",
        "#             36:'Go straight or right',\n",
        "#             37:'Go straight or left',\n",
        "#             38:'Keep right',\n",
        "#             39:'Keep left',\n",
        "#             40:'Roundabout mandatory',\n",
        "#             41:'End of no passing',\n",
        "#             42:'End no passing veh > 3.5 tons' }"
      ],
      "metadata": {
        "id": "TA87HnFKA6w1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Hyperparameters"
      ],
      "metadata": {
        "id": "E3GhuEKgdCoB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "configs = {\n",
        "    \"experiment_name\": \"First Experiement Traffic Signs \",\n",
        "    \"freeze_feature_extraction_layers\": False,\n",
        "    \"pretrained\":False,\n",
        "    \"efficientnet\":False,\n",
        "    \"data_augmentation\":True,\n",
        "    \"transferlearning\": True,\n",
        "\n",
        "    # Data\n",
        "    \"img_dimensions\" : (3,32,32),\n",
        "    \"batch_size\" : 32,\n",
        "    \"num_classes\" : 43,\n",
        "\n",
        "    # CNN\n",
        "    \"filter_sizes\" : [4,8],\n",
        "    \"kernel_size\" : 5,\n",
        "    \"stride\": 2,\n",
        "    \"padding\":1,\n",
        "\n",
        "    #Optimzation\n",
        "    \"learning_rate\" : 0.01,\n",
        "    \"epochs\" : 70,\n",
        "    \"weight_decay\" : 0.00001\n",
        "}"
      ],
      "metadata": {
        "id": "ePzEY-JJdEtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Data Augmentation\n"
      ],
      "metadata": {
        "id": "PPPLsQP-eri7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if configs[\"data_augmentation\"]:\n",
        "  transform = transforms.Compose([\n",
        "      transforms.RandomHorizontalFlip(0.5),\n",
        "      transforms.Resize(32),\n",
        "      transforms.RandomRotation(45),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "    ])\n",
        "else:\n",
        "  transform = transforms.Compose([\n",
        "      transforms.Resize(32),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "    ])"
      ],
      "metadata": {
        "id": "ITJic6XYeuud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset, val_dataset = random_split(dataset_train, [0.8, 0.2])"
      ],
      "metadata": {
        "id": "iTYeqSGGfFZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(dataset = train_dataset, batch_size = configs['batch_size'], shuffle = True)\n",
        "val_loader = DataLoader(dataset = val_dataset, batch_size = configs['batch_size'], shuffle = False)"
      ],
      "metadata": {
        "id": "JI3y2AGLf0UA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Pytorch Sequential MLP\n"
      ],
      "metadata": {
        "id": "Lhry9DmjA2Jj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Sequential Model"
      ],
      "metadata": {
        "id": "zMc_SdyFrsIu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "zLPfJJpqq0Ss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(32*32*3, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 64)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc4 = nn.Linear(64, 43)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return F.softmax(x, dim=1)"
      ],
      "metadata": {
        "id": "jNp37bONVBsG"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MLP()"
      ],
      "metadata": {
        "id": "CgYTJpyhSPnQ"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DseAJcDThxr8",
        "outputId": "997dd587-a87f-49ca-861d-fb1f265d4fdf"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.10/dist-packages (1.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary\n",
        "summary(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9R_0BF6hh31",
        "outputId": "732262c4-dfda-4636-a068-b9ffc2c1ef7b"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "=================================================================\n",
              "Layer (type:depth-idx)                   Param #\n",
              "=================================================================\n",
              "MLP                                      --\n",
              "├─Flatten: 1-1                           --\n",
              "├─Linear: 1-2                            786,688\n",
              "├─Linear: 1-3                            32,896\n",
              "├─Linear: 1-4                            8,256\n",
              "├─Dropout: 1-5                           --\n",
              "├─Linear: 1-6                            2,795\n",
              "=================================================================\n",
              "Total params: 830,635\n",
              "Trainable params: 830,635\n",
              "Non-trainable params: 0\n",
              "================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criteron = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "krTLsn_riFo3"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(model.parameters(), momentum=0.8, lr=configs['learning_rate'], weight_decay=configs['weight_decay'])"
      ],
      "metadata": {
        "id": "5vaS8n1NSxLW"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if enable_wandb:\n",
        "  wandb.init(\n",
        "    project=\"Deciphering Traffic Signs\",\n",
        "    name=configs[\"experiment_name\"],\n",
        "    config=configs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221,
          "referenced_widgets": [
            "cc9aa6bce78b4e3b9d939437f3b077c4"
          ]
        },
        "id": "vptqybDBTW6T",
        "outputId": "e1c70055-f731-4444-961b-4be8c3bcaddf"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:ccrrp21z) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cc9aa6bce78b4e3b9d939437f3b077c4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">First Experiement Traffic Signs </strong> at: <a href='https://wandb.ai/josesalerno/Deciphering%20Traffic%20Signs%20/runs/ccrrp21z' target=\"_blank\">https://wandb.ai/josesalerno/Deciphering%20Traffic%20Signs%20/runs/ccrrp21z</a><br/> View project at: <a href='https://wandb.ai/josesalerno/Deciphering%20Traffic%20Signs%20' target=\"_blank\">https://wandb.ai/josesalerno/Deciphering%20Traffic%20Signs%20</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240413_222019-ccrrp21z/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:ccrrp21z). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240413_224003-cv07xurl</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/josesalerno/Deciphering%20Traffic%20Signs%20/runs/cv07xurl' target=\"_blank\">First Experiement Traffic Signs </a></strong> to <a href='https://wandb.ai/josesalerno/Deciphering%20Traffic%20Signs%20' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/josesalerno/Deciphering%20Traffic%20Signs%20' target=\"_blank\">https://wandb.ai/josesalerno/Deciphering%20Traffic%20Signs%20</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/josesalerno/Deciphering%20Traffic%20Signs%20/runs/cv07xurl' target=\"_blank\">https://wandb.ai/josesalerno/Deciphering%20Traffic%20Signs%20/runs/cv07xurl</a>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U torchmetrics\n",
        "import torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0V4IvkHjPLP",
        "outputId": "20d7df0f-1faf-4172-b32e-d3cfe4115af6"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.25.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.0)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.2.1+cu121)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (0.11.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.11.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.13.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_accuracy(dataloader, model):\n",
        "    acc = torchmetrics.Accuracy()\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            if gpu_available and use_gpu:\n",
        "                images = images.cuda()\n",
        "                labels = labels.cuda()\n",
        "\n",
        "            outputs = model(images)\n",
        "            acc = acc + torch.sum(torch.argmax(outputs, axis = 1) == labels)\n",
        "\n",
        "        acc = acc / len(dataloader.dataset)\n",
        "        return acc"
      ],
      "metadata": {
        "id": "g0bHs5F0jEbd"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_loss(loader):\n",
        "    with torch.no_grad():\n",
        "        loss = 0\n",
        "        for i, (images, labels) in enumerate(loader):\n",
        "            if gpu_available and use_gpu:\n",
        "                images = images.cuda()\n",
        "                labels = labels.cuda()\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = loss + criterion(outputs, labels)\n",
        "        return loss/len(loader)"
      ],
      "metadata": {
        "id": "E9kAV69fj6pK"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopper:\n",
        "    def __init__(self, patience=1):\n",
        "        self.patience = patience\n",
        "        self.counter = 0\n",
        "        self.min_validation_loss = float('inf')\n",
        "\n",
        "    def early_stop(self, validation_loss):\n",
        "        if validation_loss < self.min_validation_loss:\n",
        "            self.min_validation_loss = validation_loss\n",
        "            self.counter = 0\n",
        "            torch.save(model.state_dict(), \"./best_model.pt\")\n",
        "\n",
        "        elif validation_loss > self.min_validation_loss:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                return True\n",
        "        return False\n"
      ],
      "metadata": {
        "id": "rYH7AjU8mbrR"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if gpu_available and use_gpu:\n",
        "    model = model.cuda()"
      ],
      "metadata": {
        "id": "nlIqGFWNkTVa"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopper = EarlyStopper(patience=7)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.3, patience=3)\n",
        "\n",
        "# Training\n",
        "for epoch in range(configs[\"epochs\"]):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        if gpu_available and use_gpu:\n",
        "          images = images.cuda()\n",
        "          labels = labels.cuda()\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criteron(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if i %100 == 0:\n",
        "          print(\"Epoch\", epoch+ 1, \" batch\", i+1, \". Training Loss: \", loss.item())\n",
        "          if enable_wandb:\n",
        "            wandb.log({\"loss\": loss})\n",
        "\n",
        "    train_acc = get_accuracy(train_loader, model)\n",
        "    test_acc = get_accuracy(val_loader, model)\n",
        "\n",
        "    validation_loss = get_loss(val_loader)\n",
        "    wandb.log({\"val_loss\": validation_loss})\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{configs[\"epochs\"]}], LR: {optimizer.param_groups[0][\"lr\"]}, Validation Loss: {validation_loss.item():.4f}, Train Accuracy: {train_acc.item():.4f}, Validation Accuracy: {test_acc.item():.4f}')\n",
        "    if enable_wandb:\n",
        "      wandb.log({\"epoch\": epoch + 1, \"LR\": {optimizer.param_groups[0]['lr']}, \"train_accuracy\": train_acc.item(), \"val_accuracy\": test_acc.item()})\n",
        "\n",
        "    scheduler.step(validation_loss)\n",
        "\n",
        "    if early_stopper.early_stop(validation_loss):\n",
        "        print(\"Validation loss hasn't dropped. Early stopping!\")\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UPIxOIFulXJU",
        "outputId": "32d658b9-2aa0-4704-b44a-7bcb01f4606a"
      },
      "execution_count": 74,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1  batch 1 . Training Loss:  3.761277914047241\n",
            "Epoch 1  batch 101 . Training Loss:  3.7616569995880127\n",
            "Epoch 1  batch 201 . Training Loss:  3.761273145675659\n",
            "Epoch 1  batch 301 . Training Loss:  3.76131010055542\n",
            "Epoch 1  batch 401 . Training Loss:  3.761333465576172\n",
            "Epoch 1  batch 501 . Training Loss:  3.7609474658966064\n",
            "Epoch 1  batch 601 . Training Loss:  3.7609446048736572\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-74-c28cbfa44e04>\", line 6, in <cell line: 5>\n",
            "    for i, (images, labels) in enumerate(train_loader):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 631, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 675, in _next_data\n",
            "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n",
            "    data = self.dataset.__getitems__(possibly_batched_index)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\", line 399, in __getitems__\n",
            "    return [self.dataset[self.indices[idx]] for idx in indices]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\", line 399, in <listcomp>\n",
            "    return [self.dataset[self.indices[idx]] for idx in indices]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\", line 229, in __getitem__\n",
            "    sample = self.loader(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\", line 268, in default_loader\n",
            "    return pil_loader(path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\", line 247, in pil_loader\n",
            "    img = Image.open(f)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/PIL/Image.py\", line 3236, in open\n",
            "    prefix = fp.read(16)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 869, in getmodule\n",
            "    if ismodule(module) and hasattr(module, '__file__'):\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 182, in ismodule\n",
            "    def ismodule(object):\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "object of type 'NoneType' has no len()",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-74-c28cbfa44e04>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfigs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"epochs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__getitems__\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mdefault_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mpil_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3236\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2099\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2099\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2101\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2102\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Pytoch CNN Model"
      ],
      "metadata": {
        "id": "P56zhYo9d17j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.model_CNN = nn.Sequential(\n",
        "          torch.nn.Conv2d(configs['img_dimensions'][0], configs['filter_sizes'][0], configs['kernel_size'], stride = configs['stride'], padding = configs['padding']),\n",
        "          torch.nn.ReLU(),\n",
        "          torch.nn.Conv2d(configs['img_dimensions'][0], configs['filter_sizes'][0], configs['kernel_size'], stride = configs['stride'], padding = configs['padding']),\n",
        "          torch.nn.MaxPool2d(2),\n",
        "          nn.Flatten(),\n",
        "          nn.Linear(64, 43)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, configs['img_dimensions'][0], configs['img_dimnesions'][1], configs['img_dimensions'][2])\n",
        "        return self.model(X)"
      ],
      "metadata": {
        "id": "NPuUuOpYwJqo"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_CNN = MLP()\n",
        "summary(model_CNN)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wlzPTDCx-bN",
        "outputId": "08e70a26-cde4-483d-9741-2392cdb3d1b0"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "=================================================================\n",
              "Layer (type:depth-idx)                   Param #\n",
              "=================================================================\n",
              "MLP                                      --\n",
              "├─Sequential: 1-1                        --\n",
              "│    └─Conv2d: 2-1                       304\n",
              "│    └─ReLU: 2-2                         --\n",
              "│    └─Conv2d: 2-3                       304\n",
              "│    └─MaxPool2d: 2-4                    --\n",
              "│    └─Flatten: 2-5                      --\n",
              "│    └─Linear: 2-6                       2,795\n",
              "=================================================================\n",
              "Total params: 3,403\n",
              "Trainable params: 3,403\n",
              "Non-trainable params: 0\n",
              "================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopper = EarlyStopper(patience=7)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.3, patience=3)\n",
        "\n",
        "# Training\n",
        "for epoch in range(configs[\"epochs\"]):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        if gpu_available and use_gpu:\n",
        "          images = images.cuda()\n",
        "          labels = labels.cuda()\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criteron(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if i %100 == 0:\n",
        "          print(\"Epoch\", epoch+ 1, \" batch\", i+1, \". Training Loss: \", loss.item())\n",
        "          if enable_wandb:\n",
        "            wandb.log({\"loss\": loss})\n",
        "\n",
        "    train_acc = get_accuracy(train_loader, model)\n",
        "    test_acc = get_accuracy(val_loader, model)\n",
        "\n",
        "    validation_loss = get_loss(val_loader)\n",
        "    wandb.log({\"val_loss\": validation_loss})\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{configs[\"epochs\"]}], LR: {optimizer.param_groups[0][\"lr\"]}, Validation Loss: {validation_loss.item():.4f}, Train Accuracy: {train_acc.item():.4f}, Validation Accuracy: {test_acc.item():.4f}')\n",
        "    if enable_wandb:\n",
        "      wandb.log({\"epoch\": epoch + 1, \"LR\": {optimizer.param_groups[0]['lr']}, \"train_accuracy\": train_acc.item(), \"val_accuracy\": test_acc.item()})\n",
        "\n",
        "    scheduler.step(validation_loss)\n",
        "\n",
        "    if early_stopper.early_stop(validation_loss):\n",
        "        print(\"Validation loss hasn't dropped. Early stopping!\")\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "Q1E7GMDrx7CW",
        "outputId": "48d5fe31-71be-4f9a-c326-fdc4c70101eb"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1  batch 1 . Training Loss:  3.761180877685547\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-931afe8736a1>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfigs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"epochs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgpu_available\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0muse_gpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__getitems__\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    397\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    397\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \"\"\"\n\u001b[1;32m    228\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mdefault_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maccimage_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mpil_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0;31m# open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3234\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3236\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3238\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sources:\n",
        "\n",
        "- https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html"
      ],
      "metadata": {
        "id": "63E-98XlYngo"
      }
    }
  ]
}