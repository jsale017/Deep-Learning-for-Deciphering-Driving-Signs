{"cells":[{"cell_type":"markdown","metadata":{"id":"1VoGLxYS5erB"},"source":["# Deep Learning for Deciphering Traffic Signs\n","# CNN Notebook\n","_________________________________________________________________________________________________________________________________________________________________________________\n","\n","##### Contributors:\n"," Victor Floriano, Yifan Fan, Jose Salerno"]},{"cell_type":"markdown","metadata":{"id":"hCt1WhA35erD"},"source":["## Problem Statement & Motivation\n","As the world advances towards autonomous vehicles, our team has observed the remarkable efforts of large car manufacturers, who are working with data scientists to develop fully autonomous cars. Our team is excited to contribute to the development of this technology by creating a neural network model that will be able to classify different traffic signs. Our ultimate goal is to assist car makers in overcoming the challenges they may face in implementing neural network models that effectively read traffic signs and further their efforts toward a fully autonomous car or assisted driving. We believe autonomous driving to be an important problem to solve due to the great economic benefits it can generate for car manufacturers and the improvement of general driving safety.\n","\n","## Data Preparation\n"," We've selected the German Traffic Sign Recognition Benchmark (GTSRB) as our primary dataset. It's renowned for its complexity, featuring over 50,000 images across more than 40 classes of traffic signs. The GTSRB is publicly accessible through two resources. To efficiently manage the extensive and complex GTSRB dataset, our strategy integrates preprocessing for uniformity, data augmentation for robustness, and batch processing for computational efficiency. We'll employ distributed computing to parallelize operations, enhancing processing speed, and use stratified sampling for quick experimentation without compromising representativeness.\n","\n","\n","\n","---\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"qEsKDczS5erD"},"source":["# CNN - Models\n","\n"," The provided code outlines the construction and operation of a convolutional neural network (CNN) designed for image classification, implemented using PyTorch. The process starts with data preprocessing, where image data undergoes resizing, tensor conversion, and normalization of the training dataset.\n","\n","The CNN architecture comprises multiple layers such as batch normalization and ReLU activation functions, dropout layers, and max pooling layers. Following feature extraction, the network transitions to a classifier linear layer to create predictions across 43 classes.\n","\n","________________________________________________________________________________________________________________________________________________\n","\n","Results:\n","\n","- **Model 1: Validation Accuracy = 98.76% (Best Model)**\n","- Model 2: Validation Accuracy = 98.53%\n","- Model 3: Validation Accuracy = 97.65%\n","- Model 4: Validation Accuracy = 87.41%\n","- Model 5: Validation Accuracy = 89.38%\n","- Model 6: Validation Accuracy = 90.38%\n","\n","____________"]},{"cell_type":"code","execution_count":45,"metadata":{"id":"PfK9Ior05erD","executionInfo":{"status":"ok","timestamp":1713971057565,"user_tz":240,"elapsed":236,"user":{"displayName":"Victor Floriano","userId":"16962368443903150562"}}},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","from torch.utils.data import DataLoader, random_split\n","import tensorflow as tf\n","import os\n","import cv2\n","from PIL import Image\n","import seaborn as sns\n","import time\n","import datetime"]},{"cell_type":"code","execution_count":46,"metadata":{"id":"Z_stlqaH5erF","outputId":"a7ee5999-a04f-46b5-cec9-d7ac00779b07","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713971059274,"user_tz":240,"elapsed":1,"user":{"displayName":"Victor Floriano","userId":"16962368443903150562"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":46}],"source":["enable_wandb = True\n","use_gpu = True\n","gpu_available = torch.cuda.is_available()\n","gpu_available"]},{"cell_type":"code","execution_count":47,"metadata":{"id":"PbvBdtcE5erF","executionInfo":{"status":"ok","timestamp":1713971065780,"user_tz":240,"elapsed":5161,"user":{"displayName":"Victor Floriano","userId":"16962368443903150562"}}},"outputs":[],"source":["if enable_wandb:\n","  !pip install wandb -qU\n","  import wandb\n","  wandb.login()"]},{"cell_type":"code","source":["!unzip /content/Train.zip"],"metadata":{"id":"co0rEMh05_kL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!unzip /content/Test_organized.zip"],"metadata":{"id":"Jl9U9pTk6JC0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t1_mRxBrBq98"},"source":["### Data"]},{"cell_type":"code","execution_count":48,"metadata":{"id":"jN_mrcs85erF","outputId":"017b134b-01d7-446b-b732-925d393e1bd2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713971071107,"user_tz":240,"elapsed":152,"user":{"displayName":"Victor Floriano","userId":"16962368443903150562"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["{'00': 210, '01': 2220, '02': 2250, '03': 1410, '04': 1980, '05': 1860, '06': 430, '07': 1440, '08': 1410, '09': 1470, '10': 2010, '11': 1320, '12': 2100, '13': 2160, '14': 780, '15': 630, '16': 420, '17': 1110, '18': 1200, '19': 210, '20': 360, '21': 330, '22': 390, '23': 510, '24': 270, '25': 1500, '26': 600, '27': 240, '28': 540, '29': 270, '30': 450, '31': 780, '32': 240, '33': 689, '34': 420, '35': 1200, '36': 390, '37': 210, '38': 2070, '39': 300, '40': 360, '41': 240, '42': 240}\n","Total images across all categories for training: 39219\n"]}],"source":["import os\n","\n","def count_images_per_category(directory):\n","    category_image_count = {}\n","\n","    # Iterate over each item in the specified directory.\n","    for category in os.listdir(directory):\n","        category_path = os.path.join(directory, category)\n","\n","        # Check if the current path is a directory.\n","        if os.path.isdir(category_path):\n","            num_images = len([item for item in os.listdir(category_path) if item.endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))])\n","            category_image_count[category] = num_images\n","\n","    return category_image_count\n","\n","dataset_directory = 'Train'\n","image_counts = count_images_per_category(dataset_directory)\n","# Sort the categories numerically\n","sorted_train = {key: image_counts[key] for key in sorted(image_counts.keys(), key=lambda x: int(x))}\n","print(sorted_train)\n","\n","# Calculate the total number of images across all categories\n","total_train = sum(sorted_train.values())\n","print(f\"Total images across all categories for training: {total_train}\")"]},{"cell_type":"code","execution_count":49,"metadata":{"id":"JQjYAgy05erF","outputId":"41a320ac-4c6f-4ebc-e285-29a10186bb80","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713971073097,"user_tz":240,"elapsed":209,"user":{"displayName":"Victor Floriano","userId":"16962368443903150562"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["{'00': 60, '01': 719, '02': 750, '03': 450, '04': 660, '05': 630, '06': 150, '07': 450, '08': 450, '09': 480, '10': 659, '11': 420, '12': 690, '13': 720, '14': 270, '15': 210, '16': 150, '17': 360, '18': 389, '19': 60, '20': 90, '21': 90, '22': 120, '23': 150, '24': 90, '25': 479, '26': 180, '27': 60, '28': 150, '29': 90, '30': 150, '31': 270, '32': 60, '33': 209, '34': 120, '35': 390, '36': 120, '37': 60, '38': 690, '39': 90, '40': 90, '41': 60, '42': 90}\n","Total images across all categories for testing: 12625\n"]}],"source":["dataset_directory = 'Test_organized'\n","image_counts = count_images_per_category(dataset_directory)\n","sorted_test = {key: image_counts[key] for key in sorted(image_counts.keys(), key=lambda x: int(x))}\n","\n","print(sorted_test)\n","total_test = sum(sorted_test.values())\n","print(f\"Total images across all categories for testing: {total_test}\")"]},{"cell_type":"code","execution_count":50,"metadata":{"id":"yCY9iyo85erF","executionInfo":{"status":"ok","timestamp":1713971075928,"user_tz":240,"elapsed":375,"user":{"displayName":"Victor Floriano","userId":"16962368443903150562"}}},"outputs":[],"source":["from torchvision.datasets import ImageFolder\n","from torchvision import transforms\n","\n","train_transforms = transforms.Compose([\n","    transforms.Resize((32,32)),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.3337, 0.3064, 0.3171), (0.2672, 0.2564, 0.2629))\n","])\n","\n","dataset_train = ImageFolder(\n","    'Train',\n","    transform = train_transforms\n",")\n","dataset_test = ImageFolder(\n","    'Test_organized',\n","    transform = train_transforms\n",")"]},{"cell_type":"code","execution_count":51,"metadata":{"id":"vC9D4yTsTbVH","executionInfo":{"status":"ok","timestamp":1713971077437,"user_tz":240,"elapsed":179,"user":{"displayName":"Victor Floriano","userId":"16962368443903150562"}}},"outputs":[],"source":["train_data, val_data = random_split(dataset_train, [0.8, 0.2])"]},{"cell_type":"markdown","metadata":{"id":"L8My4yFsBugm"},"source":["### CNN Model - 1"]},{"cell_type":"markdown","metadata":{"id":"k1H2ljoy5erG"},"source":["- Epochs = 100\n","- Batch size = 64\n","- Learning Rates = 0.001\n","- No Data Agumentation\n","- No Class Balancing\n","- Early Stopping Patience 5"]},{"cell_type":"code","execution_count":91,"metadata":{"scrolled":true,"id":"LkA5Fo195erG","outputId":"36226464-a54d-425b-d760-be162a087712","colab":{"base_uri":"https://localhost:8080/","height":125},"executionInfo":{"status":"ok","timestamp":1713972826645,"user_tz":240,"elapsed":2733,"user":{"displayName":"Victor Floriano","userId":"16962368443903150562"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.16.6"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20240424_153343-8hpw5y0e</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/victorgfloriano/Project%20CNN_v1/runs/8hpw5y0e' target=\"_blank\">experiment_v1</a></strong> to <a href='https://wandb.ai/victorgfloriano/Project%20CNN_v1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/victorgfloriano/Project%20CNN_v1' target=\"_blank\">https://wandb.ai/victorgfloriano/Project%20CNN_v1</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/victorgfloriano/Project%20CNN_v1/runs/8hpw5y0e' target=\"_blank\">https://wandb.ai/victorgfloriano/Project%20CNN_v1/runs/8hpw5y0e</a>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/victorgfloriano/Project%20CNN_v1/runs/8hpw5y0e?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x784ae3989750>"]},"metadata":{},"execution_count":91}],"source":["wandb.init(project=\"Project CNN_v1\", name = 'experiment_v1')"]},{"cell_type":"code","execution_count":92,"metadata":{"id":"EmhpUuKY5erG","executionInfo":{"status":"ok","timestamp":1713972826645,"user_tz":240,"elapsed":1,"user":{"displayName":"Victor Floriano","userId":"16962368443903150562"}}},"outputs":[],"source":["train_loader = DataLoader(train_data, batch_size=64, shuffle=True, num_workers=2)\n","val_loader = DataLoader(val_data, batch_size=64, shuffle=False, num_workers=2)\n","test_loader = DataLoader(dataset_test, shuffle=True, batch_size = 64, num_workers = 2)"]},{"cell_type":"code","execution_count":93,"metadata":{"id":"EL-scXGS6Ocj","executionInfo":{"status":"ok","timestamp":1713972827601,"user_tz":240,"elapsed":1,"user":{"displayName":"Victor Floriano","userId":"16962368443903150562"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchsummary import summary\n","\n","\n","class Net(nn.Module):\n","    def __init__(self, num_classes):\n","        super().__init__()\n","        # Feature extraction layers\n","        self.features = nn.Sequential(\n","            # First convolutional layer taking 3 input channels (RGB image) and outputting 64 feature maps\n","            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=2, padding=1),\n","            nn.BatchNorm2d(64),  # Normalize the output of the previous layer to improve training speed and stability\n","            nn.ReLU(inplace=True),  # Non-linear activation function (ReLU)\n","            nn.Dropout2d(0.2),  # Dropout to prevent overfitting by randomly zeroing some of the elements of the input tensor\n","\n","            nn.MaxPool2d(kernel_size=2),  # Max pooling with a kernel size of 2 to reduce spatial dimensions\n","            # Second convolutional layer, increasing the depth to 192\n","            nn.Conv2d(in_channels=64, out_channels=192, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(192),  # Batch normalization\n","            nn.ReLU(inplace=True),  # ReLU activation\n","            nn.Dropout2d(0.3),  # Increasing dropout rate for more regularization\n","\n","            nn.MaxPool2d(kernel_size=2),  # Another max pooling step\n","            # Third convolutional layer with increased depth to 384\n","            nn.Conv2d(in_channels=192, out_channels=384, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(384),  # Batch normalization\n","            nn.ReLU(inplace=True),  # ReLU activation\n","            nn.Dropout2d(0.4),  # Further increase in dropout for regularization\n","\n","            # Fourth convolutional layer maintaining depth at 256\n","            nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(256),  # Batch normalization\n","            nn.ReLU(inplace=True),  # ReLU activation\n","\n","            # Fifth convolutional layer also at 256 depth\n","            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(256),  # Batch normalization\n","            nn.ReLU(inplace=True),  # ReLU activation\n","            nn.MaxPool2d(kernel_size=2),  # Max pooling\n","            nn.Dropout2d(0.5)  # Final dropout layer to maximize regularization before classification\n","            )\n","\n","        # Classification layers\n","        self.classifier = nn.Sequential(\n","            nn.Dropout(0.5),  # Dropout before any dense layers\n","            nn.Linear(256 * 2 * 2, 1000),  # Fully connected layer reducing dimensionality to 1000\n","            nn.ReLU(inplace=True),  # ReLU activation\n","            nn.Dropout(0.5),  # Additional dropout for regularization\n","            nn.Linear(in_features=1000, out_features=256),  # Further reducing dimensionality to 256\n","            nn.ReLU(inplace=True),  # ReLU activation\n","            nn.Linear(256, num_classes)  # Final output layer with number of classes as output size\n","            )\n","\n","    def forward(self, x):\n","        # Forward pass definition\n","        x = self.features(x)  # Apply feature extractor\n","        x = x.view(x.size(0), -1)  # Flatten the output of the convolutional layers\n","        x = self.classifier(x)  # Apply classifier\n","        return x\n"]},{"cell_type":"code","execution_count":94,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9jEd8x08Iasw","outputId":"2834bf5e-4d6e-442a-9cbc-9a440c62eb71","executionInfo":{"status":"ok","timestamp":1713972830461,"user_tz":240,"elapsed":437,"user":{"displayName":"Victor Floriano","userId":"16962368443903150562"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 64, 16, 16]           1,792\n","       BatchNorm2d-2           [-1, 64, 16, 16]             128\n","              ReLU-3           [-1, 64, 16, 16]               0\n","         Dropout2d-4           [-1, 64, 16, 16]               0\n","         MaxPool2d-5             [-1, 64, 8, 8]               0\n","            Conv2d-6            [-1, 192, 8, 8]         110,784\n","       BatchNorm2d-7            [-1, 192, 8, 8]             384\n","              ReLU-8            [-1, 192, 8, 8]               0\n","         Dropout2d-9            [-1, 192, 8, 8]               0\n","        MaxPool2d-10            [-1, 192, 4, 4]               0\n","           Conv2d-11            [-1, 384, 4, 4]         663,936\n","      BatchNorm2d-12            [-1, 384, 4, 4]             768\n","             ReLU-13            [-1, 384, 4, 4]               0\n","        Dropout2d-14            [-1, 384, 4, 4]               0\n","           Conv2d-15            [-1, 256, 4, 4]         884,992\n","      BatchNorm2d-16            [-1, 256, 4, 4]             512\n","             ReLU-17            [-1, 256, 4, 4]               0\n","           Conv2d-18            [-1, 256, 4, 4]         590,080\n","      BatchNorm2d-19            [-1, 256, 4, 4]             512\n","             ReLU-20            [-1, 256, 4, 4]               0\n","        MaxPool2d-21            [-1, 256, 2, 2]               0\n","        Dropout2d-22            [-1, 256, 2, 2]               0\n","          Dropout-23                 [-1, 1024]               0\n","           Linear-24                 [-1, 1000]       1,025,000\n","             ReLU-25                 [-1, 1000]               0\n","          Dropout-26                 [-1, 1000]               0\n","           Linear-27                  [-1, 256]         256,256\n","             ReLU-28                  [-1, 256]               0\n","           Linear-29                   [-1, 43]          11,051\n","================================================================\n","Total params: 3,546,195\n","Trainable params: 3,546,195\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.01\n","Forward/backward pass size (MB): 1.36\n","Params size (MB): 13.53\n","Estimated Total Size (MB): 14.89\n","----------------------------------------------------------------\n"]}],"source":["net = Net(num_classes=43)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","net.to(device)\n","\n","# Print a summary of the network; this shows the architecture and parameter count for an input size of (3, 32, 32)\n","summary(net,(3,32,32))"]},{"cell_type":"code","execution_count":95,"metadata":{"id":"LGlz1GGL5erH","executionInfo":{"status":"ok","timestamp":1713972832730,"user_tz":240,"elapsed":2,"user":{"displayName":"Victor Floriano","userId":"16962368443903150562"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"40737753-f24d-4ecc-9885-7f3477fda1e4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[]"]},"metadata":{},"execution_count":95}],"source":["wandb.config.update({\n","    \"learning_rate\": 0.001,\n","    \"epochs\": 100,\n","    \"batch_size\": 64\n","})\n","wandb.watch(net)"]},{"cell_type":"code","execution_count":96,"metadata":{"id":"UbY4EQAuMcZp","executionInfo":{"status":"ok","timestamp":1713972834238,"user_tz":240,"elapsed":133,"user":{"displayName":"Victor Floriano","userId":"16962368443903150562"}}},"outputs":[],"source":["class EarlyStopper:\n","    def __init__(self, patience=1, delta=0):\n","        # Initialization of the EarlyStopper\n","        self.patience = patience  # Number of epochs with no improvement after which training will be stopped\n","        self.delta = delta  # Minimum change in the monitored quantity to qualify as an improvement\n","        self.counter = 0  # Counter for the epochs with no improvement\n","        self.min_validation_loss = float('inf')  # Initialize the minimum validation loss as infinity\n","        self.best_model = None  # To store the best model's weights\n","\n","    def early_stop(self, validation_loss, model):\n","        # Check if early stopping is needed\n","        if validation_loss < self.min_validation_loss - self.delta:\n","            # Improvement found, update minimum loss and reset counter\n","            self.min_validation_loss = validation_loss  # Update the minimum validation loss\n","            self.counter = 0  # Reset the no-improvement counter\n","            self.best_model = model.state_dict()  # Save the current best model's weights\n","        elif validation_loss >= self.min_validation_loss - self.delta:\n","            # No improvement, increment the counter\n","            self.counter += 1  # Increment the no-improvement counter\n","            if self.counter >= self.patience:\n","                # Patience exceeded, load the best model and stop training\n","                model.load_state_dict(self.best_model)  # Load the best model's state\n","                return True  # Return True to indicate that training should stop\n","        return False  # Return False to indicate that training should continue\n"]},{"cell_type":"code","execution_count":97,"metadata":{"id":"4nYeXugSSTCA","executionInfo":{"status":"ok","timestamp":1713972835192,"user_tz":240,"elapsed":1,"user":{"displayName":"Victor Floriano","userId":"16962368443903150562"}}},"outputs":[],"source":["def get_loss(loader, model, criterion, device):\n","    model.eval()\n","    total_loss = 0\n","    with torch.no_grad():\n","        for images, labels in loader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            total_loss += loss.item()  # Sum up batch loss\n","\n","    average_loss = total_loss / len(loader)\n","    return average_loss\n"]},{"cell_type":"code","execution_count":98,"metadata":{"id":"BZ6KLxmTSYJk","executionInfo":{"status":"ok","timestamp":1713972836139,"user_tz":240,"elapsed":233,"user":{"displayName":"Victor Floriano","userId":"16962368443903150562"}}},"outputs":[],"source":["def get_accuracy(dataloader, model, device):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for images, labels in dataloader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    accuracy = 100 * correct / total\n","    return accuracy"]},{"cell_type":"code","execution_count":99,"metadata":{"id":"cu1wauFWRqhM","executionInfo":{"status":"ok","timestamp":1713972837223,"user_tz":240,"elapsed":1,"user":{"displayName":"Victor Floriano","userId":"16962368443903150562"}}},"outputs":[],"source":["optimizer = optim.Adam(net.parameters(), lr=0.001)\n","criterion = nn.CrossEntropyLoss()\n","early_stopping = EarlyStopper(patience=5,delta = 0.01)"]},{"cell_type":"code","execution_count":100,"metadata":{"colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["38ae9d00cd8649dd913e21037008ff26","ba31b910bd4745fb8d8b490030dd970b","f30483a27c054f3f8830282f8cb182bc","fb8b87863b60462a87fb7ecf3d5e5f68","0a6e09ef92694d5b8a4ff59ab2b536b5","e836384c18e5469d9f23774753023dee","818512302e4a4b909976482afd56a7a0","26071e393c524cd1b2e76e65d191fabd"],"height":1000},"id":"UVXEYoxVRqeC","outputId":"72d0b6e1-b171-4171-e3e5-e59d6c5fdbec","scrolled":true,"executionInfo":{"status":"ok","timestamp":1713973243267,"user_tz":240,"elapsed":405472,"user":{"displayName":"Victor Floriano","userId":"16962368443903150562"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1  batch 1 . Training Loss:  3.696920871734619\n","Epoch 1  batch 101 . Training Loss:  3.1744184494018555\n","Epoch 1  batch 201 . Training Loss:  3.0203185081481934\n","Epoch 1  batch 301 . Training Loss:  2.815922260284424\n","Epoch 1  batch 401 . Training Loss:  2.525054693222046\n","Epoch 1: Validation Loss: 1.9124, Validation Accuracy: 35.92%\n","Epoch 2  batch 1 . Training Loss:  2.0229153633117676\n","Epoch 2  batch 101 . Training Loss:  1.6457794904708862\n","Epoch 2  batch 201 . Training Loss:  1.7703094482421875\n","Epoch 2  batch 301 . Training Loss:  1.6460280418395996\n","Epoch 2  batch 401 . Training Loss:  1.9861725568771362\n","Epoch 2: Validation Loss: 1.2125, Validation Accuracy: 57.52%\n","Epoch 3  batch 1 . Training Loss:  1.453515648841858\n","Epoch 3  batch 101 . Training Loss:  1.6804370880126953\n","Epoch 3  batch 201 . Training Loss:  1.583146095275879\n","Epoch 3  batch 301 . Training Loss:  1.3356252908706665\n","Epoch 3  batch 401 . Training Loss:  1.3111017942428589\n","Epoch 3: Validation Loss: 0.8751, Validation Accuracy: 69.35%\n","Epoch 4  batch 1 . Training Loss:  1.1398388147354126\n","Epoch 4  batch 101 . Training Loss:  0.9318063259124756\n","Epoch 4  batch 201 . Training Loss:  0.9253420829772949\n","Epoch 4  batch 301 . Training Loss:  1.1513193845748901\n","Epoch 4  batch 401 . Training Loss:  1.0081615447998047\n","Epoch 4: Validation Loss: 0.5042, Validation Accuracy: 81.77%\n","Epoch 5  batch 1 . Training Loss:  0.45618197321891785\n","Epoch 5  batch 101 . Training Loss:  0.7901325821876526\n","Epoch 5  batch 201 . Training Loss:  0.589356541633606\n","Epoch 5  batch 301 . Training Loss:  0.674032986164093\n","Epoch 5  batch 401 . Training Loss:  0.7226442098617554\n","Epoch 5: Validation Loss: 0.3754, Validation Accuracy: 84.62%\n","Epoch 6  batch 1 . Training Loss:  0.6011731624603271\n","Epoch 6  batch 101 . Training Loss:  0.49118998646736145\n","Epoch 6  batch 201 . Training Loss:  0.431138277053833\n","Epoch 6  batch 301 . Training Loss:  0.2565695643424988\n","Epoch 6  batch 401 . Training Loss:  0.4611890912055969\n","Epoch 6: Validation Loss: 0.2534, Validation Accuracy: 91.27%\n","Epoch 7  batch 1 . Training Loss:  0.35756975412368774\n","Epoch 7  batch 101 . Training Loss:  0.4354499578475952\n","Epoch 7  batch 201 . Training Loss:  0.4484542906284332\n","Epoch 7  batch 301 . Training Loss:  0.49121642112731934\n","Epoch 7  batch 401 . Training Loss:  0.5291730761528015\n","Epoch 7: Validation Loss: 0.1846, Validation Accuracy: 94.22%\n","Epoch 8  batch 1 . Training Loss:  0.3046501576900482\n","Epoch 8  batch 101 . Training Loss:  0.4130648076534271\n","Epoch 8  batch 201 . Training Loss:  0.45214247703552246\n","Epoch 8  batch 301 . Training Loss:  0.27193328738212585\n","Epoch 8  batch 401 . Training Loss:  0.24361556768417358\n","Epoch 8: Validation Loss: 0.1884, Validation Accuracy: 94.07%\n","Epoch 9  batch 1 . Training Loss:  0.5050526857376099\n","Epoch 9  batch 101 . Training Loss:  0.22162088751792908\n","Epoch 9  batch 201 . Training Loss:  0.25851869583129883\n","Epoch 9  batch 301 . Training Loss:  0.4802418053150177\n","Epoch 9  batch 401 . Training Loss:  0.2177807241678238\n","Epoch 9: Validation Loss: 0.1322, Validation Accuracy: 95.87%\n","Epoch 10  batch 1 . Training Loss:  0.33222177624702454\n","Epoch 10  batch 101 . Training Loss:  0.30974701046943665\n","Epoch 10  batch 201 . Training Loss:  0.06313122808933258\n","Epoch 10  batch 301 . Training Loss:  0.48205670714378357\n","Epoch 10  batch 401 . Training Loss:  0.2812913656234741\n","Epoch 10: Validation Loss: 0.1141, Validation Accuracy: 96.34%\n","Epoch 11  batch 1 . Training Loss:  0.22060008347034454\n","Epoch 11  batch 101 . Training Loss:  0.15127603709697723\n","Epoch 11  batch 201 . Training Loss:  0.1681734174489975\n","Epoch 11  batch 301 . Training Loss:  0.21948835253715515\n","Epoch 11  batch 401 . Training Loss:  0.3726932406425476\n","Epoch 11: Validation Loss: 0.0860, Validation Accuracy: 97.45%\n","Epoch 12  batch 1 . Training Loss:  0.13215628266334534\n","Epoch 12  batch 101 . Training Loss:  0.2332918643951416\n","Epoch 12  batch 201 . Training Loss:  0.06052933633327484\n","Epoch 12  batch 301 . Training Loss:  0.25585663318634033\n","Epoch 12  batch 401 . Training Loss:  0.215154767036438\n","Epoch 12: Validation Loss: 0.0760, Validation Accuracy: 97.67%\n","Epoch 13  batch 1 . Training Loss:  0.15956024825572968\n","Epoch 13  batch 101 . Training Loss:  0.28099873661994934\n","Epoch 13  batch 201 . Training Loss:  0.2132466733455658\n","Epoch 13  batch 301 . Training Loss:  0.1036614328622818\n","Epoch 13  batch 401 . Training Loss:  0.0800357535481453\n","Epoch 13: Validation Loss: 0.0845, Validation Accuracy: 97.36%\n","Epoch 14  batch 1 . Training Loss:  0.2419237494468689\n","Epoch 14  batch 101 . Training Loss:  0.20770426094532013\n","Epoch 14  batch 201 . Training Loss:  0.02976870723068714\n","Epoch 14  batch 301 . Training Loss:  0.3088444769382477\n","Epoch 14  batch 401 . Training Loss:  0.19342489540576935\n","Epoch 14: Validation Loss: 0.0891, Validation Accuracy: 97.35%\n","Epoch 15  batch 1 . Training Loss:  0.08080492168664932\n","Epoch 15  batch 101 . Training Loss:  0.16611522436141968\n","Epoch 15  batch 201 . Training Loss:  0.2051832526922226\n","Epoch 15  batch 301 . Training Loss:  0.2154054194688797\n","Epoch 15  batch 401 . Training Loss:  0.1562059074640274\n","Epoch 15: Validation Loss: 0.0823, Validation Accuracy: 97.53%\n","Epoch 16  batch 1 . Training Loss:  0.2333785593509674\n","Epoch 16  batch 101 . Training Loss:  0.03020981326699257\n","Epoch 16  batch 201 . Training Loss:  0.08533217012882233\n","Epoch 16  batch 301 . Training Loss:  0.16358935832977295\n","Epoch 16  batch 401 . Training Loss:  0.12220724672079086\n","Epoch 16: Validation Loss: 0.0681, Validation Accuracy: 97.93%\n","Epoch 17  batch 1 . Training Loss:  0.16471277177333832\n","Epoch 17  batch 101 . Training Loss:  0.08739707618951797\n","Epoch 17  batch 201 . Training Loss:  0.09534446895122528\n","Epoch 17  batch 301 . Training Loss:  0.3530738353729248\n","Epoch 17  batch 401 . Training Loss:  0.24488934874534607\n","Epoch 17: Validation Loss: 0.0667, Validation Accuracy: 98.07%\n","Epoch 18  batch 1 . Training Loss:  0.10670783370733261\n","Epoch 18  batch 101 . Training Loss:  0.1663467288017273\n","Epoch 18  batch 201 . Training Loss:  0.041562821716070175\n","Epoch 18  batch 301 . Training Loss:  0.2181161642074585\n","Epoch 18  batch 401 . Training Loss:  0.11655335128307343\n","Epoch 18: Validation Loss: 0.0529, Validation Accuracy: 98.32%\n","Epoch 19  batch 1 . Training Loss:  0.13161568343639374\n","Epoch 19  batch 101 . Training Loss:  0.17359468340873718\n","Epoch 19  batch 201 . Training Loss:  0.3049007058143616\n","Epoch 19  batch 301 . Training Loss:  0.11975504457950592\n","Epoch 19  batch 401 . Training Loss:  0.1011991873383522\n","Epoch 19: Validation Loss: 0.0487, Validation Accuracy: 98.70%\n","Epoch 20  batch 1 . Training Loss:  0.06394661962985992\n","Epoch 20  batch 101 . Training Loss:  0.1461363136768341\n","Epoch 20  batch 201 . Training Loss:  0.14762923121452332\n","Epoch 20  batch 301 . Training Loss:  0.027923855930566788\n","Epoch 20  batch 401 . Training Loss:  0.14416974782943726\n","Epoch 20: Validation Loss: 0.0512, Validation Accuracy: 98.50%\n","Epoch 21  batch 1 . Training Loss:  0.04536397010087967\n","Epoch 21  batch 101 . Training Loss:  0.17745308578014374\n","Epoch 21  batch 201 . Training Loss:  0.23637917637825012\n","Epoch 21  batch 301 . Training Loss:  0.07169310748577118\n","Epoch 21  batch 401 . Training Loss:  0.09276721626520157\n","Epoch 21: Validation Loss: 0.0646, Validation Accuracy: 98.15%\n","Epoch 22  batch 1 . Training Loss:  0.2559506595134735\n","Epoch 22  batch 101 . Training Loss:  0.046293098479509354\n","Epoch 22  batch 201 . Training Loss:  0.0670383870601654\n","Epoch 22  batch 301 . Training Loss:  0.0415114164352417\n","Epoch 22  batch 401 . Training Loss:  0.1505092829465866\n","Epoch 22: Validation Loss: 0.0407, Validation Accuracy: 98.84%\n","Epoch 23  batch 1 . Training Loss:  0.09878065437078476\n","Epoch 23  batch 101 . Training Loss:  0.03685140609741211\n","Epoch 23  batch 201 . Training Loss:  0.05667240917682648\n","Epoch 23  batch 301 . Training Loss:  0.05112443119287491\n","Epoch 23  batch 401 . Training Loss:  0.07266166061162949\n","Epoch 23: Validation Loss: 0.0449, Validation Accuracy: 98.75%\n","Epoch 24  batch 1 . Training Loss:  0.0645069107413292\n","Epoch 24  batch 101 . Training Loss:  0.08112525194883347\n","Epoch 24  batch 201 . Training Loss:  0.03842124342918396\n","Epoch 24  batch 301 . Training Loss:  0.06317681819200516\n","Epoch 24  batch 401 . Training Loss:  0.04033403843641281\n","Epoch 24: Validation Loss: 0.0457, Validation Accuracy: 98.78%\n","Epoch 25  batch 1 . Training Loss:  0.21271991729736328\n","Epoch 25  batch 101 . Training Loss:  0.05048790201544762\n","Epoch 25  batch 201 . Training Loss:  0.0771411657333374\n","Epoch 25  batch 301 . Training Loss:  0.15597665309906006\n","Epoch 25  batch 401 . Training Loss:  0.11091665923595428\n","Epoch 25: Validation Loss: 0.0475, Validation Accuracy: 98.78%\n","Epoch 26  batch 1 . Training Loss:  0.0931238979101181\n","Epoch 26  batch 101 . Training Loss:  0.019178977236151695\n","Epoch 26  batch 201 . Training Loss:  0.15507234632968903\n","Epoch 26  batch 301 . Training Loss:  0.12916548550128937\n","Epoch 26  batch 401 . Training Loss:  0.046725351363420486\n","Epoch 26: Validation Loss: 0.0398, Validation Accuracy: 98.88%\n","Epoch 27  batch 1 . Training Loss:  0.16180504858493805\n","Epoch 27  batch 101 . Training Loss:  0.0821133404970169\n","Epoch 27  batch 201 . Training Loss:  0.030361250042915344\n","Epoch 27  batch 301 . Training Loss:  0.010234770365059376\n","Epoch 27  batch 401 . Training Loss:  0.0047821588814258575\n","Epoch 27: Validation Loss: 0.0458, Validation Accuracy: 98.76%\n","Early stopping triggered.\n"]},{"output_type":"display_data","data":{"text/plain":["VBox(children=(Label(value='0.003 MB of 0.003 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38ae9d00cd8649dd913e21037008ff26"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>█▇▅▅▄▃▃▂▂▂▂▂▁▂▁▁▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▆▄▃▃▃▂▂▂▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.00478</td></tr><tr><td>train_loss</td><td>0.66854</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">experiment_v1</strong> at: <a href='https://wandb.ai/victorgfloriano/Project%20CNN_v1/runs/8hpw5y0e' target=\"_blank\">https://wandb.ai/victorgfloriano/Project%20CNN_v1/runs/8hpw5y0e</a><br/> View project at: <a href='https://wandb.ai/victorgfloriano/Project%20CNN_v1' target=\"_blank\">https://wandb.ai/victorgfloriano/Project%20CNN_v1</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20240424_153343-8hpw5y0e/logs</code>"]},"metadata":{}}],"source":["epochs = 100\n","model = net\n","for epoch in range(epochs):\n","    # Training phase\n","    model.train()  # Set the model to training mode (activates dropout, batch norm etc.)\n","    for i, (images, labels) in enumerate(train_loader):  # Iterate over batches of data from the training loader\n","        images, labels = images.to(device), labels.to(device)  # Move the data to the appropriate device (GPU or CPU)\n","        optimizer.zero_grad()  # Clear the gradients of all optimized variables\n","        outputs = model(images)  # Forward pass: compute predicted outputs by passing inputs to the model\n","        loss = criterion(outputs, labels)  # Calculate the batch's loss using the defined loss criterion\n","        loss.backward()  # Backward pass: compute gradient of the loss with respect to model parameters\n","        optimizer.step()  # Perform a single optimization step (parameter update)\n","\n","        if i % 100 == 0:  # Every 100 batches, print the training loss\n","           print(\"Epoch\", epoch + 1, \" batch\", i + 1, \". Training Loss: \", loss.item())  # Display the current epoch, batch, and loss\n","           if enable_wandb:\n","            wandb.log({\"loss\": loss})\n","        wandb.log({\"train_loss\":loss.item()})\n","\n","    # Validation phase\n","    model.eval()  # Set the model to evaluation mode (deactivates dropout, batch norm etc.)\n","    validation_loss = get_loss(val_loader, model, criterion, device)  # Compute the total loss over all validation data\n","    validation_accuracy = get_accuracy(val_loader, model, device)  # Compute the accuracy over all validation data\n","\n","    print(f'Epoch {epoch+1}: Validation Loss: {validation_loss:.4f}, Validation Accuracy: {validation_accuracy:.2f}%')  # Display validation results\n","\n","    # Check for early stopping\n","    if early_stopping.early_stop(validation_loss, model):  # If the early stopping condition is met\n","        print(\"Early stopping triggered.\")  # Print a message indicating that early stopping has been triggered\n","        break  # Exit the training loop\n","wandb.finish()\n"]},{"cell_type":"markdown","metadata":{"id":"CYQmq5FORqbI"},"source":["------------------------------------------------------------------------"]},{"cell_type":"markdown","metadata":{"id":"21rOVvnYRqV5"},"source":["### CNN Model - 2"]},{"cell_type":"markdown","metadata":{"id":"5FVKIU5j5erI"},"source":["- Epochs = 25\n","- Batch size = 128\n","- Learning Rates = 0.001\n","- No Data Agumentation\n","- No Class Balancing\n","- Early Stopping Patience 5"]},{"cell_type":"code","execution_count":85,"metadata":{"id":"mfTZpdJvRqTC","outputId":"c124a3c0-b4b1-4359-afef-98310e32f273","colab":{"base_uri":"https://localhost:8080/","height":125},"executionInfo":{"status":"ok","timestamp":1713972490857,"user_tz":240,"elapsed":13197,"user":{"displayName":"Victor Floriano","userId":"16962368443903150562"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.16.6"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20240424_152757-1bdju16m</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/victorgfloriano/Project%20CNN_v1/runs/1bdju16m' target=\"_blank\">experiment_v2</a></strong> to <a href='https://wandb.ai/victorgfloriano/Project%20CNN_v1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/victorgfloriano/Project%20CNN_v1' target=\"_blank\">https://wandb.ai/victorgfloriano/Project%20CNN_v1</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/victorgfloriano/Project%20CNN_v1/runs/1bdju16m' target=\"_blank\">https://wandb.ai/victorgfloriano/Project%20CNN_v1/runs/1bdju16m</a>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/victorgfloriano/Project%20CNN_v1/runs/1bdju16m?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x784c82911e10>"]},"metadata":{},"execution_count":85}],"source":["wandb.init(project=\"Project CNN_v1\", name = 'experiment_v2')"]},{"cell_type":"code","execution_count":86,"metadata":{"id":"uIMFwutlRqPs","executionInfo":{"status":"ok","timestamp":1713972490857,"user_tz":240,"elapsed":2,"user":{"displayName":"Victor Floriano","userId":"16962368443903150562"}}},"outputs":[],"source":["wandb.config.update({\n","    \"learning_rate\": 0.001,\n","    \"epochs\": 25,\n","    \"batch_size\": 128\n","})\n","#wandb.watch(net)"]},{"cell_type":"code","execution_count":87,"metadata":{"id":"mEVjteRa5erI","executionInfo":{"status":"ok","timestamp":1713972490857,"user_tz":240,"elapsed":2,"user":{"displayName":"Victor Floriano","userId":"16962368443903150562"}}},"outputs":[],"source":["train_loader = DataLoader(train_data, batch_size=128, shuffle=True, num_workers=2)\n","val_loader = DataLoader(val_data, batch_size=128, shuffle=False, num_workers=2)\n","test_loader = DataLoader(dataset_test, shuffle=True, batch_size = 128, num_workers = 2)"]},{"cell_type":"code","execution_count":88,"metadata":{"id":"xXFumPLO5erI","outputId":"20f6903f-1862-4465-bfb6-ee136330612f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713972490857,"user_tz":240,"elapsed":2,"user":{"displayName":"Victor Floriano","userId":"16962368443903150562"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Net(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","    (3): Dropout2d(p=0.2, inplace=False)\n","    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (5): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (6): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (7): ReLU(inplace=True)\n","    (8): Dropout2d(p=0.3, inplace=False)\n","    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (10): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (12): ReLU(inplace=True)\n","    (13): Dropout2d(p=0.4, inplace=False)\n","    (14): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (16): ReLU(inplace=True)\n","    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (19): ReLU(inplace=True)\n","    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (21): Dropout2d(p=0.5, inplace=False)\n","  )\n","  (classifier): Sequential(\n","    (0): Dropout(p=0.5, inplace=False)\n","    (1): Linear(in_features=1024, out_features=1000, bias=True)\n","    (2): ReLU(inplace=True)\n","    (3): Dropout(p=0.5, inplace=False)\n","    (4): Linear(in_features=1000, out_features=256, bias=True)\n","    (5): ReLU(inplace=True)\n","    (6): Linear(in_features=256, out_features=43, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":88}],"source":["net1 = Net(num_classes=43)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","net1.to(device)"]},{"cell_type":"code","execution_count":89,"metadata":{"id":"RU3tRoI25erI","executionInfo":{"status":"ok","timestamp":1713972490857,"user_tz":240,"elapsed":2,"user":{"displayName":"Victor Floriano","userId":"16962368443903150562"}}},"outputs":[],"source":["optimizer = optim.Adam(net1.parameters(), lr=0.001)\n","criterion = nn.CrossEntropyLoss()\n","early_stopping = EarlyStopper(patience=5,delta = 0.01)"]},{"cell_type":"code","execution_count":90,"metadata":{"id":"nZ3pCZQ7RqM9","outputId":"81e2624b-3fb8-40ae-f509-02b19449f548","colab":{"referenced_widgets":["6dccedb9018843bc8095d85ffaeac36a","035febd0690f420ca196cdd72d3e0df4","92a9b1f5a61a4eb8b8c95755a8152a5d","7fa2da7993be48978c35ab09f63fa975","1526d043e3cf4a2ba3fcc7192f23af25","b0f6dde0665c4d6580aa3f08ca2f8e92","eaa76a2263fc468a8bff4116c5fce39e","a8c672a2bf8c41f2bde16984992b8fd4"],"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1713972801927,"user_tz":240,"elapsed":311071,"user":{"displayName":"Victor Floriano","userId":"16962368443903150562"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1  batch 1 . Training Loss:  3.7596635818481445\n","Epoch 1  batch 101 . Training Loss:  3.114266872406006\n","Epoch 1  batch 201 . Training Loss:  2.627506732940674\n","Epoch 1: Validation Loss: 1.8877, Validation Accuracy: 36.04%\n","Epoch 2  batch 1 . Training Loss:  2.1745693683624268\n","Epoch 2  batch 101 . Training Loss:  1.8355135917663574\n","Epoch 2  batch 201 . Training Loss:  1.5455976724624634\n","Epoch 2: Validation Loss: 1.1717, Validation Accuracy: 57.92%\n","Epoch 3  batch 1 . Training Loss:  1.3612180948257446\n","Epoch 3  batch 101 . Training Loss:  1.193291187286377\n","Epoch 3  batch 201 . Training Loss:  0.822697639465332\n","Epoch 3: Validation Loss: 0.7312, Validation Accuracy: 73.38%\n","Epoch 4  batch 1 . Training Loss:  1.0528944730758667\n","Epoch 4  batch 101 . Training Loss:  1.0348796844482422\n","Epoch 4  batch 201 . Training Loss:  0.743293285369873\n","Epoch 4: Validation Loss: 0.4741, Validation Accuracy: 82.18%\n","Epoch 5  batch 1 . Training Loss:  0.695701003074646\n","Epoch 5  batch 101 . Training Loss:  0.6083040237426758\n","Epoch 5  batch 201 . Training Loss:  0.6454610228538513\n","Epoch 5: Validation Loss: 0.2872, Validation Accuracy: 90.46%\n","Epoch 6  batch 1 . Training Loss:  0.5223069190979004\n","Epoch 6  batch 101 . Training Loss:  0.5063157677650452\n","Epoch 6  batch 201 . Training Loss:  0.5990143418312073\n","Epoch 6: Validation Loss: 0.2673, Validation Accuracy: 90.22%\n","Epoch 7  batch 1 . Training Loss:  0.5972409248352051\n","Epoch 7  batch 101 . Training Loss:  0.42844143509864807\n","Epoch 7  batch 201 . Training Loss:  0.3974265158176422\n","Epoch 7: Validation Loss: 0.1635, Validation Accuracy: 94.81%\n","Epoch 8  batch 1 . Training Loss:  0.3620363175868988\n","Epoch 8  batch 101 . Training Loss:  0.42955970764160156\n","Epoch 8  batch 201 . Training Loss:  0.21588698029518127\n","Epoch 8: Validation Loss: 0.1147, Validation Accuracy: 96.52%\n","Epoch 9  batch 1 . Training Loss:  0.2868911921977997\n","Epoch 9  batch 101 . Training Loss:  0.27332964539527893\n","Epoch 9  batch 201 . Training Loss:  0.29199323058128357\n","Epoch 9: Validation Loss: 0.1266, Validation Accuracy: 95.97%\n","Epoch 10  batch 1 . Training Loss:  0.26917365193367004\n","Epoch 10  batch 101 . Training Loss:  0.22268038988113403\n","Epoch 10  batch 201 . Training Loss:  0.19590172171592712\n","Epoch 10: Validation Loss: 0.0885, Validation Accuracy: 97.36%\n","Epoch 11  batch 1 . Training Loss:  0.11435513198375702\n","Epoch 11  batch 101 . Training Loss:  0.15015961229801178\n","Epoch 11  batch 201 . Training Loss:  0.19557899236679077\n","Epoch 11: Validation Loss: 0.0821, Validation Accuracy: 97.39%\n","Epoch 12  batch 1 . Training Loss:  0.10798782855272293\n","Epoch 12  batch 101 . Training Loss:  0.12260367721319199\n","Epoch 12  batch 201 . Training Loss:  0.2690771222114563\n","Epoch 12: Validation Loss: 0.0735, Validation Accuracy: 97.76%\n","Epoch 13  batch 1 . Training Loss:  0.23193685710430145\n","Epoch 13  batch 101 . Training Loss:  0.21623022854328156\n","Epoch 13  batch 201 . Training Loss:  0.1785988062620163\n","Epoch 13: Validation Loss: 0.0764, Validation Accuracy: 97.59%\n","Epoch 14  batch 1 . Training Loss:  0.11769974231719971\n","Epoch 14  batch 101 . Training Loss:  0.15175552666187286\n","Epoch 14  batch 201 . Training Loss:  0.1241045817732811\n","Epoch 14: Validation Loss: 0.0644, Validation Accuracy: 98.07%\n","Epoch 15  batch 1 . Training Loss:  0.2389468550682068\n","Epoch 15  batch 101 . Training Loss:  0.1349363923072815\n","Epoch 15  batch 201 . Training Loss:  0.12936082482337952\n","Epoch 15: Validation Loss: 0.0645, Validation Accuracy: 98.07%\n","Epoch 16  batch 1 . Training Loss:  0.19809189438819885\n","Epoch 16  batch 101 . Training Loss:  0.176046222448349\n","Epoch 16  batch 201 . Training Loss:  0.11949680000543594\n","Epoch 16: Validation Loss: 0.0541, Validation Accuracy: 98.23%\n","Epoch 17  batch 1 . Training Loss:  0.15179361402988434\n","Epoch 17  batch 101 . Training Loss:  0.11781632155179977\n","Epoch 17  batch 201 . Training Loss:  0.12633906304836273\n","Epoch 17: Validation Loss: 0.0635, Validation Accuracy: 98.05%\n","Epoch 18  batch 1 . Training Loss:  0.09306628257036209\n","Epoch 18  batch 101 . Training Loss:  0.08009021729230881\n","Epoch 18  batch 201 . Training Loss:  0.13375835120677948\n","Epoch 18: Validation Loss: 0.0643, Validation Accuracy: 98.18%\n","Epoch 19  batch 1 . Training Loss:  0.10047181695699692\n","Epoch 19  batch 101 . Training Loss:  0.05467452108860016\n","Epoch 19  batch 201 . Training Loss:  0.09609907865524292\n","Epoch 19: Validation Loss: 0.0561, Validation Accuracy: 98.37%\n","Epoch 20  batch 1 . Training Loss:  0.16442522406578064\n","Epoch 20  batch 101 . Training Loss:  0.09431097656488419\n","Epoch 20  batch 201 . Training Loss:  0.1572466790676117\n","Epoch 20: Validation Loss: 0.0468, Validation Accuracy: 98.53%\n","Epoch 21  batch 1 . Training Loss:  0.10641352832317352\n","Epoch 21  batch 101 . Training Loss:  0.020634260028600693\n","Epoch 21  batch 201 . Training Loss:  0.1471295952796936\n","Epoch 21: Validation Loss: 0.0525, Validation Accuracy: 98.53%\n","Early stopping triggered.\n"]},{"output_type":"display_data","data":{"text/plain":["VBox(children=(Label(value='0.003 MB of 0.016 MB uploaded\\r'), FloatProgress(value=0.15402926149558754, max=1.…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6dccedb9018843bc8095d85ffaeac36a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>█▇▅▄▄▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▆▅▄▄▄▂▃▂▂▂▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▃▅▆▇▇███████████████</td></tr><tr><td>val_loss</td><td>█▅▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.14713</td></tr><tr><td>train_loss</td><td>0.10731</td></tr><tr><td>val_accuracy</td><td>98.53372</td></tr><tr><td>val_loss</td><td>0.05254</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">experiment_v2</strong> at: <a href='https://wandb.ai/victorgfloriano/Project%20CNN_v1/runs/1bdju16m' target=\"_blank\">https://wandb.ai/victorgfloriano/Project%20CNN_v1/runs/1bdju16m</a><br/> View project at: <a href='https://wandb.ai/victorgfloriano/Project%20CNN_v1' target=\"_blank\">https://wandb.ai/victorgfloriano/Project%20CNN_v1</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20240424_152757-1bdju16m/logs</code>"]},"metadata":{}}],"source":["epochs = 25\n","model = net1\n","for epoch in range(epochs):\n","    # Training loop\n","    model.train()\n","    for i,(images, labels) in enumerate(train_loader):\n","        images, labels = images.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        if i %100 == 0:\n","          print(\"Epoch\", epoch+ 1, \" batch\", i+1, \". Training Loss: \", loss.item())\n","          if enable_wandb:\n","            wandb.log({\"loss\": loss})\n","        wandb.log({\"train_loss\":loss.item()})\n","\n","    # Validation loop\n","    model.eval()\n","    validation_loss = get_loss(val_loader, model, criterion, device)\n","    validation_accuracy = get_accuracy(val_loader, model, device)\n","    wandb.log({\"val_loss\": validation_loss, \"val_accuracy\": validation_accuracy})\n","\n","    print(f'Epoch {epoch+1}: Validation Loss: {validation_loss:.4f}, Validation Accuracy: {validation_accuracy:.2f}%')\n","\n","    if early_stopping.early_stop(validation_loss, model):\n","        print(\"Early stopping triggered.\")\n","        break\n","wandb.finish()\n"]},{"cell_type":"markdown","metadata":{"id":"yHBREy3FRqJx"},"source":["---------------------------------"]},{"cell_type":"markdown","metadata":{"id":"nji7qJFQ5erI"},"source":["### CNN Model - 3"]},{"cell_type":"markdown","metadata":{"id":"FK88dB3_5erI"},"source":["- Epochs = 25\n","- Batch size = 128\n","- Learning Rates = 0.001\n","- No Data Agumentation\n","- Class Balancing\n","- Early Stopping Patience 5"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mRmOqtwe5erI","outputId":"09224448-20d4-48aa-e1e5-a95610dea347"},"outputs":[{"data":{"text/html":["Tracking run with wandb version 0.16.6"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/projectnb/ba865/students/evafan/wandb/run-20240417_160729-wtq186fx</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/evafan123/Project%20CNN_v1/runs/wtq186fx' target=\"_blank\">experiment_v3</a></strong> to <a href='https://wandb.ai/evafan123/Project%20CNN_v1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/evafan123/Project%20CNN_v1' target=\"_blank\">https://wandb.ai/evafan123/Project%20CNN_v1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/evafan123/Project%20CNN_v1/runs/wtq186fx' target=\"_blank\">https://wandb.ai/evafan123/Project%20CNN_v1/runs/wtq186fx</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/evafan123/Project%20CNN_v1/runs/wtq186fx?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x150c25ad2fe0>"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["wandb.init(project=\"Project CNN_v1\", name = 'experiment_v3')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FMHjHygp5erJ","outputId":"0c0681d6-88e0-4401-c9d9-ab2dc7dd0aeb"},"outputs":[{"data":{"text/plain":["[]"]},"execution_count":44,"metadata":{},"output_type":"execute_result"}],"source":["wandb.config.update({\n","    \"learning_rate\": 0.001,\n","    \"epochs\": 25,\n","    \"batch_size\": 128\n","})\n","wandb.watch(net)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ds2mGBLM5erJ"},"outputs":[],"source":["train_loader = DataLoader(train_data, batch_size=128, shuffle=True, num_workers=2)\n","val_loader = DataLoader(val_data, batch_size=128, shuffle=False, num_workers=2)\n","test_loader = DataLoader(dataset_test, shuffle=True, batch_size = 128, num_workers = 2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5UoFZdXC5erJ","outputId":"6a4e59b8-c458-4007-9642-d913a14c853d"},"outputs":[{"data":{"text/plain":["Net(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","    (3): Dropout2d(p=0.2, inplace=False)\n","    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (5): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (6): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (7): ReLU(inplace=True)\n","    (8): Dropout2d(p=0.3, inplace=False)\n","    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (10): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (12): ReLU(inplace=True)\n","    (13): Dropout2d(p=0.4, inplace=False)\n","    (14): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (16): ReLU(inplace=True)\n","    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (19): ReLU(inplace=True)\n","    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (21): Dropout2d(p=0.5, inplace=False)\n","  )\n","  (classifier): Sequential(\n","    (0): Dropout(p=0.5, inplace=False)\n","    (1): Linear(in_features=1024, out_features=1000, bias=True)\n","    (2): ReLU(inplace=True)\n","    (3): Dropout(p=0.5, inplace=False)\n","    (4): Linear(in_features=1000, out_features=256, bias=True)\n","    (5): ReLU(inplace=True)\n","    (6): Linear(in_features=256, out_features=43, bias=True)\n","  )\n",")"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["net2 = Net(num_classes=43)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","net2.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_qUZZlAF5erP"},"outputs":[],"source":["weights = [total_train/sorted_train[str(i).zfill(2)] if str(i).zfill(2) in sorted_train else 1 for i in range(43)]\n","class_weights = torch.FloatTensor(weights).cuda()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kfKapWgb5erP"},"outputs":[],"source":["optimizer = optim.Adam(net2.parameters(), lr=0.001)\n","early_stopping = EarlyStopper(patience=5,delta = 0.01)\n","criterion = nn.CrossEntropyLoss(weight=class_weights)"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"Fg3nvGjG5erP","outputId":"9771be14-8ac2-412b-e052-3483bc374fb1","colab":{"referenced_widgets":["407e1db1a0c448f4846b3943098d6a85"]}},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1  batch 1 . Training Loss:  3.7736706733703613\n","Epoch 1  batch 101 . Training Loss:  3.5578105449676514\n","Epoch 1  batch 201 . Training Loss:  3.195345163345337\n","Epoch 1: Validation Loss: 3.0196, Validation Accuracy: 5.17%\n","Epoch 2  batch 1 . Training Loss:  2.9793307781219482\n","Epoch 2  batch 101 . Training Loss:  2.6133809089660645\n","Epoch 2  batch 201 . Training Loss:  2.442598342895508\n","Epoch 2: Validation Loss: 2.0729, Validation Accuracy: 29.78%\n","Epoch 3  batch 1 . Training Loss:  2.336299419403076\n","Epoch 3  batch 101 . Training Loss:  2.1039879322052\n","Epoch 3  batch 201 . Training Loss:  2.08070969581604\n","Epoch 3: Validation Loss: 1.6997, Validation Accuracy: 39.69%\n","Epoch 4  batch 1 . Training Loss:  1.8897264003753662\n","Epoch 4  batch 101 . Training Loss:  2.063704490661621\n","Epoch 4  batch 201 . Training Loss:  1.7049708366394043\n","Epoch 4: Validation Loss: 1.2603, Validation Accuracy: 50.34%\n","Epoch 5  batch 1 . Training Loss:  1.4017705917358398\n","Epoch 5  batch 101 . Training Loss:  1.4644529819488525\n","Epoch 5  batch 201 . Training Loss:  1.1759403944015503\n","Epoch 5: Validation Loss: 0.9108, Validation Accuracy: 63.46%\n","Epoch 6  batch 1 . Training Loss:  1.316703200340271\n","Epoch 6  batch 101 . Training Loss:  1.1272741556167603\n","Epoch 6  batch 201 . Training Loss:  1.1494197845458984\n","Epoch 6: Validation Loss: 0.5792, Validation Accuracy: 72.55%\n","Epoch 7  batch 1 . Training Loss:  0.9424355626106262\n","Epoch 7  batch 101 . Training Loss:  0.9627170562744141\n","Epoch 7  batch 201 . Training Loss:  0.7132917046546936\n","Epoch 7: Validation Loss: 0.4527, Validation Accuracy: 76.48%\n","Epoch 8  batch 1 . Training Loss:  0.739297091960907\n","Epoch 8  batch 101 . Training Loss:  0.5749643445014954\n","Epoch 8  batch 201 . Training Loss:  0.5105191469192505\n","Epoch 8: Validation Loss: 0.3419, Validation Accuracy: 81.88%\n","Epoch 9  batch 1 . Training Loss:  0.7816896438598633\n","Epoch 9  batch 101 . Training Loss:  0.4045046865940094\n","Epoch 9  batch 201 . Training Loss:  0.3747624158859253\n","Epoch 9: Validation Loss: 0.2859, Validation Accuracy: 85.96%\n","Epoch 10  batch 1 . Training Loss:  0.718317985534668\n","Epoch 10  batch 101 . Training Loss:  0.4254109859466553\n","Epoch 10  batch 201 . Training Loss:  0.5554942488670349\n","Epoch 10: Validation Loss: 0.2366, Validation Accuracy: 87.77%\n","Epoch 11  batch 1 . Training Loss:  0.4264855682849884\n","Epoch 11  batch 101 . Training Loss:  0.44754305481910706\n","Epoch 11  batch 201 . Training Loss:  0.6361220479011536\n","Epoch 11: Validation Loss: 0.2023, Validation Accuracy: 89.71%\n","Epoch 12  batch 1 . Training Loss:  0.3716249465942383\n","Epoch 12  batch 101 . Training Loss:  0.30156829953193665\n","Epoch 12  batch 201 . Training Loss:  0.24838313460350037\n","Epoch 12: Validation Loss: 0.1727, Validation Accuracy: 91.17%\n","Epoch 13  batch 1 . Training Loss:  0.37051329016685486\n","Epoch 13  batch 101 . Training Loss:  0.3623619079589844\n","Epoch 13  batch 201 . Training Loss:  0.26972848176956177\n","Epoch 13: Validation Loss: 0.1520, Validation Accuracy: 91.83%\n","Epoch 14  batch 1 . Training Loss:  0.2665461003780365\n","Epoch 14  batch 101 . Training Loss:  0.3070172071456909\n","Epoch 14  batch 201 . Training Loss:  0.4754333198070526\n","Epoch 14: Validation Loss: 0.1451, Validation Accuracy: 93.09%\n","Epoch 15  batch 1 . Training Loss:  0.430475115776062\n","Epoch 15  batch 101 . Training Loss:  0.2857552170753479\n","Epoch 15  batch 201 . Training Loss:  0.1850673109292984\n","Epoch 15: Validation Loss: 0.1222, Validation Accuracy: 94.12%\n","Epoch 16  batch 1 . Training Loss:  0.28315526247024536\n","Epoch 16  batch 101 . Training Loss:  0.2956596612930298\n","Epoch 16  batch 201 . Training Loss:  0.2788715362548828\n","Epoch 16: Validation Loss: 0.1230, Validation Accuracy: 93.97%\n","Epoch 17  batch 1 . Training Loss:  0.3437974750995636\n","Epoch 17  batch 101 . Training Loss:  0.2953653335571289\n","Epoch 17  batch 201 . Training Loss:  0.3020947277545929\n","Epoch 17: Validation Loss: 0.1011, Validation Accuracy: 95.32%\n","Epoch 18  batch 1 . Training Loss:  0.224470317363739\n","Epoch 18  batch 101 . Training Loss:  0.24974258244037628\n","Epoch 18  batch 201 . Training Loss:  0.2252579778432846\n","Epoch 18: Validation Loss: 0.0900, Validation Accuracy: 95.70%\n","Epoch 19  batch 1 . Training Loss:  0.19967585802078247\n","Epoch 19  batch 101 . Training Loss:  0.29124659299850464\n","Epoch 19  batch 201 . Training Loss:  0.14317406713962555\n","Epoch 19: Validation Loss: 0.0805, Validation Accuracy: 96.33%\n","Epoch 20  batch 1 . Training Loss:  0.16023410856723785\n","Epoch 20  batch 101 . Training Loss:  0.18482881784439087\n","Epoch 20  batch 201 . Training Loss:  0.17997337877750397\n","Epoch 20: Validation Loss: 0.0797, Validation Accuracy: 96.15%\n","Epoch 21  batch 1 . Training Loss:  0.17919614911079407\n","Epoch 21  batch 101 . Training Loss:  0.3174866735935211\n","Epoch 21  batch 201 . Training Loss:  0.17121846973896027\n","Epoch 21: Validation Loss: 0.0667, Validation Accuracy: 96.67%\n","Epoch 22  batch 1 . Training Loss:  0.14969351887702942\n","Epoch 22  batch 101 . Training Loss:  0.18760204315185547\n","Epoch 22  batch 201 . Training Loss:  0.15528038144111633\n","Epoch 22: Validation Loss: 0.0720, Validation Accuracy: 96.94%\n","Epoch 23  batch 1 . Training Loss:  0.3391406834125519\n","Epoch 23  batch 101 . Training Loss:  0.17139706015586853\n","Epoch 23  batch 201 . Training Loss:  0.12342008948326111\n","Epoch 23: Validation Loss: 0.0637, Validation Accuracy: 97.02%\n","Epoch 24  batch 1 . Training Loss:  0.259400874376297\n","Epoch 24  batch 101 . Training Loss:  0.1115034818649292\n","Epoch 24  batch 201 . Training Loss:  0.0891747921705246\n","Epoch 24: Validation Loss: 0.0674, Validation Accuracy: 97.00%\n","Epoch 25  batch 1 . Training Loss:  0.15927934646606445\n","Epoch 25  batch 101 . Training Loss:  0.14029788970947266\n","Epoch 25  batch 201 . Training Loss:  0.1845475435256958\n","Epoch 25: Validation Loss: 0.0578, Validation Accuracy: 97.65%\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"407e1db1a0c448f4846b3943098d6a85","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.004 MB of 0.004 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>██▆▅▅▄▄▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▇▆▅▅▅▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▃▄▄▅▆▆▇▇▇▇██████████████</td></tr><tr><td>val_loss</td><td>█▆▅▄▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.18455</td></tr><tr><td>train_loss</td><td>0.01202</td></tr><tr><td>val_accuracy</td><td>97.65336</td></tr><tr><td>val_loss</td><td>0.05779</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">experiment_v3</strong> at: <a href='https://wandb.ai/evafan123/Project%20CNN_v1/runs/wtq186fx' target=\"_blank\">https://wandb.ai/evafan123/Project%20CNN_v1/runs/wtq186fx</a><br/> View project at: <a href='https://wandb.ai/evafan123/Project%20CNN_v1' target=\"_blank\">https://wandb.ai/evafan123/Project%20CNN_v1</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20240417_160729-wtq186fx/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["epochs = 25\n","model = net2\n","for epoch in range(epochs):\n","    # Training loop\n","    model.train()\n","    for i,(images, labels) in enumerate(train_loader):\n","        images, labels = images.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        if i %100 == 0:\n","          print(\"Epoch\", epoch+ 1, \" batch\", i+1, \". Training Loss: \", loss.item())\n","          if enable_wandb:\n","            wandb.log({\"loss\": loss})\n","        wandb.log({\"train_loss\":loss.item()})\n","\n","    # Validation loop\n","    model.eval()\n","    validation_loss = get_loss(val_loader, model, criterion, device)\n","    validation_accuracy = get_accuracy(val_loader, model, device)\n","    wandb.log({\"val_loss\": validation_loss, \"val_accuracy\": validation_accuracy})\n","\n","    print(f'Epoch {epoch+1}: Validation Loss: {validation_loss:.4f}, Validation Accuracy: {validation_accuracy:.2f}%')\n","\n","    if early_stopping.early_stop(validation_loss, model):\n","        print(\"Early stopping triggered.\")\n","        break\n","wandb.finish()\n"]},{"cell_type":"markdown","metadata":{"id":"dhwztyYg5erP"},"source":["---------------------"]},{"cell_type":"markdown","metadata":{"id":"F-JaOQnT5erP"},"source":["### CNN Model - 4"]},{"cell_type":"markdown","metadata":{"id":"3N20pOSu5erP"},"source":["- Epochs = 50\n","- Batch size = 128\n","- Learning Rates = 0.001\n","- Data Agumentation\n","- Class Balancing\n","- Early Stopping Patience 5"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EBFDzNDV5erP","outputId":"00733929-a4cc-41b2-b6ae-788aeab0af46"},"outputs":[{"data":{"text/html":["Tracking run with wandb version 0.16.6"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/projectnb/ba865/students/evafan/wandb/run-20240417_163104-vl1uu89m</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/evafan123/Project%20CNN_v1/runs/vl1uu89m' target=\"_blank\">experiment_v4</a></strong> to <a href='https://wandb.ai/evafan123/Project%20CNN_v1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/evafan123/Project%20CNN_v1' target=\"_blank\">https://wandb.ai/evafan123/Project%20CNN_v1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/evafan123/Project%20CNN_v1/runs/vl1uu89m' target=\"_blank\">https://wandb.ai/evafan123/Project%20CNN_v1/runs/vl1uu89m</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/evafan123/Project%20CNN_v1/runs/vl1uu89m?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x150c25a71d20>"]},"execution_count":53,"metadata":{},"output_type":"execute_result"}],"source":["wandb.init(project=\"Project CNN_v1\", name = 'experiment_v4')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7Z-_k_wT5erP"},"outputs":[],"source":["wandb.config.update({\n","    \"learning_rate\": 0.001,\n","    \"epochs\": 50,\n","    \"batch_size\": 128\n","})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CQEfG8dI5erP"},"outputs":[],"source":["train_transform_1 = transforms.Compose([\n","    transforms.Resize((32, 32)),\n","    transforms.RandomHorizontalFlip(0.5),\n","    transforms.RandomRotation(45),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.3337, 0.3064, 0.3171), (0.2672, 0.2564, 0.2629))\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OTviMKRu5erP"},"outputs":[],"source":["dataset_train = ImageFolder(\n","    'Train',\n","    transform = train_transform_1\n",")\n","\n","train_data, val_data = random_split(dataset_train, [0.8, 0.2])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"StU-owQp5erQ"},"outputs":[],"source":["train_loader = DataLoader(train_data, batch_size=128, shuffle=True, num_workers=2)\n","val_loader = DataLoader(val_data, batch_size=128, shuffle=False, num_workers=2)\n","test_loader = DataLoader(dataset_test, shuffle=True, batch_size = 128, num_workers = 2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NnMcGs155erQ","outputId":"4cecefba-0d9f-4c63-f1a9-63c20060400b"},"outputs":[{"data":{"text/plain":["Net(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","    (3): Dropout2d(p=0.2, inplace=False)\n","    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (5): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (6): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (7): ReLU(inplace=True)\n","    (8): Dropout2d(p=0.3, inplace=False)\n","    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (10): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (12): ReLU(inplace=True)\n","    (13): Dropout2d(p=0.4, inplace=False)\n","    (14): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (16): ReLU(inplace=True)\n","    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (19): ReLU(inplace=True)\n","    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (21): Dropout2d(p=0.5, inplace=False)\n","  )\n","  (classifier): Sequential(\n","    (0): Dropout(p=0.5, inplace=False)\n","    (1): Linear(in_features=1024, out_features=1000, bias=True)\n","    (2): ReLU(inplace=True)\n","    (3): Dropout(p=0.5, inplace=False)\n","    (4): Linear(in_features=1000, out_features=256, bias=True)\n","    (5): ReLU(inplace=True)\n","    (6): Linear(in_features=256, out_features=43, bias=True)\n","  )\n",")"]},"execution_count":55,"metadata":{},"output_type":"execute_result"}],"source":["net3 = Net(num_classes=43)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","net3.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZHyhKO3f5erQ"},"outputs":[],"source":["optimizer = optim.Adam(net3.parameters(), lr=0.001)\n","early_stopping = EarlyStopper(patience=5,delta = 0.01)\n","criterion = nn.CrossEntropyLoss(weight=class_weights)"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"t9OXHfwP5erQ","outputId":"1c5a25f1-fc1f-4b33-9cb1-2b937872c563","colab":{"referenced_widgets":["c4bd4c0b25324823819070fc7585b045"]}},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1  batch 1 . Training Loss:  3.8147876262664795\n","Epoch 1  batch 101 . Training Loss:  3.5149896144866943\n","Epoch 1  batch 201 . Training Loss:  3.3080899715423584\n","Epoch 1: Validation Loss: 2.8435, Validation Accuracy: 8.86%\n","Epoch 2  batch 1 . Training Loss:  2.7447104454040527\n","Epoch 2  batch 101 . Training Loss:  2.8544790744781494\n","Epoch 2  batch 201 . Training Loss:  2.420358657836914\n","Epoch 2: Validation Loss: 2.2796, Validation Accuracy: 21.16%\n","Epoch 3  batch 1 . Training Loss:  2.4717936515808105\n","Epoch 3  batch 101 . Training Loss:  2.3563475608825684\n","Epoch 3  batch 201 . Training Loss:  2.222247362136841\n","Epoch 3: Validation Loss: 2.0543, Validation Accuracy: 25.69%\n","Epoch 4  batch 1 . Training Loss:  2.1091411113739014\n","Epoch 4  batch 101 . Training Loss:  2.2933366298675537\n","Epoch 4  batch 201 . Training Loss:  2.1197264194488525\n","Epoch 4: Validation Loss: 1.8142, Validation Accuracy: 34.61%\n","Epoch 5  batch 1 . Training Loss:  1.878069519996643\n","Epoch 5  batch 101 . Training Loss:  1.8093887567520142\n","Epoch 5  batch 201 . Training Loss:  1.7186288833618164\n","Epoch 5: Validation Loss: 1.6591, Validation Accuracy: 39.80%\n","Epoch 6  batch 1 . Training Loss:  1.6346933841705322\n","Epoch 6  batch 101 . Training Loss:  2.0103840827941895\n","Epoch 6  batch 201 . Training Loss:  1.734400749206543\n","Epoch 6: Validation Loss: 1.4223, Validation Accuracy: 41.64%\n","Epoch 7  batch 1 . Training Loss:  1.53714919090271\n","Epoch 7  batch 101 . Training Loss:  1.7284539937973022\n","Epoch 7  batch 201 . Training Loss:  1.4583876132965088\n","Epoch 7: Validation Loss: 1.3287, Validation Accuracy: 45.58%\n","Epoch 8  batch 1 . Training Loss:  1.8070791959762573\n","Epoch 8  batch 101 . Training Loss:  1.537049651145935\n","Epoch 8  batch 201 . Training Loss:  1.626383662223816\n","Epoch 8: Validation Loss: 1.1853, Validation Accuracy: 50.70%\n","Epoch 9  batch 1 . Training Loss:  1.350841760635376\n","Epoch 9  batch 101 . Training Loss:  1.1847546100616455\n","Epoch 9  batch 201 . Training Loss:  1.3897762298583984\n","Epoch 9: Validation Loss: 1.0657, Validation Accuracy: 55.12%\n","Epoch 10  batch 1 . Training Loss:  1.2967913150787354\n","Epoch 10  batch 101 . Training Loss:  1.3542358875274658\n","Epoch 10  batch 201 . Training Loss:  1.3694632053375244\n","Epoch 10: Validation Loss: 0.9649, Validation Accuracy: 57.39%\n","Epoch 11  batch 1 . Training Loss:  1.5101908445358276\n","Epoch 11  batch 101 . Training Loss:  1.389530897140503\n","Epoch 11  batch 201 . Training Loss:  1.3294150829315186\n","Epoch 11: Validation Loss: 0.9056, Validation Accuracy: 59.20%\n","Epoch 12  batch 1 . Training Loss:  1.2073345184326172\n","Epoch 12  batch 101 . Training Loss:  1.2742961645126343\n","Epoch 12  batch 201 . Training Loss:  0.9137673377990723\n","Epoch 12: Validation Loss: 0.8638, Validation Accuracy: 60.96%\n","Epoch 13  batch 1 . Training Loss:  1.2139540910720825\n","Epoch 13  batch 101 . Training Loss:  1.0828068256378174\n","Epoch 13  batch 201 . Training Loss:  1.146146297454834\n","Epoch 13: Validation Loss: 0.8044, Validation Accuracy: 62.10%\n","Epoch 14  batch 1 . Training Loss:  0.9359943866729736\n","Epoch 14  batch 101 . Training Loss:  1.0674169063568115\n","Epoch 14  batch 201 . Training Loss:  1.1619030237197876\n","Epoch 14: Validation Loss: 0.7590, Validation Accuracy: 64.41%\n","Epoch 15  batch 1 . Training Loss:  1.0161744356155396\n","Epoch 15  batch 101 . Training Loss:  1.0245864391326904\n","Epoch 15  batch 201 . Training Loss:  0.840387761592865\n","Epoch 15: Validation Loss: 0.7301, Validation Accuracy: 66.52%\n","Epoch 16  batch 1 . Training Loss:  0.9238609671592712\n","Epoch 16  batch 101 . Training Loss:  0.8337833285331726\n","Epoch 16  batch 201 . Training Loss:  1.012507677078247\n","Epoch 16: Validation Loss: 0.7127, Validation Accuracy: 66.88%\n","Epoch 17  batch 1 . Training Loss:  0.8588206768035889\n","Epoch 17  batch 101 . Training Loss:  0.9264667630195618\n","Epoch 17  batch 201 . Training Loss:  1.130476474761963\n","Epoch 17: Validation Loss: 0.6710, Validation Accuracy: 71.13%\n","Epoch 18  batch 1 . Training Loss:  0.8537394404411316\n","Epoch 18  batch 101 . Training Loss:  0.7621443271636963\n","Epoch 18  batch 201 . Training Loss:  1.026057481765747\n","Epoch 18: Validation Loss: 0.6141, Validation Accuracy: 72.41%\n","Epoch 19  batch 1 . Training Loss:  0.851945698261261\n","Epoch 19  batch 101 . Training Loss:  1.0049759149551392\n","Epoch 19  batch 201 . Training Loss:  0.8236258029937744\n","Epoch 19: Validation Loss: 0.5859, Validation Accuracy: 71.00%\n","Epoch 20  batch 1 . Training Loss:  0.8219751715660095\n","Epoch 20  batch 101 . Training Loss:  0.8330689072608948\n","Epoch 20  batch 201 . Training Loss:  0.8547568917274475\n","Epoch 20: Validation Loss: 0.5701, Validation Accuracy: 73.46%\n","Epoch 21  batch 1 . Training Loss:  0.7234737873077393\n","Epoch 21  batch 101 . Training Loss:  0.9061400890350342\n","Epoch 21  batch 201 . Training Loss:  0.8175577521324158\n","Epoch 21: Validation Loss: 0.5405, Validation Accuracy: 73.94%\n","Epoch 22  batch 1 . Training Loss:  0.7432879209518433\n","Epoch 22  batch 101 . Training Loss:  0.8523425459861755\n","Epoch 22  batch 201 . Training Loss:  0.9113644361495972\n","Epoch 22: Validation Loss: 0.5439, Validation Accuracy: 73.77%\n","Epoch 23  batch 1 . Training Loss:  0.616101086139679\n","Epoch 23  batch 101 . Training Loss:  0.747808039188385\n","Epoch 23  batch 201 . Training Loss:  0.6548805832862854\n","Epoch 23: Validation Loss: 0.4760, Validation Accuracy: 77.18%\n","Epoch 24  batch 1 . Training Loss:  0.5703667998313904\n","Epoch 24  batch 101 . Training Loss:  0.7740985155105591\n","Epoch 24  batch 201 . Training Loss:  0.7180878520011902\n","Epoch 24: Validation Loss: 0.4764, Validation Accuracy: 77.66%\n","Epoch 25  batch 1 . Training Loss:  0.7559589147567749\n","Epoch 25  batch 101 . Training Loss:  0.6589093208312988\n","Epoch 25  batch 201 . Training Loss:  0.829163134098053\n","Epoch 25: Validation Loss: 0.4616, Validation Accuracy: 77.40%\n","Epoch 26  batch 1 . Training Loss:  0.6960063576698303\n","Epoch 26  batch 101 . Training Loss:  0.6012942790985107\n","Epoch 26  batch 201 . Training Loss:  0.6219682097434998\n","Epoch 26: Validation Loss: 0.4366, Validation Accuracy: 78.14%\n","Epoch 27  batch 1 . Training Loss:  0.6142142415046692\n","Epoch 27  batch 101 . Training Loss:  0.6537884473800659\n","Epoch 27  batch 201 . Training Loss:  0.7637179493904114\n","Epoch 27: Validation Loss: 0.4147, Validation Accuracy: 77.41%\n","Epoch 28  batch 1 . Training Loss:  0.7085140943527222\n","Epoch 28  batch 101 . Training Loss:  0.7162855267524719\n","Epoch 28  batch 201 . Training Loss:  0.711592435836792\n","Epoch 28: Validation Loss: 0.4214, Validation Accuracy: 79.72%\n","Epoch 29  batch 1 . Training Loss:  0.635911226272583\n","Epoch 29  batch 101 . Training Loss:  0.7518412470817566\n","Epoch 29  batch 201 . Training Loss:  0.6384578943252563\n","Epoch 29: Validation Loss: 0.3989, Validation Accuracy: 79.96%\n","Epoch 30  batch 1 . Training Loss:  0.694694995880127\n","Epoch 30  batch 101 . Training Loss:  0.5512910485267639\n","Epoch 30  batch 201 . Training Loss:  0.8027809858322144\n","Epoch 30: Validation Loss: 0.4001, Validation Accuracy: 78.59%\n","Epoch 31  batch 1 . Training Loss:  0.5098328590393066\n","Epoch 31  batch 101 . Training Loss:  0.5668683648109436\n","Epoch 31  batch 201 . Training Loss:  0.6177315711975098\n","Epoch 31: Validation Loss: 0.4554, Validation Accuracy: 77.59%\n","Epoch 32  batch 1 . Training Loss:  0.7404090762138367\n","Epoch 32  batch 101 . Training Loss:  0.49081236124038696\n","Epoch 32  batch 201 . Training Loss:  0.7317051887512207\n","Epoch 32: Validation Loss: 0.3477, Validation Accuracy: 81.00%\n","Epoch 33  batch 1 . Training Loss:  0.6059399247169495\n","Epoch 33  batch 101 . Training Loss:  0.4585944414138794\n","Epoch 33  batch 201 . Training Loss:  0.6452369689941406\n","Epoch 33: Validation Loss: 0.3455, Validation Accuracy: 81.95%\n","Epoch 34  batch 1 . Training Loss:  0.6165857315063477\n","Epoch 34  batch 101 . Training Loss:  0.7073436379432678\n","Epoch 34  batch 201 . Training Loss:  0.7555443644523621\n","Epoch 34: Validation Loss: 0.3434, Validation Accuracy: 82.06%\n","Epoch 35  batch 1 . Training Loss:  0.5331928730010986\n","Epoch 35  batch 101 . Training Loss:  0.5801885724067688\n","Epoch 35  batch 201 . Training Loss:  0.7208600640296936\n","Epoch 35: Validation Loss: 0.3173, Validation Accuracy: 83.47%\n","Epoch 36  batch 1 . Training Loss:  0.49050045013427734\n","Epoch 36  batch 101 . Training Loss:  0.5660935044288635\n","Epoch 36  batch 201 . Training Loss:  0.5312013030052185\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 36: Validation Loss: 0.3294, Validation Accuracy: 82.72%\n","Epoch 37  batch 1 . Training Loss:  0.45854634046554565\n","Epoch 37  batch 101 . Training Loss:  0.42244046926498413\n","Epoch 37  batch 201 . Training Loss:  0.6222683191299438\n","Epoch 37: Validation Loss: 0.3092, Validation Accuracy: 84.29%\n","Epoch 38  batch 1 . Training Loss:  0.3853470981121063\n","Epoch 38  batch 101 . Training Loss:  0.5691140294075012\n","Epoch 38  batch 201 . Training Loss:  0.4466889798641205\n","Epoch 38: Validation Loss: 0.3283, Validation Accuracy: 82.64%\n","Epoch 39  batch 1 . Training Loss:  0.4012397229671478\n","Epoch 39  batch 101 . Training Loss:  0.46965929865837097\n","Epoch 39  batch 201 . Training Loss:  0.46745169162750244\n","Epoch 39: Validation Loss: 0.3072, Validation Accuracy: 83.88%\n","Epoch 40  batch 1 . Training Loss:  0.6425666809082031\n","Epoch 40  batch 101 . Training Loss:  0.566315233707428\n","Epoch 40  batch 201 . Training Loss:  0.466322660446167\n","Epoch 40: Validation Loss: 0.2996, Validation Accuracy: 83.76%\n","Epoch 41  batch 1 . Training Loss:  0.5310930609703064\n","Epoch 41  batch 101 . Training Loss:  0.5215045213699341\n","Epoch 41  batch 201 . Training Loss:  0.5798084735870361\n","Epoch 41: Validation Loss: 0.2999, Validation Accuracy: 84.84%\n","Epoch 42  batch 1 . Training Loss:  0.5583769083023071\n","Epoch 42  batch 101 . Training Loss:  0.6247722506523132\n","Epoch 42  batch 201 . Training Loss:  0.5147913098335266\n","Epoch 42: Validation Loss: 0.2703, Validation Accuracy: 84.76%\n","Epoch 43  batch 1 . Training Loss:  0.43431639671325684\n","Epoch 43  batch 101 . Training Loss:  0.5692195296287537\n","Epoch 43  batch 201 . Training Loss:  0.3846636712551117\n","Epoch 43: Validation Loss: 0.2750, Validation Accuracy: 84.66%\n","Epoch 44  batch 1 . Training Loss:  0.4412136375904083\n","Epoch 44  batch 101 . Training Loss:  0.3173951506614685\n","Epoch 44  batch 201 . Training Loss:  0.7884201407432556\n","Epoch 44: Validation Loss: 0.2602, Validation Accuracy: 85.13%\n","Epoch 45  batch 1 . Training Loss:  0.5830985307693481\n","Epoch 45  batch 101 . Training Loss:  0.5345719456672668\n","Epoch 45  batch 201 . Training Loss:  0.4846295416355133\n","Epoch 45: Validation Loss: 0.2531, Validation Accuracy: 85.78%\n","Epoch 46  batch 1 . Training Loss:  0.40691670775413513\n","Epoch 46  batch 101 . Training Loss:  0.3299926221370697\n","Epoch 46  batch 201 . Training Loss:  0.4986615777015686\n","Epoch 46: Validation Loss: 0.2710, Validation Accuracy: 85.44%\n","Epoch 47  batch 1 . Training Loss:  0.332743376493454\n","Epoch 47  batch 101 . Training Loss:  0.38155338168144226\n","Epoch 47  batch 201 . Training Loss:  0.447689950466156\n","Epoch 47: Validation Loss: 0.2419, Validation Accuracy: 86.24%\n","Epoch 48  batch 1 . Training Loss:  0.4418121576309204\n","Epoch 48  batch 101 . Training Loss:  0.5130907893180847\n","Epoch 48  batch 201 . Training Loss:  0.5625210404396057\n","Epoch 48: Validation Loss: 0.2673, Validation Accuracy: 84.79%\n","Epoch 49  batch 1 . Training Loss:  0.5995877981185913\n","Epoch 49  batch 101 . Training Loss:  0.43377718329429626\n","Epoch 49  batch 201 . Training Loss:  0.4133082926273346\n","Epoch 49: Validation Loss: 0.2419, Validation Accuracy: 87.86%\n","Epoch 50  batch 1 . Training Loss:  0.39605093002319336\n","Epoch 50  batch 101 . Training Loss:  0.364484041929245\n","Epoch 50  batch 201 . Training Loss:  0.34472334384918213\n","Epoch 50: Validation Loss: 0.2300, Validation Accuracy: 87.41%\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c4bd4c0b25324823819070fc7585b045","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.004 MB of 0.004 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>█▆▅▅▄▄▄▃▃▂▃▃▂▂▃▂▂▂▁▂▂▂▂▂▁▂▂▂▁▁▁▂▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▆▆▅▅▄▃▄▃▃▃▄▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▁▁▁▂▂▁▁▂▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▂▂▃▄▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇██████████████</td></tr><tr><td>val_loss</td><td>█▆▆▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.34472</td></tr><tr><td>train_loss</td><td>0.48425</td></tr><tr><td>val_accuracy</td><td>87.41232</td></tr><tr><td>val_loss</td><td>0.23001</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">experiment_v4</strong> at: <a href='https://wandb.ai/evafan123/Project%20CNN_v1/runs/vl1uu89m' target=\"_blank\">https://wandb.ai/evafan123/Project%20CNN_v1/runs/vl1uu89m</a><br/> View project at: <a href='https://wandb.ai/evafan123/Project%20CNN_v1' target=\"_blank\">https://wandb.ai/evafan123/Project%20CNN_v1</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20240417_163104-vl1uu89m/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["epochs = 50\n","model = net3\n","for epoch in range(epochs):\n","    # Training loop\n","    model.train()\n","    for i,(images, labels) in enumerate(train_loader):\n","        images, labels = images.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        if i %100 == 0:\n","          print(\"Epoch\", epoch+ 1, \" batch\", i+1, \". Training Loss: \", loss.item())\n","          if enable_wandb:\n","            wandb.log({\"loss\": loss})\n","        wandb.log({\"train_loss\":loss.item()})\n","\n","    # Validation loop\n","    model.eval()\n","    validation_loss = get_loss(val_loader, model, criterion, device)\n","    validation_accuracy = get_accuracy(val_loader, model, device)\n","    wandb.log({\"val_loss\": validation_loss, \"val_accuracy\": validation_accuracy})\n","\n","    print(f'Epoch {epoch+1}: Validation Loss: {validation_loss:.4f}, Validation Accuracy: {validation_accuracy:.2f}%')\n","\n","    if early_stopping.early_stop(validation_loss, model):\n","        print(\"Early stopping triggered.\")\n","        break\n","wandb.finish()"]},{"cell_type":"markdown","metadata":{"id":"Qm6BSRjl5erQ"},"source":["---------------------"]},{"cell_type":"markdown","metadata":{"id":"P6Ly0inz5erQ"},"source":["### CNN Model - 5"]},{"cell_type":"markdown","metadata":{"id":"YhHFGL6t5erQ"},"source":["- Epochs = 100\n","- Batch size = 128\n","- Learning Rates = 0.001\n","- Data Agumentation\n","- Class Balancing\n","- Early Stopping Patience 5"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ouifdm3f5erQ","outputId":"5335a4a3-4be3-427e-e625-236d7ea45e7a"},"outputs":[{"data":{"text/html":["Tracking run with wandb version 0.16.6"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/projectnb/ba865/students/evafan/wandb/run-20240417_165937-7glnky47</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/evafan123/Project%20CNN_v1/runs/7glnky47' target=\"_blank\">experiment_v5</a></strong> to <a href='https://wandb.ai/evafan123/Project%20CNN_v1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/evafan123/Project%20CNN_v1' target=\"_blank\">https://wandb.ai/evafan123/Project%20CNN_v1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/evafan123/Project%20CNN_v1/runs/7glnky47' target=\"_blank\">https://wandb.ai/evafan123/Project%20CNN_v1/runs/7glnky47</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/evafan123/Project%20CNN_v1/runs/7glnky47?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x150c25ac8970>"]},"execution_count":67,"metadata":{},"output_type":"execute_result"}],"source":["wandb.init(project=\"Project CNN_v1\", name = 'experiment_v5')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hbv7nO8y5erQ"},"outputs":[],"source":["wandb.config.update({\n","    \"learning_rate\": 0.001,\n","    \"epochs\": 100,\n","    \"batch_size\": 128\n","})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_8thV35M5erQ"},"outputs":[],"source":["train_loader = DataLoader(train_data, batch_size=128, shuffle=True, num_workers=2)\n","val_loader = DataLoader(val_data, batch_size=128, shuffle=False, num_workers=2)\n","test_loader = DataLoader(dataset_test, shuffle=True, batch_size = 128, num_workers = 2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WhsDCHx85erQ","outputId":"29424e9b-ab40-4c8b-c927-584d2593d979"},"outputs":[{"data":{"text/plain":["Net(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","    (3): Dropout2d(p=0.2, inplace=False)\n","    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (5): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (6): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (7): ReLU(inplace=True)\n","    (8): Dropout2d(p=0.3, inplace=False)\n","    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (10): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (12): ReLU(inplace=True)\n","    (13): Dropout2d(p=0.4, inplace=False)\n","    (14): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (16): ReLU(inplace=True)\n","    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (19): ReLU(inplace=True)\n","    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (21): Dropout2d(p=0.5, inplace=False)\n","  )\n","  (classifier): Sequential(\n","    (0): Dropout(p=0.5, inplace=False)\n","    (1): Linear(in_features=1024, out_features=1000, bias=True)\n","    (2): ReLU(inplace=True)\n","    (3): Dropout(p=0.5, inplace=False)\n","    (4): Linear(in_features=1000, out_features=256, bias=True)\n","    (5): ReLU(inplace=True)\n","    (6): Linear(in_features=256, out_features=43, bias=True)\n","  )\n",")"]},"execution_count":72,"metadata":{},"output_type":"execute_result"}],"source":["net4 = Net(num_classes=43)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","net4.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RKIgVo3v5erQ"},"outputs":[],"source":["weights_normalized = [weight * len(sorted_train) / sum(weights) for weight in weights]\n","class_weights = torch.tensor(weights_normalized, dtype=torch.float32)\n","if torch.cuda.is_available():\n","    class_weights = class_weights.cuda()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MY7MCvTA5erR"},"outputs":[],"source":["optimizer = optim.Adam(net4.parameters(), lr=0.001)\n","early_stopping = EarlyStopper(patience=5,delta = 0.01)\n","criterion = nn.CrossEntropyLoss(weight=class_weights)"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"MOeZT0n05erR","outputId":"08fc0fe0-4ec8-4187-ff46-e8e12c4a67ec","colab":{"referenced_widgets":["2c366cb6eac245f682f7a264c521b088"]}},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1  batch 1 . Training Loss:  3.7799925804138184\n","Epoch 1  batch 101 . Training Loss:  3.462458848953247\n","Epoch 1  batch 201 . Training Loss:  2.818197011947632\n","Epoch 1: Validation Loss: 2.9514, Validation Accuracy: 8.23%\n","Epoch 2  batch 1 . Training Loss:  2.760685920715332\n","Epoch 2  batch 101 . Training Loss:  2.5269665718078613\n","Epoch 2  batch 201 . Training Loss:  2.2609143257141113\n","Epoch 2: Validation Loss: 2.2359, Validation Accuracy: 26.31%\n","Epoch 3  batch 1 . Training Loss:  2.2194390296936035\n","Epoch 3  batch 101 . Training Loss:  2.5049893856048584\n","Epoch 3  batch 201 . Training Loss:  2.280463695526123\n","Epoch 3: Validation Loss: 1.9806, Validation Accuracy: 33.39%\n","Epoch 4  batch 1 . Training Loss:  2.4278275966644287\n","Epoch 4  batch 101 . Training Loss:  2.079555034637451\n","Epoch 4  batch 201 . Training Loss:  2.0913970470428467\n","Epoch 4: Validation Loss: 1.8345, Validation Accuracy: 33.64%\n","Epoch 5  batch 1 . Training Loss:  1.8381377458572388\n","Epoch 5  batch 101 . Training Loss:  1.9224226474761963\n","Epoch 5  batch 201 . Training Loss:  1.7102911472320557\n","Epoch 5: Validation Loss: 1.5542, Validation Accuracy: 41.64%\n","Epoch 6  batch 1 . Training Loss:  1.8724088668823242\n","Epoch 6  batch 101 . Training Loss:  1.6865379810333252\n","Epoch 6  batch 201 . Training Loss:  1.5590516328811646\n","Epoch 6: Validation Loss: 1.4087, Validation Accuracy: 44.52%\n","Epoch 7  batch 1 . Training Loss:  1.8031749725341797\n","Epoch 7  batch 101 . Training Loss:  1.5023640394210815\n","Epoch 7  batch 201 . Training Loss:  1.7307835817337036\n","Epoch 7: Validation Loss: 1.2767, Validation Accuracy: 49.59%\n","Epoch 8  batch 1 . Training Loss:  1.6356778144836426\n","Epoch 8  batch 101 . Training Loss:  1.3547987937927246\n","Epoch 8  batch 201 . Training Loss:  1.3978163003921509\n","Epoch 8: Validation Loss: 1.1724, Validation Accuracy: 51.41%\n","Epoch 9  batch 1 . Training Loss:  1.4499832391738892\n","Epoch 9  batch 101 . Training Loss:  1.3337634801864624\n","Epoch 9  batch 201 . Training Loss:  1.3923139572143555\n","Epoch 9: Validation Loss: 1.0434, Validation Accuracy: 55.20%\n","Epoch 10  batch 1 . Training Loss:  1.378868579864502\n","Epoch 10  batch 101 . Training Loss:  1.342711329460144\n","Epoch 10  batch 201 . Training Loss:  1.4420387744903564\n","Epoch 10: Validation Loss: 0.9725, Validation Accuracy: 60.89%\n","Epoch 11  batch 1 . Training Loss:  1.2944505214691162\n","Epoch 11  batch 101 . Training Loss:  1.4743415117263794\n","Epoch 11  batch 201 . Training Loss:  1.3430593013763428\n","Epoch 11: Validation Loss: 0.9120, Validation Accuracy: 59.33%\n","Epoch 12  batch 1 . Training Loss:  1.007018804550171\n","Epoch 12  batch 101 . Training Loss:  1.2766239643096924\n","Epoch 12  batch 201 . Training Loss:  1.3544987440109253\n","Epoch 12: Validation Loss: 0.8717, Validation Accuracy: 62.43%\n","Epoch 13  batch 1 . Training Loss:  1.219872236251831\n","Epoch 13  batch 101 . Training Loss:  1.3780308961868286\n","Epoch 13  batch 201 . Training Loss:  1.0606452226638794\n","Epoch 13: Validation Loss: 0.7767, Validation Accuracy: 67.33%\n","Epoch 14  batch 1 . Training Loss:  1.0794702768325806\n","Epoch 14  batch 101 . Training Loss:  0.9292933344841003\n","Epoch 14  batch 201 . Training Loss:  0.9144702553749084\n","Epoch 14: Validation Loss: 0.7621, Validation Accuracy: 66.41%\n","Epoch 15  batch 1 . Training Loss:  0.9097509980201721\n","Epoch 15  batch 101 . Training Loss:  1.1854370832443237\n","Epoch 15  batch 201 . Training Loss:  1.208063006401062\n","Epoch 15: Validation Loss: 0.7305, Validation Accuracy: 68.01%\n","Epoch 16  batch 1 . Training Loss:  0.9362819790840149\n","Epoch 16  batch 101 . Training Loss:  0.8636797070503235\n","Epoch 16  batch 201 . Training Loss:  1.135737419128418\n","Epoch 16: Validation Loss: 0.6781, Validation Accuracy: 70.55%\n","Epoch 17  batch 1 . Training Loss:  0.822738766670227\n","Epoch 17  batch 101 . Training Loss:  1.2686262130737305\n","Epoch 17  batch 201 . Training Loss:  0.9123320579528809\n","Epoch 17: Validation Loss: 0.6475, Validation Accuracy: 69.85%\n","Epoch 18  batch 1 . Training Loss:  0.7616688013076782\n","Epoch 18  batch 101 . Training Loss:  0.874928891658783\n","Epoch 18  batch 201 . Training Loss:  0.7057041525840759\n","Epoch 18: Validation Loss: 0.6257, Validation Accuracy: 70.25%\n","Epoch 19  batch 1 . Training Loss:  0.8116475939750671\n","Epoch 19  batch 101 . Training Loss:  0.9432795643806458\n","Epoch 19  batch 201 . Training Loss:  0.9785894751548767\n","Epoch 19: Validation Loss: 0.6173, Validation Accuracy: 72.86%\n","Epoch 20  batch 1 . Training Loss:  0.7649129033088684\n","Epoch 20  batch 101 . Training Loss:  0.7156556248664856\n","Epoch 20  batch 201 . Training Loss:  0.7857168912887573\n","Epoch 20: Validation Loss: 0.5850, Validation Accuracy: 71.78%\n","Epoch 21  batch 1 . Training Loss:  0.9368995428085327\n","Epoch 21  batch 101 . Training Loss:  0.9708372354507446\n","Epoch 21  batch 201 . Training Loss:  0.8071417808532715\n","Epoch 21: Validation Loss: 0.5150, Validation Accuracy: 76.34%\n","Epoch 22  batch 1 . Training Loss:  0.7977582812309265\n","Epoch 22  batch 101 . Training Loss:  0.8341062068939209\n","Epoch 22  batch 201 . Training Loss:  0.7561854124069214\n","Epoch 22: Validation Loss: 0.5044, Validation Accuracy: 76.71%\n","Epoch 23  batch 1 . Training Loss:  0.8060142397880554\n","Epoch 23  batch 101 . Training Loss:  0.7113621234893799\n","Epoch 23  batch 201 . Training Loss:  0.7307001948356628\n","Epoch 23: Validation Loss: 0.5112, Validation Accuracy: 77.31%\n","Epoch 24  batch 1 . Training Loss:  1.202976107597351\n","Epoch 24  batch 101 . Training Loss:  0.7686097621917725\n","Epoch 24  batch 201 . Training Loss:  0.8339942693710327\n","Epoch 24: Validation Loss: 0.5035, Validation Accuracy: 76.33%\n","Epoch 25  batch 1 . Training Loss:  0.7957324385643005\n","Epoch 25  batch 101 . Training Loss:  0.8234708905220032\n","Epoch 25  batch 201 . Training Loss:  0.7191283106803894\n","Epoch 25: Validation Loss: 0.4820, Validation Accuracy: 76.80%\n","Epoch 26  batch 1 . Training Loss:  0.7894259691238403\n","Epoch 26  batch 101 . Training Loss:  0.577778697013855\n","Epoch 26  batch 201 . Training Loss:  0.7147238850593567\n","Epoch 26: Validation Loss: 0.4572, Validation Accuracy: 78.45%\n","Epoch 27  batch 1 . Training Loss:  0.5425071716308594\n","Epoch 27  batch 101 . Training Loss:  0.6574363112449646\n","Epoch 27  batch 201 . Training Loss:  0.9101371169090271\n","Epoch 27: Validation Loss: 0.4500, Validation Accuracy: 79.33%\n","Epoch 28  batch 1 . Training Loss:  0.6179391145706177\n","Epoch 28  batch 101 . Training Loss:  0.8897379040718079\n","Epoch 28  batch 201 . Training Loss:  0.6513150930404663\n","Epoch 28: Validation Loss: 0.4200, Validation Accuracy: 79.34%\n","Epoch 29  batch 1 . Training Loss:  0.8141284584999084\n","Epoch 29  batch 101 . Training Loss:  0.6459938883781433\n","Epoch 29  batch 201 . Training Loss:  0.5635413527488708\n","Epoch 29: Validation Loss: 0.4289, Validation Accuracy: 79.84%\n","Epoch 30  batch 1 . Training Loss:  0.5357470512390137\n","Epoch 30  batch 101 . Training Loss:  0.7428600788116455\n","Epoch 30  batch 201 . Training Loss:  0.6015947461128235\n","Epoch 30: Validation Loss: 0.3973, Validation Accuracy: 81.11%\n","Epoch 31  batch 1 . Training Loss:  0.6025856733322144\n","Epoch 31  batch 101 . Training Loss:  0.6282156109809875\n","Epoch 31  batch 201 . Training Loss:  0.7736461758613586\n","Epoch 31: Validation Loss: 0.3988, Validation Accuracy: 80.68%\n","Epoch 32  batch 1 . Training Loss:  0.49859821796417236\n","Epoch 32  batch 101 . Training Loss:  0.5209457278251648\n","Epoch 32  batch 201 . Training Loss:  0.636969268321991\n","Epoch 32: Validation Loss: 0.3732, Validation Accuracy: 80.68%\n","Epoch 33  batch 1 . Training Loss:  0.4325016140937805\n","Epoch 33  batch 101 . Training Loss:  0.6626766324043274\n","Epoch 33  batch 201 . Training Loss:  0.8127071857452393\n","Epoch 33: Validation Loss: 0.3740, Validation Accuracy: 80.92%\n","Epoch 34  batch 1 . Training Loss:  0.5739108920097351\n","Epoch 34  batch 101 . Training Loss:  0.8786914944648743\n","Epoch 34  batch 201 . Training Loss:  0.4279607832431793\n","Epoch 34: Validation Loss: 0.3583, Validation Accuracy: 82.26%\n","Epoch 35  batch 1 . Training Loss:  0.4533965289592743\n","Epoch 35  batch 101 . Training Loss:  0.6602651476860046\n","Epoch 35  batch 201 . Training Loss:  0.48467162251472473\n","Epoch 35: Validation Loss: 0.3540, Validation Accuracy: 82.97%\n","Epoch 36  batch 1 . Training Loss:  0.5666436553001404\n","Epoch 36  batch 101 . Training Loss:  0.5169387459754944\n","Epoch 36  batch 201 . Training Loss:  0.7255486845970154\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 36: Validation Loss: 0.3419, Validation Accuracy: 82.68%\n","Epoch 37  batch 1 . Training Loss:  0.629709780216217\n","Epoch 37  batch 101 . Training Loss:  0.7041293382644653\n","Epoch 37  batch 201 . Training Loss:  0.5941136479377747\n","Epoch 37: Validation Loss: 0.3293, Validation Accuracy: 83.03%\n","Epoch 38  batch 1 . Training Loss:  0.5397292971611023\n","Epoch 38  batch 101 . Training Loss:  0.4399472773075104\n","Epoch 38  batch 201 . Training Loss:  0.5783757567405701\n","Epoch 38: Validation Loss: 0.3276, Validation Accuracy: 83.34%\n","Epoch 39  batch 1 . Training Loss:  0.4393775761127472\n","Epoch 39  batch 101 . Training Loss:  0.7997291684150696\n","Epoch 39  batch 201 . Training Loss:  0.43415191769599915\n","Epoch 39: Validation Loss: 0.3153, Validation Accuracy: 83.28%\n","Epoch 40  batch 1 . Training Loss:  0.6963233947753906\n","Epoch 40  batch 101 . Training Loss:  0.6284853219985962\n","Epoch 40  batch 201 . Training Loss:  0.402750700712204\n","Epoch 40: Validation Loss: 0.3017, Validation Accuracy: 85.52%\n","Epoch 41  batch 1 . Training Loss:  0.5771352648735046\n","Epoch 41  batch 101 . Training Loss:  0.5024183988571167\n","Epoch 41  batch 201 . Training Loss:  0.6411054730415344\n","Epoch 41: Validation Loss: 0.2949, Validation Accuracy: 84.44%\n","Epoch 42  batch 1 . Training Loss:  0.6594929695129395\n","Epoch 42  batch 101 . Training Loss:  0.5152023434638977\n","Epoch 42  batch 201 . Training Loss:  0.3927680552005768\n","Epoch 42: Validation Loss: 0.2810, Validation Accuracy: 85.00%\n","Epoch 43  batch 1 . Training Loss:  0.5581358075141907\n","Epoch 43  batch 101 . Training Loss:  0.42878738045692444\n","Epoch 43  batch 201 . Training Loss:  0.6354280114173889\n","Epoch 43: Validation Loss: 0.2916, Validation Accuracy: 84.15%\n","Epoch 44  batch 1 . Training Loss:  0.5532717108726501\n","Epoch 44  batch 101 . Training Loss:  0.7373723983764648\n","Epoch 44  batch 201 . Training Loss:  0.33932921290397644\n","Epoch 44: Validation Loss: 0.2852, Validation Accuracy: 85.21%\n","Epoch 45  batch 1 . Training Loss:  0.49956977367401123\n","Epoch 45  batch 101 . Training Loss:  0.5536851286888123\n","Epoch 45  batch 201 . Training Loss:  0.5085654258728027\n","Epoch 45: Validation Loss: 0.2798, Validation Accuracy: 85.44%\n","Epoch 46  batch 1 . Training Loss:  0.45271456241607666\n","Epoch 46  batch 101 . Training Loss:  0.4511162042617798\n","Epoch 46  batch 201 . Training Loss:  0.43515774607658386\n","Epoch 46: Validation Loss: 0.2573, Validation Accuracy: 86.95%\n","Epoch 47  batch 1 . Training Loss:  0.515126645565033\n","Epoch 47  batch 101 . Training Loss:  0.45473018288612366\n","Epoch 47  batch 201 . Training Loss:  0.41209864616394043\n","Epoch 47: Validation Loss: 0.2632, Validation Accuracy: 86.25%\n","Epoch 48  batch 1 . Training Loss:  0.3914150297641754\n","Epoch 48  batch 101 . Training Loss:  0.36828669905662537\n","Epoch 48  batch 201 . Training Loss:  0.2850566804409027\n","Epoch 48: Validation Loss: 0.2645, Validation Accuracy: 86.93%\n","Epoch 49  batch 1 . Training Loss:  0.6221378445625305\n","Epoch 49  batch 101 . Training Loss:  0.3566179871559143\n","Epoch 49  batch 201 . Training Loss:  0.3969474732875824\n","Epoch 49: Validation Loss: 0.2539, Validation Accuracy: 86.85%\n","Epoch 50  batch 1 . Training Loss:  0.3676316738128662\n","Epoch 50  batch 101 . Training Loss:  0.27812421321868896\n","Epoch 50  batch 201 . Training Loss:  0.41579103469848633\n","Epoch 50: Validation Loss: 0.2400, Validation Accuracy: 87.25%\n","Epoch 51  batch 1 . Training Loss:  0.2739897668361664\n","Epoch 51  batch 101 . Training Loss:  0.3704197406768799\n","Epoch 51  batch 201 . Training Loss:  0.49768829345703125\n","Epoch 51: Validation Loss: 0.2443, Validation Accuracy: 87.25%\n","Epoch 52  batch 1 . Training Loss:  0.49642834067344666\n","Epoch 52  batch 101 . Training Loss:  0.36523881554603577\n","Epoch 52  batch 201 . Training Loss:  0.28134065866470337\n","Epoch 52: Validation Loss: 0.2470, Validation Accuracy: 88.27%\n","Epoch 53  batch 1 . Training Loss:  0.29272136092185974\n","Epoch 53  batch 101 . Training Loss:  0.6372760534286499\n","Epoch 53  batch 201 . Training Loss:  0.5079029202461243\n","Epoch 53: Validation Loss: 0.2298, Validation Accuracy: 87.81%\n","Epoch 54  batch 1 . Training Loss:  0.3327319324016571\n","Epoch 54  batch 101 . Training Loss:  0.7272286415100098\n","Epoch 54  batch 201 . Training Loss:  0.7296207547187805\n","Epoch 54: Validation Loss: 0.2237, Validation Accuracy: 88.09%\n","Epoch 55  batch 1 . Training Loss:  0.359918475151062\n","Epoch 55  batch 101 . Training Loss:  0.5683006644248962\n","Epoch 55  batch 201 . Training Loss:  0.4346923828125\n","Epoch 55: Validation Loss: 0.2266, Validation Accuracy: 88.65%\n","Epoch 56  batch 1 . Training Loss:  0.40638986229896545\n","Epoch 56  batch 101 . Training Loss:  0.5564191341400146\n","Epoch 56  batch 201 . Training Loss:  0.43431445956230164\n","Epoch 56: Validation Loss: 0.2203, Validation Accuracy: 88.34%\n","Epoch 57  batch 1 . Training Loss:  0.33000537753105164\n","Epoch 57  batch 101 . Training Loss:  0.4917154014110565\n","Epoch 57  batch 201 . Training Loss:  0.417368620634079\n","Epoch 57: Validation Loss: 0.2083, Validation Accuracy: 88.85%\n","Epoch 58  batch 1 . Training Loss:  0.2870306968688965\n","Epoch 58  batch 101 . Training Loss:  0.4723410904407501\n","Epoch 58  batch 201 . Training Loss:  0.4630815088748932\n","Epoch 58: Validation Loss: 0.2067, Validation Accuracy: 88.73%\n","Epoch 59  batch 1 . Training Loss:  0.24791787564754486\n","Epoch 59  batch 101 . Training Loss:  0.43286216259002686\n","Epoch 59  batch 201 . Training Loss:  0.34018561244010925\n","Epoch 59: Validation Loss: 0.2126, Validation Accuracy: 89.26%\n","Epoch 60  batch 1 . Training Loss:  0.30910801887512207\n","Epoch 60  batch 101 . Training Loss:  0.5854955911636353\n","Epoch 60  batch 201 . Training Loss:  0.27721545100212097\n","Epoch 60: Validation Loss: 0.2211, Validation Accuracy: 88.97%\n","Epoch 61  batch 1 . Training Loss:  0.3286607265472412\n","Epoch 61  batch 101 . Training Loss:  0.45384812355041504\n","Epoch 61  batch 201 . Training Loss:  0.356112539768219\n","Epoch 61: Validation Loss: 0.2078, Validation Accuracy: 89.27%\n","Epoch 62  batch 1 . Training Loss:  0.37701910734176636\n","Epoch 62  batch 101 . Training Loss:  0.24544399976730347\n","Epoch 62  batch 201 . Training Loss:  0.32520583271980286\n","Epoch 62: Validation Loss: 0.1997, Validation Accuracy: 89.38%\n","Early stopping triggered.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2c366cb6eac245f682f7a264c521b088","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.032 MB of 0.032 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>█▅▆▅▄▃▄▃▃▃▃▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▂▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▆▆▅▄▄▄▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▁▁▁▂▁▁▂▂▂▁▂▁▁▁▂▁▂▁</td></tr><tr><td>val_accuracy</td><td>▁▃▃▄▅▅▆▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇███████████████</td></tr><tr><td>val_loss</td><td>█▆▅▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.32521</td></tr><tr><td>train_loss</td><td>0.6436</td></tr><tr><td>val_accuracy</td><td>89.37636</td></tr><tr><td>val_loss</td><td>0.19973</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">experiment_v5</strong> at: <a href='https://wandb.ai/evafan123/Project%20CNN_v1/runs/7glnky47' target=\"_blank\">https://wandb.ai/evafan123/Project%20CNN_v1/runs/7glnky47</a><br/> View project at: <a href='https://wandb.ai/evafan123/Project%20CNN_v1' target=\"_blank\">https://wandb.ai/evafan123/Project%20CNN_v1</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20240417_165937-7glnky47/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["epochs = 100\n","model = net4\n","for epoch in range(epochs):\n","    # Training loop\n","    model.train()\n","    for i,(images, labels) in enumerate(train_loader):\n","        images, labels = images.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        if i %100 == 0:\n","          print(\"Epoch\", epoch+ 1, \" batch\", i+1, \". Training Loss: \", loss.item())\n","          if enable_wandb:\n","            wandb.log({\"loss\": loss})\n","        wandb.log({\"train_loss\":loss.item()})\n","\n","    # Validation loop\n","    model.eval()\n","    validation_loss = get_loss(val_loader, model, criterion, device)\n","    validation_accuracy = get_accuracy(val_loader, model, device)\n","    wandb.log({\"val_loss\": validation_loss, \"val_accuracy\": validation_accuracy})\n","\n","    print(f'Epoch {epoch+1}: Validation Loss: {validation_loss:.4f}, Validation Accuracy: {validation_accuracy:.2f}%')\n","\n","    if early_stopping.early_stop(validation_loss, model):\n","        print(\"Early stopping triggered.\")\n","        break\n","wandb.finish()"]},{"cell_type":"markdown","metadata":{"id":"QNPAsA3_5erR"},"source":["-------------------------"]},{"cell_type":"markdown","metadata":{"id":"uckKPlrX5erR"},"source":["### CNN Model - 6"]},{"cell_type":"markdown","metadata":{"id":"iSFGquF05erR"},"source":["- Epochs = 50\n","- Batch size = 128\n","- Learning Rates = 0.001\n","- Data Agumentation\n","- Class Balancing\n","- Early Stopping Patience 7"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dq6YUgg15erR","outputId":"756b1c52-161a-4a64-d861-b65a137459a8"},"outputs":[{"data":{"text/html":["Tracking run with wandb version 0.16.6"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/projectnb/ba865/students/evafan/wandb/run-20240419_180207-vtuato2u</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/evafan123/Project%20CNN_v1/runs/vtuato2u' target=\"_blank\">experiment_v6</a></strong> to <a href='https://wandb.ai/evafan123/Project%20CNN_v1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/evafan123/Project%20CNN_v1' target=\"_blank\">https://wandb.ai/evafan123/Project%20CNN_v1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/evafan123/Project%20CNN_v1/runs/vtuato2u' target=\"_blank\">https://wandb.ai/evafan123/Project%20CNN_v1/runs/vtuato2u</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/evafan123/Project%20CNN_v1/runs/vtuato2u?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x14d0094d7280>"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["wandb.init(project=\"Project CNN_v1\", name = 'experiment_v6')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pPY87lJ05erR"},"outputs":[],"source":["wandb.config.update({\n","    \"learning_rate\": 0.001,\n","    \"epochs\": 50,\n","    \"batch_size\": 128,\n","})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E_Hnc0yp5erR"},"outputs":[],"source":["train_transform_1 = transforms.Compose([\n","    transforms.Resize((32, 32)),\n","    transforms.RandomHorizontalFlip(0.5),\n","    transforms.RandomRotation(45),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.3337, 0.3064, 0.3171), (0.2672, 0.2564, 0.2629))\n","])\n","dataset_train = ImageFolder(\n","    'Train',\n","    transform = train_transform_1)\n","\n","train_data, val_data = random_split(dataset_train, [0.8, 0.2])\n","train_loader = DataLoader(train_data, batch_size=128, shuffle=True, num_workers=2)\n","val_loader = DataLoader(val_data, batch_size=128, shuffle=False, num_workers=2)\n","test_loader = DataLoader(dataset_test, shuffle=True, batch_size = 128, num_workers = 2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c2qNfHL_5erR","outputId":"e1a4ca73-f969-441d-d4bd-350c4ab72a25"},"outputs":[{"data":{"text/plain":["Net(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","    (3): Dropout2d(p=0.2, inplace=False)\n","    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (5): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (6): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (7): ReLU(inplace=True)\n","    (8): Dropout2d(p=0.3, inplace=False)\n","    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (10): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (12): ReLU(inplace=True)\n","    (13): Dropout2d(p=0.4, inplace=False)\n","    (14): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (16): ReLU(inplace=True)\n","    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (19): ReLU(inplace=True)\n","    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (21): Dropout2d(p=0.5, inplace=False)\n","  )\n","  (classifier): Sequential(\n","    (0): Dropout(p=0.5, inplace=False)\n","    (1): Linear(in_features=1024, out_features=1000, bias=True)\n","    (2): ReLU(inplace=True)\n","    (3): Dropout(p=0.5, inplace=False)\n","    (4): Linear(in_features=1000, out_features=256, bias=True)\n","    (5): ReLU(inplace=True)\n","    (6): Linear(in_features=256, out_features=43, bias=True)\n","  )\n",")"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["net5 = Net(num_classes=43)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","net5.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"05IAPgJT5erR"},"outputs":[],"source":["weights_normalized = [weight * len(sorted_train) / sum(weights) for weight in weights]\n","class_weights = torch.tensor(weights_normalized, dtype=torch.float32)\n","if torch.cuda.is_available():\n","    class_weights = class_weights.cuda()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cpU9wnS55erR"},"outputs":[],"source":["optimizer = optim.Adam(net5.parameters(), lr=0.001)\n","early_stopping = EarlyStopper(patience=7,delta = 0.01)\n","criterion = nn.CrossEntropyLoss(weight=class_weights)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SnMxgysk5erR","outputId":"938f30f3-c0b3-412b-d1a9-25faf714a4ce","colab":{"referenced_widgets":["26cd7988b8764a4a84b11fb1267f15a1"]}},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1  batch 1 . Training Loss:  3.8933286666870117\n","Epoch 1  batch 101 . Training Loss:  3.487985134124756\n","Epoch 1  batch 201 . Training Loss:  3.0350165367126465\n","Epoch 1: Validation Loss: 2.7386, Validation Accuracy: 9.04%\n","Epoch 2  batch 1 . Training Loss:  2.8283674716949463\n","Epoch 2  batch 101 . Training Loss:  2.5068910121917725\n","Epoch 2  batch 201 . Training Loss:  2.461008310317993\n","Epoch 2: Validation Loss: 2.2643, Validation Accuracy: 23.79%\n","Epoch 3  batch 1 . Training Loss:  2.357834577560425\n","Epoch 3  batch 101 . Training Loss:  2.249356269836426\n","Epoch 3  batch 201 . Training Loss:  2.4024529457092285\n","Epoch 3: Validation Loss: 2.0437, Validation Accuracy: 32.98%\n","Epoch 4  batch 1 . Training Loss:  2.1649677753448486\n","Epoch 4  batch 101 . Training Loss:  2.267047882080078\n","Epoch 4  batch 201 . Training Loss:  1.7670679092407227\n","Epoch 4: Validation Loss: 1.7687, Validation Accuracy: 35.02%\n","Epoch 5  batch 1 . Training Loss:  2.073256731033325\n","Epoch 5  batch 101 . Training Loss:  2.013406991958618\n","Epoch 5  batch 201 . Training Loss:  1.7351325750350952\n","Epoch 5: Validation Loss: 1.6225, Validation Accuracy: 39.61%\n","Epoch 6  batch 1 . Training Loss:  1.8103820085525513\n","Epoch 6  batch 101 . Training Loss:  1.8085758686065674\n","Epoch 6  batch 201 . Training Loss:  1.5275098085403442\n","Epoch 6: Validation Loss: 1.4739, Validation Accuracy: 42.55%\n","Epoch 7  batch 1 . Training Loss:  1.8421608209609985\n","Epoch 7  batch 101 . Training Loss:  1.797104835510254\n","Epoch 7  batch 201 . Training Loss:  1.62933349609375\n","Epoch 7: Validation Loss: 1.3358, Validation Accuracy: 46.78%\n","Epoch 8  batch 1 . Training Loss:  1.7078404426574707\n","Epoch 8  batch 101 . Training Loss:  1.480624794960022\n","Epoch 8  batch 201 . Training Loss:  1.743942379951477\n","Epoch 8: Validation Loss: 1.2650, Validation Accuracy: 49.09%\n","Epoch 9  batch 1 . Training Loss:  1.313990592956543\n","Epoch 9  batch 101 . Training Loss:  1.5314176082611084\n","Epoch 9  batch 201 . Training Loss:  1.520411729812622\n","Epoch 9: Validation Loss: 1.1475, Validation Accuracy: 51.51%\n","Epoch 10  batch 1 . Training Loss:  1.5229980945587158\n","Epoch 10  batch 101 . Training Loss:  1.3000376224517822\n","Epoch 10  batch 201 . Training Loss:  1.1776421070098877\n","Epoch 10: Validation Loss: 1.0892, Validation Accuracy: 53.77%\n","Epoch 11  batch 1 . Training Loss:  1.3685611486434937\n","Epoch 11  batch 101 . Training Loss:  1.3136128187179565\n","Epoch 11  batch 201 . Training Loss:  1.2252600193023682\n","Epoch 11: Validation Loss: 1.1120, Validation Accuracy: 53.64%\n","Epoch 12  batch 1 . Training Loss:  1.2219585180282593\n","Epoch 12  batch 101 . Training Loss:  1.079017996788025\n","Epoch 12  batch 201 . Training Loss:  1.1198700666427612\n","Epoch 12: Validation Loss: 0.9642, Validation Accuracy: 57.21%\n","Epoch 13  batch 1 . Training Loss:  1.2949780225753784\n","Epoch 13  batch 101 . Training Loss:  0.9719895720481873\n","Epoch 13  batch 201 . Training Loss:  1.1573859453201294\n","Epoch 13: Validation Loss: 0.8856, Validation Accuracy: 59.07%\n","Epoch 14  batch 1 . Training Loss:  0.9911688566207886\n","Epoch 14  batch 101 . Training Loss:  1.1792323589324951\n","Epoch 14  batch 201 . Training Loss:  1.1650309562683105\n","Epoch 14: Validation Loss: 0.8501, Validation Accuracy: 62.66%\n","Epoch 15  batch 1 . Training Loss:  1.131832242012024\n","Epoch 15  batch 101 . Training Loss:  1.3182573318481445\n","Epoch 15  batch 201 . Training Loss:  1.2452857494354248\n","Epoch 15: Validation Loss: 0.7783, Validation Accuracy: 63.49%\n","Epoch 16  batch 1 . Training Loss:  0.9916082620620728\n","Epoch 16  batch 101 . Training Loss:  1.2438182830810547\n","Epoch 16  batch 201 . Training Loss:  0.9856945872306824\n","Epoch 16: Validation Loss: 0.7310, Validation Accuracy: 63.24%\n","Epoch 17  batch 1 . Training Loss:  0.9073716998100281\n","Epoch 17  batch 101 . Training Loss:  1.0467723608016968\n","Epoch 17  batch 201 . Training Loss:  1.133931279182434\n","Epoch 17: Validation Loss: 0.7280, Validation Accuracy: 63.35%\n","Epoch 18  batch 1 . Training Loss:  1.0182783603668213\n","Epoch 18  batch 101 . Training Loss:  0.8625841736793518\n","Epoch 18  batch 201 . Training Loss:  1.1141959428787231\n","Epoch 18: Validation Loss: 0.6534, Validation Accuracy: 68.54%\n","Epoch 19  batch 1 . Training Loss:  1.1180119514465332\n","Epoch 19  batch 101 . Training Loss:  0.8253533840179443\n","Epoch 19  batch 201 . Training Loss:  0.9489070177078247\n","Epoch 19: Validation Loss: 0.6060, Validation Accuracy: 70.81%\n","Epoch 20  batch 1 . Training Loss:  0.8464421033859253\n","Epoch 20  batch 101 . Training Loss:  0.9976266026496887\n","Epoch 20  batch 201 . Training Loss:  0.902538001537323\n","Epoch 20: Validation Loss: 0.6049, Validation Accuracy: 70.46%\n","Epoch 21  batch 1 . Training Loss:  0.8408732414245605\n","Epoch 21  batch 101 . Training Loss:  1.0789295434951782\n","Epoch 21  batch 201 . Training Loss:  0.7406579852104187\n","Epoch 21: Validation Loss: 0.6066, Validation Accuracy: 71.06%\n","Epoch 22  batch 1 . Training Loss:  0.7764317989349365\n","Epoch 22  batch 101 . Training Loss:  0.6776530146598816\n","Epoch 22  batch 201 . Training Loss:  1.1039124727249146\n","Epoch 22: Validation Loss: 0.5532, Validation Accuracy: 70.65%\n","Epoch 23  batch 1 . Training Loss:  0.9026547074317932\n","Epoch 23  batch 101 . Training Loss:  0.76783287525177\n","Epoch 23  batch 201 . Training Loss:  0.6748819351196289\n","Epoch 23: Validation Loss: 0.5572, Validation Accuracy: 72.26%\n","Epoch 24  batch 1 . Training Loss:  0.7359688878059387\n","Epoch 24  batch 101 . Training Loss:  0.85833740234375\n","Epoch 24  batch 201 . Training Loss:  0.8189914226531982\n","Epoch 24: Validation Loss: 0.5057, Validation Accuracy: 73.65%\n","Epoch 25  batch 1 . Training Loss:  0.6705139875411987\n","Epoch 25  batch 101 . Training Loss:  0.6394672989845276\n","Epoch 25  batch 201 . Training Loss:  0.6518832445144653\n","Epoch 25: Validation Loss: 0.4865, Validation Accuracy: 75.44%\n","Epoch 26  batch 1 . Training Loss:  0.8245112299919128\n","Epoch 26  batch 101 . Training Loss:  1.0195521116256714\n","Epoch 26  batch 201 . Training Loss:  0.8940483331680298\n","Epoch 26: Validation Loss: 0.4618, Validation Accuracy: 76.36%\n","Epoch 27  batch 1 . Training Loss:  0.9347239136695862\n","Epoch 27  batch 101 . Training Loss:  0.6942223906517029\n","Epoch 27  batch 201 . Training Loss:  0.5574149489402771\n","Epoch 27: Validation Loss: 0.4672, Validation Accuracy: 76.51%\n","Epoch 28  batch 1 . Training Loss:  0.639135479927063\n","Epoch 28  batch 101 . Training Loss:  0.7648078799247742\n","Epoch 28  batch 201 . Training Loss:  0.6141964197158813\n","Epoch 28: Validation Loss: 0.4706, Validation Accuracy: 78.08%\n","Epoch 29  batch 1 . Training Loss:  0.5873894691467285\n","Epoch 29  batch 101 . Training Loss:  0.6982563734054565\n","Epoch 29  batch 201 . Training Loss:  0.742380678653717\n","Epoch 29: Validation Loss: 0.4164, Validation Accuracy: 78.66%\n","Epoch 30  batch 1 . Training Loss:  0.5102918744087219\n","Epoch 30  batch 101 . Training Loss:  0.6556260585784912\n","Epoch 30  batch 201 . Training Loss:  0.58708256483078\n","Epoch 30: Validation Loss: 0.4243, Validation Accuracy: 80.13%\n","Epoch 31  batch 1 . Training Loss:  0.7388165593147278\n","Epoch 31  batch 101 . Training Loss:  0.7257134318351746\n","Epoch 31  batch 201 . Training Loss:  0.6454238295555115\n","Epoch 31: Validation Loss: 0.3998, Validation Accuracy: 79.70%\n","Epoch 32  batch 1 . Training Loss:  0.7705849409103394\n","Epoch 32  batch 101 . Training Loss:  0.6252129673957825\n","Epoch 32  batch 201 . Training Loss:  0.5412643551826477\n","Epoch 32: Validation Loss: 0.3897, Validation Accuracy: 80.73%\n","Epoch 33  batch 1 . Training Loss:  0.581987738609314\n","Epoch 33  batch 101 . Training Loss:  0.521580696105957\n","Epoch 33  batch 201 . Training Loss:  0.5841583013534546\n","Epoch 33: Validation Loss: 0.3886, Validation Accuracy: 79.02%\n","Epoch 34  batch 1 . Training Loss:  0.7022942304611206\n","Epoch 34  batch 101 . Training Loss:  0.5304099917411804\n","Epoch 34  batch 201 . Training Loss:  0.5795632004737854\n","Epoch 34: Validation Loss: 0.3779, Validation Accuracy: 80.37%\n","Epoch 35  batch 1 . Training Loss:  0.569948673248291\n","Epoch 35  batch 101 . Training Loss:  0.7760286927223206\n","Epoch 35  batch 201 . Training Loss:  0.6545551419258118\n","Epoch 35: Validation Loss: 0.3640, Validation Accuracy: 80.64%\n","Epoch 36  batch 1 . Training Loss:  0.5506989359855652\n","Epoch 36  batch 101 . Training Loss:  0.8803251385688782\n","Epoch 36  batch 201 . Training Loss:  0.6241892576217651\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 36: Validation Loss: 0.3379, Validation Accuracy: 82.82%\n","Epoch 37  batch 1 . Training Loss:  0.48224759101867676\n","Epoch 37  batch 101 . Training Loss:  0.5396406054496765\n","Epoch 37  batch 201 . Training Loss:  0.5639005303382874\n","Epoch 37: Validation Loss: 0.3288, Validation Accuracy: 82.83%\n","Epoch 38  batch 1 . Training Loss:  0.5898976922035217\n","Epoch 38  batch 101 . Training Loss:  0.5728935599327087\n","Epoch 38  batch 201 . Training Loss:  0.5638312101364136\n","Epoch 38: Validation Loss: 0.3251, Validation Accuracy: 82.74%\n","Epoch 39  batch 1 . Training Loss:  0.6789456009864807\n","Epoch 39  batch 101 . Training Loss:  0.7256856560707092\n","Epoch 39  batch 201 . Training Loss:  0.582680881023407\n","Epoch 39: Validation Loss: 0.3318, Validation Accuracy: 83.85%\n","Epoch 40  batch 1 . Training Loss:  0.7096741199493408\n","Epoch 40  batch 101 . Training Loss:  0.5494446754455566\n","Epoch 40  batch 201 . Training Loss:  0.43946805596351624\n","Epoch 40: Validation Loss: 0.3085, Validation Accuracy: 84.59%\n","Epoch 41  batch 1 . Training Loss:  0.6134163737297058\n","Epoch 41  batch 101 . Training Loss:  0.34024912118911743\n","Epoch 41  batch 201 . Training Loss:  0.4383082985877991\n","Epoch 41: Validation Loss: 0.2999, Validation Accuracy: 84.29%\n","Epoch 42  batch 1 . Training Loss:  0.5114837288856506\n","Epoch 42  batch 101 . Training Loss:  0.44978025555610657\n","Epoch 42  batch 201 . Training Loss:  0.30910396575927734\n","Epoch 42: Validation Loss: 0.2851, Validation Accuracy: 84.16%\n","Epoch 43  batch 1 . Training Loss:  0.5963035821914673\n","Epoch 43  batch 101 . Training Loss:  0.6283763647079468\n","Epoch 43  batch 201 . Training Loss:  0.4082912504673004\n","Epoch 43: Validation Loss: 0.3022, Validation Accuracy: 83.97%\n","Epoch 44  batch 1 . Training Loss:  0.44156643748283386\n","Epoch 44  batch 101 . Training Loss:  0.47432589530944824\n","Epoch 44  batch 201 . Training Loss:  0.4186505973339081\n","Epoch 44: Validation Loss: 0.2846, Validation Accuracy: 85.21%\n","Epoch 45  batch 1 . Training Loss:  0.49435555934906006\n","Epoch 45  batch 101 . Training Loss:  0.6322654485702515\n","Epoch 45  batch 201 . Training Loss:  0.43442875146865845\n","Epoch 45: Validation Loss: 0.2651, Validation Accuracy: 85.33%\n","Epoch 46  batch 1 . Training Loss:  0.5704811811447144\n","Epoch 46  batch 101 . Training Loss:  0.41315820813179016\n","Epoch 46  batch 201 . Training Loss:  0.46562108397483826\n","Epoch 46: Validation Loss: 0.2762, Validation Accuracy: 85.26%\n","Epoch 47  batch 1 . Training Loss:  0.4653918147087097\n","Epoch 47  batch 101 . Training Loss:  0.36504727602005005\n","Epoch 47  batch 201 . Training Loss:  0.4394806921482086\n","Epoch 47: Validation Loss: 0.2530, Validation Accuracy: 86.47%\n","Epoch 48  batch 1 . Training Loss:  0.4488263726234436\n","Epoch 48  batch 101 . Training Loss:  0.45432546734809875\n","Epoch 48  batch 201 . Training Loss:  0.3470575511455536\n","Epoch 48: Validation Loss: 0.2941, Validation Accuracy: 84.49%\n","Epoch 49  batch 1 . Training Loss:  0.8089742660522461\n","Epoch 49  batch 101 . Training Loss:  0.6135194301605225\n","Epoch 49  batch 201 . Training Loss:  0.4996672570705414\n","Epoch 49: Validation Loss: 0.2489, Validation Accuracy: 86.39%\n","Epoch 50  batch 1 . Training Loss:  0.46162328124046326\n","Epoch 50  batch 101 . Training Loss:  0.3294932544231415\n","Epoch 50  batch 201 . Training Loss:  0.3531564474105835\n","Epoch 50: Validation Loss: 0.2544, Validation Accuracy: 85.69%\n","Epoch 51  batch 1 . Training Loss:  0.5452011823654175\n","Epoch 51  batch 101 . Training Loss:  0.668560802936554\n","Epoch 51  batch 201 . Training Loss:  0.48212388157844543\n","Epoch 51: Validation Loss: 0.2465, Validation Accuracy: 85.81%\n","Epoch 52  batch 1 . Training Loss:  0.572134256362915\n","Epoch 52  batch 101 . Training Loss:  0.6205698847770691\n","Epoch 52  batch 201 . Training Loss:  0.5202555656433105\n","Epoch 52: Validation Loss: 0.2368, Validation Accuracy: 86.94%\n","Epoch 53  batch 1 . Training Loss:  0.41817182302474976\n","Epoch 53  batch 101 . Training Loss:  0.4764518141746521\n","Epoch 53  batch 201 . Training Loss:  0.3753989338874817\n","Epoch 53: Validation Loss: 0.2357, Validation Accuracy: 86.56%\n","Epoch 54  batch 1 . Training Loss:  0.41985803842544556\n","Epoch 54  batch 101 . Training Loss:  0.48858770728111267\n","Epoch 54  batch 201 . Training Loss:  0.32446327805519104\n","Epoch 54: Validation Loss: 0.2358, Validation Accuracy: 87.07%\n","Epoch 55  batch 1 . Training Loss:  0.5524875521659851\n","Epoch 55  batch 101 . Training Loss:  0.45406216382980347\n","Epoch 55  batch 201 . Training Loss:  0.4458305239677429\n","Epoch 55: Validation Loss: 0.2536, Validation Accuracy: 86.57%\n","Epoch 56  batch 1 . Training Loss:  0.48546719551086426\n","Epoch 56  batch 101 . Training Loss:  0.368844598531723\n","Epoch 56  batch 201 . Training Loss:  0.4834800362586975\n","Epoch 56: Validation Loss: 0.2300, Validation Accuracy: 88.14%\n","Epoch 57  batch 1 . Training Loss:  0.5701488852500916\n","Epoch 57  batch 101 . Training Loss:  0.46608734130859375\n","Epoch 57  batch 201 . Training Loss:  0.3758268654346466\n","Epoch 57: Validation Loss: 0.2270, Validation Accuracy: 87.63%\n","Epoch 58  batch 1 . Training Loss:  0.4303678274154663\n","Epoch 58  batch 101 . Training Loss:  0.3825621008872986\n","Epoch 58  batch 201 . Training Loss:  0.3725324869155884\n","Epoch 58: Validation Loss: 0.2202, Validation Accuracy: 88.19%\n","Epoch 59  batch 1 . Training Loss:  0.3178809583187103\n","Epoch 59  batch 101 . Training Loss:  0.6492804884910583\n","Epoch 59  batch 201 . Training Loss:  0.4206717312335968\n","Epoch 59: Validation Loss: 0.2077, Validation Accuracy: 88.08%\n","Epoch 60  batch 1 . Training Loss:  0.39556893706321716\n","Epoch 60  batch 101 . Training Loss:  0.3776470124721527\n","Epoch 60  batch 201 . Training Loss:  0.45279601216316223\n","Epoch 60: Validation Loss: 0.2116, Validation Accuracy: 88.06%\n","Epoch 61  batch 1 . Training Loss:  0.4500146210193634\n","Epoch 61  batch 101 . Training Loss:  0.30960485339164734\n","Epoch 61  batch 201 . Training Loss:  0.44135499000549316\n","Epoch 61: Validation Loss: 0.2149, Validation Accuracy: 87.97%\n","Epoch 62  batch 1 . Training Loss:  0.3962472677230835\n","Epoch 62  batch 101 . Training Loss:  0.3895207345485687\n","Epoch 62  batch 201 . Training Loss:  0.2671279013156891\n","Epoch 62: Validation Loss: 0.2098, Validation Accuracy: 88.60%\n","Epoch 63  batch 1 . Training Loss:  0.47037068009376526\n","Epoch 63  batch 101 . Training Loss:  0.4704485535621643\n","Epoch 63  batch 201 . Training Loss:  0.42903417348861694\n","Epoch 63: Validation Loss: 0.1879, Validation Accuracy: 89.06%\n","Epoch 64  batch 1 . Training Loss:  0.3848489820957184\n","Epoch 64  batch 101 . Training Loss:  0.5571913719177246\n","Epoch 64  batch 201 . Training Loss:  0.26941195130348206\n","Epoch 64: Validation Loss: 0.2012, Validation Accuracy: 88.19%\n","Epoch 65  batch 1 . Training Loss:  0.28742432594299316\n","Epoch 65  batch 101 . Training Loss:  0.35414883494377136\n","Epoch 65  batch 201 . Training Loss:  0.3864723742008209\n","Epoch 65: Validation Loss: 0.2025, Validation Accuracy: 88.66%\n","Epoch 66  batch 1 . Training Loss:  0.4324811100959778\n","Epoch 66  batch 101 . Training Loss:  0.49255070090293884\n","Epoch 66  batch 201 . Training Loss:  0.3866811990737915\n","Epoch 66: Validation Loss: 0.1877, Validation Accuracy: 88.92%\n","Epoch 67  batch 1 . Training Loss:  0.3414969742298126\n","Epoch 67  batch 101 . Training Loss:  0.6010718941688538\n","Epoch 67  batch 201 . Training Loss:  0.39616572856903076\n","Epoch 67: Validation Loss: 0.1912, Validation Accuracy: 88.42%\n","Epoch 68  batch 1 . Training Loss:  0.44872644543647766\n","Epoch 68  batch 101 . Training Loss:  0.3314562439918518\n","Epoch 68  batch 201 . Training Loss:  0.306258887052536\n","Epoch 68: Validation Loss: 0.1655, Validation Accuracy: 90.15%\n","Epoch 69  batch 1 . Training Loss:  0.3639604151248932\n","Epoch 69  batch 101 . Training Loss:  0.2525911033153534\n","Epoch 69  batch 201 . Training Loss:  0.3575429618358612\n","Epoch 69: Validation Loss: 0.1875, Validation Accuracy: 90.15%\n","Epoch 70  batch 1 . Training Loss:  0.2859802544116974\n","Epoch 70  batch 101 . Training Loss:  0.42927008867263794\n","Epoch 70  batch 201 . Training Loss:  0.3522763252258301\n","Epoch 70: Validation Loss: 0.1876, Validation Accuracy: 88.96%\n","Epoch 71  batch 1 . Training Loss:  0.5773104429244995\n","Epoch 71  batch 101 . Training Loss:  0.2803310751914978\n","Epoch 71  batch 201 . Training Loss:  0.3395494520664215\n","Epoch 71: Validation Loss: 0.1859, Validation Accuracy: 89.87%\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 72  batch 1 . Training Loss:  0.26299765706062317\n","Epoch 72  batch 101 . Training Loss:  0.3608761131763458\n","Epoch 72  batch 201 . Training Loss:  0.44342151284217834\n","Epoch 72: Validation Loss: 0.1754, Validation Accuracy: 90.32%\n","Epoch 73  batch 1 . Training Loss:  0.36048686504364014\n","Epoch 73  batch 101 . Training Loss:  0.34961360692977905\n","Epoch 73  batch 201 . Training Loss:  0.36577674746513367\n","Epoch 73: Validation Loss: 0.1560, Validation Accuracy: 91.07%\n","Epoch 74  batch 1 . Training Loss:  0.4020003080368042\n","Epoch 74  batch 101 . Training Loss:  0.4022863209247589\n","Epoch 74  batch 201 . Training Loss:  0.42391663789749146\n","Epoch 74: Validation Loss: 0.1651, Validation Accuracy: 90.95%\n","Epoch 75  batch 1 . Training Loss:  0.37245362997055054\n","Epoch 75  batch 101 . Training Loss:  0.3831147849559784\n","Epoch 75  batch 201 . Training Loss:  0.2977456748485565\n","Epoch 75: Validation Loss: 0.1687, Validation Accuracy: 90.38%\n","Early stopping triggered.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"26cd7988b8764a4a84b11fb1267f15a1","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.004 MB of 0.004 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>█▆▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▂▁▂▁▁▁▁▁▂▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▇▆▅▅▄▅▃▃▃▃▃▃▂▂▃▂▂▂▂▂▁▁▂▂▂▂▂▂▂▂▁▁▁▁▂▂▁▁▂</td></tr><tr><td>val_accuracy</td><td>▁▂▃▄▄▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇██████████████</td></tr><tr><td>val_loss</td><td>█▇▅▅▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.29775</td></tr><tr><td>train_loss</td><td>0.38454</td></tr><tr><td>val_accuracy</td><td>90.38388</td></tr><tr><td>val_loss</td><td>0.1687</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">experiment_v6</strong> at: <a href='https://wandb.ai/evafan123/Project%20CNN_v1/runs/vtuato2u' target=\"_blank\">https://wandb.ai/evafan123/Project%20CNN_v1/runs/vtuato2u</a><br/> View project at: <a href='https://wandb.ai/evafan123/Project%20CNN_v1' target=\"_blank\">https://wandb.ai/evafan123/Project%20CNN_v1</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20240419_180207-vtuato2u/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["epochs = 100\n","model = net5\n","for epoch in range(epochs):\n","    # Training loop\n","    model.train()\n","    for i,(images, labels) in enumerate(train_loader):\n","        images, labels = images.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        if i %100 == 0:\n","          print(\"Epoch\", epoch+ 1, \" batch\", i+1, \". Training Loss: \", loss.item())\n","          if enable_wandb:\n","            wandb.log({\"loss\": loss})\n","        wandb.log({\"train_loss\":loss.item()})\n","\n","    # Validation loop\n","    model.eval()\n","    validation_loss = get_loss(val_loader, model, criterion, device)\n","    validation_accuracy = get_accuracy(val_loader, model, device)\n","    wandb.log({\"val_loss\": validation_loss, \"val_accuracy\": validation_accuracy})\n","\n","    print(f'Epoch {epoch+1}: Validation Loss: {validation_loss:.4f}, Validation Accuracy: {validation_accuracy:.2f}%')\n","\n","    if early_stopping.early_stop(validation_loss, model):\n","        print(\"Early stopping triggered.\")\n","        break\n","wandb.finish()"]},{"cell_type":"markdown","metadata":{"id":"OczgK69v5erR"},"source":["-------------------"]},{"cell_type":"markdown","source":["## CNN Model 1 - Applying to Test Data\n","\n","Our CNN Model 1 had the best validation performance accross all models, inccluding our MLPs and Pre-Trained models in the other notebooks for this project. Therefore, we decided to deploy such model on our test data to get a final test score."],"metadata":{"id":"LSo6PcZL_ctE"}},{"cell_type":"code","source":["#We found that some images on the test data were \"bad files\", since they weere\n","#only 5 files in the entire test dataset we decided to remove them\n","from PIL import Image\n","import os\n","\n","def check_images(directory):\n","    for root, dirs, files in os.walk(directory):\n","        for file in files:\n","            if file.endswith(\".png\"):\n","                path = os.path.join(root, file)\n","                try:\n","                    with Image.open(path) as img:\n","                        img.verify()  #Verifies that this is an image\n","                except (IOError, SyntaxError) as e:\n","                    print(f'Bad file: {path} - {e}')\n","\n","check_images('Test_organized')\n","\n","\n","#List of problematic image files\n","bad_files = [\n","    'Test_organized/33/06392.png',\n","    'Test_organized/10/06389.png',\n","    'Test_organized/01/06390.png',\n","    'Test_organized/18/06393.png',\n","    'Test_organized/25/06391.png'\n","]\n","\n","#Remove each bad file\n","for file_path in bad_files:\n","    try:\n","        os.remove(file_path)\n","        print(f\"Successfully removed {file_path}\")\n","    except Exception as e:\n","        print(f\"Failed to remove {file_path}: {e}\")"],"metadata":{"id":"Md4qWJdDCsli"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset_test = ImageFolder(\n","    'Test_organized',\n","    transform = train_transforms\n",")\n","\n","test_loader = DataLoader(dataset_test, shuffle=True, batch_size = 128, num_workers = 2)"],"metadata":{"id":"Rmdlk0p-G5Xy","executionInfo":{"status":"ok","timestamp":1713973437611,"user_tz":240,"elapsed":154,"user":{"displayName":"Victor Floriano","userId":"16962368443903150562"}}},"execution_count":103,"outputs":[]},{"cell_type":"code","source":["# Test loop\n","model.eval()\n","with torch.no_grad():\n","  test_loss = get_loss(test_loader, model, criterion, device) #We used the model as defined in CNN Model 1\n","  test_accuracy = get_accuracy(test_loader, model, device)\n","\n","\n","  print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0F7IHI_q_7Vb","executionInfo":{"status":"ok","timestamp":1713973447568,"user_tz":240,"elapsed":8547,"user":{"displayName":"Victor Floriano","userId":"16962368443903150562"}},"outputId":"470923d6-7dbe-45c1-c338-a7b15bae4173"},"execution_count":104,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Loss: 0.2796, Test Accuracy: 93.62%\n"]}]},{"cell_type":"markdown","metadata":{"id":"c3OZOY6q5erS"},"source":["# Sources:\n","- Generative AI was utilized for Debugging, code improvement, create loop to remove deffective images, sentence structure and grammar.\n","- https://github.com/poojahira/gtsrb-pytorch"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"widgets":{"application/vnd.jupyter.widget-state+json":{"38ae9d00cd8649dd913e21037008ff26":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_ba31b910bd4745fb8d8b490030dd970b","IPY_MODEL_f30483a27c054f3f8830282f8cb182bc"],"layout":"IPY_MODEL_fb8b87863b60462a87fb7ecf3d5e5f68"}},"ba31b910bd4745fb8d8b490030dd970b":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0a6e09ef92694d5b8a4ff59ab2b536b5","placeholder":"​","style":"IPY_MODEL_e836384c18e5469d9f23774753023dee","value":"0.070 MB of 0.070 MB uploaded\r"}},"f30483a27c054f3f8830282f8cb182bc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_818512302e4a4b909976482afd56a7a0","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_26071e393c524cd1b2e76e65d191fabd","value":1}},"fb8b87863b60462a87fb7ecf3d5e5f68":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a6e09ef92694d5b8a4ff59ab2b536b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e836384c18e5469d9f23774753023dee":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"818512302e4a4b909976482afd56a7a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"26071e393c524cd1b2e76e65d191fabd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6dccedb9018843bc8095d85ffaeac36a":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_035febd0690f420ca196cdd72d3e0df4","IPY_MODEL_92a9b1f5a61a4eb8b8c95755a8152a5d"],"layout":"IPY_MODEL_7fa2da7993be48978c35ab09f63fa975"}},"035febd0690f420ca196cdd72d3e0df4":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1526d043e3cf4a2ba3fcc7192f23af25","placeholder":"​","style":"IPY_MODEL_b0f6dde0665c4d6580aa3f08ca2f8e92","value":"0.017 MB of 0.017 MB uploaded\r"}},"92a9b1f5a61a4eb8b8c95755a8152a5d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_eaa76a2263fc468a8bff4116c5fce39e","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a8c672a2bf8c41f2bde16984992b8fd4","value":1}},"7fa2da7993be48978c35ab09f63fa975":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1526d043e3cf4a2ba3fcc7192f23af25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b0f6dde0665c4d6580aa3f08ca2f8e92":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eaa76a2263fc468a8bff4116c5fce39e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8c672a2bf8c41f2bde16984992b8fd4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}}},"nbformat":4,"nbformat_minor":0}