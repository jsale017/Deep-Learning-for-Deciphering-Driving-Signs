{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensorflow\n",
      "  Obtaining dependency information for tensorflow from https://files.pythonhosted.org/packages/a8/dc/e5797d6bf966cd3baa5a6ae32bec31472934c9021ca1505dc7bf5c8fc902/tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages (from tensorflow) (1.4.0)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Obtaining dependency information for astunparse>=1.6.0 from https://files.pythonhosted.org/packages/2b/03/13dde6512ad7b4557eb792fbcf0c653af6076b81e5941d36ec61f7ce6028/astunparse-1.6.3-py2.py3-none-any.whl.metadata\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=23.5.26 (from tensorflow)\n",
      "  Obtaining dependency information for flatbuffers>=23.5.26 from https://files.pythonhosted.org/packages/41/f0/7e988a019bc54b2dbd0ad4182ef2d53488bb02e58694cd79d61369e85900/flatbuffers-24.3.25-py2.py3-none-any.whl.metadata\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages (from tensorflow) (0.5.4)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Obtaining dependency information for google-pasta>=0.1.1 from https://files.pythonhosted.org/packages/a3/de/c648ef6835192e6e2cc03f40b19eeda4382c49b5bafb43d88b931c4c74ac/google_pasta-0.2.0-py3-none-any.whl.metadata\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py>=3.10.0 (from tensorflow)\n",
      "  Obtaining dependency information for h5py>=3.10.0 from https://files.pythonhosted.org/packages/94/00/94bf8573e7487b7c37f2b613fc381880d48ec2311f2e859b8a5817deb4df/h5py-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading h5py-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Obtaining dependency information for libclang>=13.0.0 from https://files.pythonhosted.org/packages/1d/fc/716c1e62e512ef1c160e7984a73a5fc7df45166f2ff3f254e71c58076f7c/libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting ml-dtypes~=0.3.1 (from tensorflow)\n",
      "  Obtaining dependency information for ml-dtypes~=0.3.1 from https://files.pythonhosted.org/packages/71/01/7dc0e2cdead686a758810d08fd4111602088fe3f0d88064a83cbfb635593/ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages (from tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages (from tensorflow) (4.23.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages (from tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Obtaining dependency information for termcolor>=1.1.0 from https://files.pythonhosted.org/packages/d9/5f/8c716e47b3a50cbd7c146f45881e11d9414def768b7cd9c5e6650ec2a80a/termcolor-2.4.0-py3-none-any.whl.metadata\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr4/ba820/evafan/.local/lib/python3.10/site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages (from tensorflow) (1.15.0)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Obtaining dependency information for grpcio<2.0,>=1.24.3 from https://files.pythonhosted.org/packages/c9/45/e9237e5fa69bdc2cf01e6ef2be3a421cb1c2c30dbb4e0859ad9ed3bcde0c/grpcio-1.62.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading grpcio-1.62.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard<2.17,>=2.16 (from tensorflow)\n",
      "  Obtaining dependency information for tensorboard<2.17,>=2.16 from https://files.pythonhosted.org/packages/3a/d0/b97889ffa769e2d1fdebb632084d5e8b53fc299d43a537acee7ec0c021a3/tensorboard-2.16.2-py3-none-any.whl.metadata\n",
      "  Downloading tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.0.0 (from tensorflow)\n",
      "  Obtaining dependency information for keras>=3.0.0 from https://files.pythonhosted.org/packages/48/a6/ac5cc97a2677e07d3ac359d05cfb2974ec16c8c8ae6dd265e94706256608/keras-3.2.1-py3-none-any.whl.metadata\n",
      "  Downloading keras-3.2.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Obtaining dependency information for tensorflow-io-gcs-filesystem>=0.23.1 from https://files.pythonhosted.org/packages/7a/5f/2cce4de2189f72e8d0b2bf7de1f3270cdaf397f8458008e79584b024e5a4/tensorflow_io_gcs_filesystem-0.36.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.36.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages (from tensorflow) (1.24.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
      "Requirement already satisfied: rich in /share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (13.4.2)\n",
      "Collecting namex (from keras>=3.0.0->tensorflow)\n",
      "  Obtaining dependency information for namex from https://files.pythonhosted.org/packages/cd/43/b971880e2eb45c0bee2093710ae8044764a89afe9620df34a231c6f0ecd2/namex-0.0.7-py3-none-any.whl.metadata\n",
      "  Downloading namex-0.0.7-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.0.0->tensorflow)\n",
      "  Obtaining dependency information for optree from https://files.pythonhosted.org/packages/0b/1b/afe635bae61fedc09fc702e7162fe7f31f437c872f827d22b04fa4861c29/optree-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading optree-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.4/45.4 kB\u001b[0m \u001b[31m102.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr4/ba820/evafan/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.4.3)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.17,>=2.16->tensorflow)\n",
      "  Obtaining dependency information for tensorboard-data-server<0.8.0,>=0.7.0 from https://files.pythonhosted.org/packages/7a/13/e503968fefabd4c6b2650af21e110aa8466fe21432cd7c43a84577a89438/tensorboard_data_server-0.7.2-py3-none-any.whl.metadata\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (2.3.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /share/pkg.8/python3/3.10.12/install/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n",
      "Downloading tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (589.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.8/589.8 MB\u001b[0m \u001b[31m173.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m340.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.62.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m144.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading h5py-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m216.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.2.1-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m426.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m179.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m228.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m241.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.36.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m210.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading namex-0.0.7-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (311 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m461.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: namex, libclang, flatbuffers, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, optree, ml-dtypes, h5py, grpcio, google-pasta, astunparse, tensorboard, keras, tensorflow\n",
      "\u001b[33m  WARNING: The script tensorboard is installed in '/usr4/ba820/evafan/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The scripts import_pb_to_tensorboard, saved_model_cli, tensorboard, tf_upgrade_v2, tflite_convert, toco and toco_from_protos are installed in '/usr4/ba820/evafan/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed astunparse-1.6.3 flatbuffers-24.3.25 google-pasta-0.2.0 grpcio-1.62.1 h5py-3.11.0 keras-3.2.1 libclang-18.1.1 ml-dtypes-0.3.2 namex-0.0.7 optree-0.11.0 tensorboard-2.16.2 tensorboard-data-server-0.7.2 tensorflow-2.16.1 tensorflow-io-gcs-filesystem-0.36.0 termcolor-2.4.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-17 13:47:20.397188: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-17 13:47:20.443211: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-17 13:47:22.395614: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!find Train -name .ipynb_checkpoints -exec rm -r {} +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enable_wandb = True\n",
    "use_gpu = True\n",
    "gpu_available = torch.cuda.is_available()\n",
    "gpu_available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mevafan12\u001b[0m (\u001b[33mevafan123\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "if enable_wandb:\n",
    "  !pip install wandb -qU\n",
    "  import wandb\n",
    "  wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t1_mRxBrBq98"
   },
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'00': 210, '01': 2220, '02': 2250, '03': 1410, '04': 1980, '05': 1860, '06': 420, '07': 1440, '08': 1410, '09': 1470, '10': 2010, '11': 1320, '12': 2100, '13': 2160, '14': 780, '15': 630, '16': 420, '17': 1110, '18': 1200, '19': 210, '20': 360, '21': 330, '22': 390, '23': 510, '24': 270, '25': 1500, '26': 600, '27': 240, '28': 540, '29': 270, '30': 450, '31': 780, '32': 240, '33': 689, '34': 420, '35': 1200, '36': 390, '37': 210, '38': 2070, '39': 300, '40': 360, '41': 240, '42': 240}\n",
      "Total images across all categories for training: 39209\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def count_images_per_category(directory):\n",
    "    category_image_count = {}\n",
    "\n",
    "    for category in os.listdir(directory):\n",
    "        category_path = os.path.join(directory, category)\n",
    "        \n",
    "        if os.path.isdir(category_path):\n",
    "            num_images = len([item for item in os.listdir(category_path) if item.endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))])\n",
    "            category_image_count[category] = num_images\n",
    "\n",
    "    return category_image_count\n",
    "\n",
    "dataset_directory = 'Train'\n",
    "image_counts = count_images_per_category(dataset_directory)\n",
    "sorted_train = {key: image_counts[key] for key in sorted(image_counts.keys(), key=lambda x: int(x))}\n",
    "\n",
    "print(sorted_train)\n",
    "total_train = sum(sorted_train.values())\n",
    "print(f\"Total images across all categories for training: {total_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': 60, '1': 720, '2': 750, '3': 450, '4': 660, '5': 630, '6': 150, '7': 450, '8': 450, '9': 480, '10': 660, '11': 420, '12': 690, '13': 720, '14': 270, '15': 210, '16': 150, '17': 360, '18': 390, '19': 60, '20': 90, '21': 90, '22': 120, '23': 150, '24': 90, '25': 480, '26': 180, '27': 60, '28': 150, '29': 90, '30': 150, '31': 270, '32': 60, '33': 210, '34': 120, '35': 390, '36': 120, '37': 60, '38': 690, '39': 90, '40': 90, '41': 60, '42': 90}\n",
      "Total images across all categories for testing: 12630\n"
     ]
    }
   ],
   "source": [
    "dataset_directory = 'Test_organized'\n",
    "image_counts = count_images_per_category(dataset_directory)\n",
    "sorted_test = {key: image_counts[key] for key in sorted(image_counts.keys(), key=lambda x: int(x))}\n",
    "\n",
    "print(sorted_test)\n",
    "total_test = sum(sorted_test.values())\n",
    "print(f\"Total images across all categories for testing: {total_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((32,32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.3337, 0.3064, 0.3171), (0.2672, 0.2564, 0.2629))\n",
    "])\n",
    "\n",
    "dataset_train = ImageFolder(\n",
    "    'Train',\n",
    "    transform = train_transforms\n",
    ")\n",
    "dataset_test = ImageFolder(\n",
    "    'Test_organized',\n",
    "    transform = train_transforms\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "vC9D4yTsTbVH"
   },
   "outputs": [],
   "source": [
    "train_data, val_data = random_split(dataset_train, [0.8, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OUafymzHCmPB"
   },
   "source": [
    "https://github.com/poojahira/gtsrb-pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L8My4yFsBugm"
   },
   "source": [
    "### CNN Model - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/projectnb/ba865/students/evafan/wandb/run-20240417_135058-ezmhd20p</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/evafan123/Project%20CNN_v1/runs/ezmhd20p' target=\"_blank\">experiment_v1</a></strong> to <a href='https://wandb.ai/evafan123/Project%20CNN_v1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/evafan123/Project%20CNN_v1' target=\"_blank\">https://wandb.ai/evafan123/Project%20CNN_v1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/evafan123/Project%20CNN_v1/runs/ezmhd20p' target=\"_blank\">https://wandb.ai/evafan123/Project%20CNN_v1/runs/ezmhd20p</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/evafan123/Project%20CNN_v1/runs/ezmhd20p?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x150cbf0329e0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"Project CNN_v1\", name = 'experiment_v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_data, batch_size=64, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(dataset_test, shuffle=True, batch_size = 64, num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "EL-scXGS6Ocj"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        # Define feature extractor\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(0.2),\n",
    "\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=64, out_channels=192, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(0.3),\n",
    "\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=192, out_channels=384, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(384),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(0.4),\n",
    "\n",
    "            nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Dropout2d(0.5)\n",
    "            )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256 * 2 * 2, 1000),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(in_features=1000, out_features=256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, num_classes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass input through feature extractor and classifier\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten the features\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9jEd8x08Iasw",
    "outputId": "c9bfeaea-9c33-4d8c-8f6c-e140ed1f7e32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 16, 16]           1,792\n",
      "       BatchNorm2d-2           [-1, 64, 16, 16]             128\n",
      "              ReLU-3           [-1, 64, 16, 16]               0\n",
      "         Dropout2d-4           [-1, 64, 16, 16]               0\n",
      "         MaxPool2d-5             [-1, 64, 8, 8]               0\n",
      "            Conv2d-6            [-1, 192, 8, 8]         110,784\n",
      "       BatchNorm2d-7            [-1, 192, 8, 8]             384\n",
      "              ReLU-8            [-1, 192, 8, 8]               0\n",
      "         Dropout2d-9            [-1, 192, 8, 8]               0\n",
      "        MaxPool2d-10            [-1, 192, 4, 4]               0\n",
      "           Conv2d-11            [-1, 384, 4, 4]         663,936\n",
      "      BatchNorm2d-12            [-1, 384, 4, 4]             768\n",
      "             ReLU-13            [-1, 384, 4, 4]               0\n",
      "        Dropout2d-14            [-1, 384, 4, 4]               0\n",
      "           Conv2d-15            [-1, 256, 4, 4]         884,992\n",
      "      BatchNorm2d-16            [-1, 256, 4, 4]             512\n",
      "             ReLU-17            [-1, 256, 4, 4]               0\n",
      "           Conv2d-18            [-1, 256, 4, 4]         590,080\n",
      "      BatchNorm2d-19            [-1, 256, 4, 4]             512\n",
      "             ReLU-20            [-1, 256, 4, 4]               0\n",
      "        MaxPool2d-21            [-1, 256, 2, 2]               0\n",
      "        Dropout2d-22            [-1, 256, 2, 2]               0\n",
      "          Dropout-23                 [-1, 1024]               0\n",
      "           Linear-24                 [-1, 1000]       1,025,000\n",
      "             ReLU-25                 [-1, 1000]               0\n",
      "          Dropout-26                 [-1, 1000]               0\n",
      "           Linear-27                  [-1, 256]         256,256\n",
      "             ReLU-28                  [-1, 256]               0\n",
      "           Linear-29                   [-1, 43]          11,051\n",
      "================================================================\n",
      "Total params: 3,546,195\n",
      "Trainable params: 3,546,195\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.36\n",
      "Params size (MB): 13.53\n",
      "Estimated Total Size (MB): 14.89\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "net = Net(num_classes=43)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net.to(device)\n",
    "summary(net,(3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.config.update({\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"epochs\": 100,\n",
    "    \"batch_size\": 64\n",
    "})\n",
    "wandb.watch(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "UbY4EQAuMcZp"
   },
   "outputs": [],
   "source": [
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1, delta=0):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = float('inf')\n",
    "        self.best_model = None\n",
    "\n",
    "    def early_stop(self, validation_loss, model):\n",
    "        if validation_loss < self.min_validation_loss - self.delta:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "            self.best_model = model.state_dict()\n",
    "        elif validation_loss >= self.min_validation_loss - self.delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                model.load_state_dict(self.best_model)\n",
    "                return True\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "4nYeXugSSTCA"
   },
   "outputs": [],
   "source": [
    "def get_loss(loader, model, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()  # Sum up batch loss\n",
    "\n",
    "    average_loss = total_loss / len(loader)\n",
    "    return average_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "BZ6KLxmTSYJk"
   },
   "outputs": [],
   "source": [
    "def get_accuracy(dataloader, model, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "cu1wauFWRqhM"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "early_stopping = EarlyStopper(patience=5,delta = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UVXEYoxVRqeC",
    "outputId": "0409de5a-6998-4b27-ba0d-562376610db9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1  batch 1 . Training Loss:  3.740623712539673\n",
      "Epoch 1  batch 101 . Training Loss:  3.2844128608703613\n",
      "Epoch 1  batch 201 . Training Loss:  2.627850294113159\n",
      "Epoch 1  batch 301 . Training Loss:  2.0726101398468018\n",
      "Epoch 1  batch 401 . Training Loss:  2.0345070362091064\n",
      "Epoch 1: Validation Loss: 1.6195, Validation Accuracy: 42.10%\n",
      "Epoch 2  batch 1 . Training Loss:  1.851232886314392\n",
      "Epoch 2  batch 101 . Training Loss:  1.8435171842575073\n",
      "Epoch 2  batch 201 . Training Loss:  1.7504080533981323\n",
      "Epoch 2  batch 301 . Training Loss:  1.6081430912017822\n",
      "Epoch 2  batch 401 . Training Loss:  1.6278976202011108\n",
      "Epoch 2: Validation Loss: 1.2251, Validation Accuracy: 56.70%\n",
      "Epoch 3  batch 1 . Training Loss:  1.5973659753799438\n",
      "Epoch 3  batch 101 . Training Loss:  1.3043276071548462\n",
      "Epoch 3  batch 201 . Training Loss:  1.249068260192871\n",
      "Epoch 3  batch 301 . Training Loss:  1.0592491626739502\n",
      "Epoch 3  batch 401 . Training Loss:  0.9640299677848816\n",
      "Epoch 3: Validation Loss: 0.7157, Validation Accuracy: 73.50%\n",
      "Epoch 4  batch 1 . Training Loss:  1.3602714538574219\n",
      "Epoch 4  batch 101 . Training Loss:  0.7825140953063965\n",
      "Epoch 4  batch 201 . Training Loss:  0.9009556174278259\n",
      "Epoch 4  batch 301 . Training Loss:  0.8996531963348389\n",
      "Epoch 4  batch 401 . Training Loss:  0.9044365882873535\n",
      "Epoch 4: Validation Loss: 0.3954, Validation Accuracy: 86.94%\n",
      "Epoch 5  batch 1 . Training Loss:  0.912706732749939\n",
      "Epoch 5  batch 101 . Training Loss:  0.5289360284805298\n",
      "Epoch 5  batch 201 . Training Loss:  0.6213037371635437\n",
      "Epoch 5  batch 301 . Training Loss:  0.5647568106651306\n",
      "Epoch 5  batch 401 . Training Loss:  0.44137299060821533\n",
      "Epoch 5: Validation Loss: 0.2777, Validation Accuracy: 90.32%\n",
      "Epoch 6  batch 1 . Training Loss:  0.49486085772514343\n",
      "Epoch 6  batch 101 . Training Loss:  0.41668444871902466\n",
      "Epoch 6  batch 201 . Training Loss:  0.2856026291847229\n",
      "Epoch 6  batch 301 . Training Loss:  0.291103720664978\n",
      "Epoch 6  batch 401 . Training Loss:  0.4116847515106201\n",
      "Epoch 6: Validation Loss: 0.2061, Validation Accuracy: 92.96%\n",
      "Epoch 7  batch 1 . Training Loss:  0.5296012759208679\n",
      "Epoch 7  batch 101 . Training Loss:  0.5151572823524475\n",
      "Epoch 7  batch 201 . Training Loss:  0.41430017352104187\n",
      "Epoch 7  batch 301 . Training Loss:  0.1536451131105423\n",
      "Epoch 7  batch 401 . Training Loss:  0.17430225014686584\n",
      "Epoch 7: Validation Loss: 0.1356, Validation Accuracy: 95.57%\n",
      "Epoch 8  batch 1 . Training Loss:  0.2599322199821472\n",
      "Epoch 8  batch 101 . Training Loss:  0.3348589837551117\n",
      "Epoch 8  batch 201 . Training Loss:  0.26504069566726685\n",
      "Epoch 8  batch 301 . Training Loss:  0.16440162062644958\n",
      "Epoch 8  batch 401 . Training Loss:  0.12172074615955353\n",
      "Epoch 8: Validation Loss: 0.1275, Validation Accuracy: 95.86%\n",
      "Epoch 9  batch 1 . Training Loss:  0.17489105463027954\n",
      "Epoch 9  batch 101 . Training Loss:  0.30732041597366333\n",
      "Epoch 9  batch 201 . Training Loss:  0.33956119418144226\n",
      "Epoch 9  batch 301 . Training Loss:  0.2623386085033417\n",
      "Epoch 9  batch 401 . Training Loss:  0.24358808994293213\n",
      "Epoch 9: Validation Loss: 0.1042, Validation Accuracy: 96.93%\n",
      "Epoch 10  batch 1 . Training Loss:  0.23368699848651886\n",
      "Epoch 10  batch 101 . Training Loss:  0.11742454767227173\n",
      "Epoch 10  batch 201 . Training Loss:  0.21164977550506592\n",
      "Epoch 10  batch 301 . Training Loss:  0.19573433697223663\n",
      "Epoch 10  batch 401 . Training Loss:  0.2677750289440155\n",
      "Epoch 10: Validation Loss: 0.0861, Validation Accuracy: 97.25%\n",
      "Epoch 11  batch 1 . Training Loss:  0.236814484000206\n",
      "Epoch 11  batch 101 . Training Loss:  0.09122662991285324\n",
      "Epoch 11  batch 201 . Training Loss:  0.18173843622207642\n",
      "Epoch 11  batch 301 . Training Loss:  0.22519318759441376\n",
      "Epoch 11  batch 401 . Training Loss:  0.3123587667942047\n",
      "Epoch 11: Validation Loss: 0.0739, Validation Accuracy: 97.62%\n",
      "Epoch 12  batch 1 . Training Loss:  0.1137162521481514\n",
      "Epoch 12  batch 101 . Training Loss:  0.11212529242038727\n",
      "Epoch 12  batch 201 . Training Loss:  0.1513146460056305\n",
      "Epoch 12  batch 301 . Training Loss:  0.2142331451177597\n",
      "Epoch 12  batch 401 . Training Loss:  0.19531702995300293\n",
      "Epoch 12: Validation Loss: 0.0699, Validation Accuracy: 97.88%\n",
      "Epoch 13  batch 1 . Training Loss:  0.22379447519779205\n",
      "Epoch 13  batch 101 . Training Loss:  0.17838187515735626\n",
      "Epoch 13  batch 201 . Training Loss:  0.14223594963550568\n",
      "Epoch 13  batch 301 . Training Loss:  0.4042801856994629\n",
      "Epoch 13  batch 401 . Training Loss:  0.12145569920539856\n",
      "Epoch 13: Validation Loss: 0.0590, Validation Accuracy: 98.01%\n",
      "Epoch 14  batch 1 . Training Loss:  0.2132910192012787\n",
      "Epoch 14  batch 101 . Training Loss:  0.15257902443408966\n",
      "Epoch 14  batch 201 . Training Loss:  0.19105982780456543\n",
      "Epoch 14  batch 301 . Training Loss:  0.16089236736297607\n",
      "Epoch 14  batch 401 . Training Loss:  0.10597237944602966\n",
      "Epoch 14: Validation Loss: 0.0605, Validation Accuracy: 98.21%\n",
      "Epoch 15  batch 1 . Training Loss:  0.11342140287160873\n",
      "Epoch 15  batch 101 . Training Loss:  0.17036910355091095\n",
      "Epoch 15  batch 201 . Training Loss:  0.13905417919158936\n",
      "Epoch 15  batch 301 . Training Loss:  0.16995052993297577\n",
      "Epoch 15  batch 401 . Training Loss:  0.13196086883544922\n",
      "Epoch 15: Validation Loss: 0.0641, Validation Accuracy: 97.84%\n",
      "Epoch 16  batch 1 . Training Loss:  0.17418994009494781\n",
      "Epoch 16  batch 101 . Training Loss:  0.11783049255609512\n",
      "Epoch 16  batch 201 . Training Loss:  0.2283453643321991\n",
      "Epoch 16  batch 301 . Training Loss:  0.05818449333310127\n",
      "Epoch 16  batch 401 . Training Loss:  0.13690952956676483\n",
      "Epoch 16: Validation Loss: 0.0673, Validation Accuracy: 97.93%\n",
      "Epoch 17  batch 1 . Training Loss:  0.11086854338645935\n",
      "Epoch 17  batch 101 . Training Loss:  0.1599770039319992\n",
      "Epoch 17  batch 201 . Training Loss:  0.14644019305706024\n",
      "Epoch 17  batch 301 . Training Loss:  0.18640626966953278\n",
      "Epoch 17  batch 401 . Training Loss:  0.07428416609764099\n",
      "Epoch 17: Validation Loss: 0.0560, Validation Accuracy: 98.32%\n",
      "Epoch 18  batch 1 . Training Loss:  0.059464868158102036\n",
      "Epoch 18  batch 101 . Training Loss:  0.06839319318532944\n",
      "Epoch 18  batch 201 . Training Loss:  0.08596130460500717\n",
      "Epoch 18  batch 301 . Training Loss:  0.19188225269317627\n",
      "Epoch 18  batch 401 . Training Loss:  0.22456848621368408\n",
      "Epoch 18: Validation Loss: 0.0409, Validation Accuracy: 98.78%\n",
      "Epoch 19  batch 1 . Training Loss:  0.08390334993600845\n",
      "Epoch 19  batch 101 . Training Loss:  0.25549212098121643\n",
      "Epoch 19  batch 201 . Training Loss:  0.07762092351913452\n",
      "Epoch 19  batch 301 . Training Loss:  0.030621472746133804\n",
      "Epoch 19  batch 401 . Training Loss:  0.028770092874765396\n",
      "Epoch 19: Validation Loss: 0.0465, Validation Accuracy: 98.61%\n",
      "Epoch 20  batch 1 . Training Loss:  0.2322929948568344\n",
      "Epoch 20  batch 101 . Training Loss:  0.06059540435671806\n",
      "Epoch 20  batch 201 . Training Loss:  0.058429475873708725\n",
      "Epoch 20  batch 301 . Training Loss:  0.07473070174455643\n",
      "Epoch 20  batch 401 . Training Loss:  0.10744068026542664\n",
      "Epoch 20: Validation Loss: 0.0342, Validation Accuracy: 98.89%\n",
      "Epoch 21  batch 1 . Training Loss:  0.10344704240560532\n",
      "Epoch 21  batch 101 . Training Loss:  0.04241245612502098\n",
      "Epoch 21  batch 201 . Training Loss:  0.09457378834486008\n",
      "Epoch 21  batch 301 . Training Loss:  0.20658092200756073\n",
      "Epoch 21  batch 401 . Training Loss:  0.09214413911104202\n",
      "Epoch 21: Validation Loss: 0.0373, Validation Accuracy: 98.99%\n",
      "Epoch 22  batch 1 . Training Loss:  0.11008656024932861\n",
      "Epoch 22  batch 101 . Training Loss:  0.06462739408016205\n",
      "Epoch 22  batch 201 . Training Loss:  0.11114273220300674\n",
      "Epoch 22  batch 301 . Training Loss:  0.030748702585697174\n",
      "Epoch 22  batch 401 . Training Loss:  0.048293180763721466\n",
      "Epoch 22: Validation Loss: 0.0391, Validation Accuracy: 98.79%\n",
      "Epoch 23  batch 1 . Training Loss:  0.09778373688459396\n",
      "Epoch 23  batch 101 . Training Loss:  0.07673856616020203\n",
      "Epoch 23  batch 201 . Training Loss:  0.060341157019138336\n",
      "Epoch 23  batch 301 . Training Loss:  0.2763488292694092\n",
      "Epoch 23  batch 401 . Training Loss:  0.08108534663915634\n",
      "Epoch 23: Validation Loss: 0.0360, Validation Accuracy: 98.99%\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "264e878c2785482d8682ae0d9f4d7c6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.004 MB of 0.004 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>█▆▄▄▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▅▅▄▄▃▃▃▂▂▁▂▂▂▁▂▁▁▂▂▁▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▃▅▇▇▇█████████████████</td></tr><tr><td>val_loss</td><td>█▆▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.08109</td></tr><tr><td>train_loss</td><td>0.00345</td></tr><tr><td>val_accuracy</td><td>98.99248</td></tr><tr><td>val_loss</td><td>0.03599</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">experiment_v1</strong> at: <a href='https://wandb.ai/evafan123/Project%20CNN_v1/runs/ezmhd20p' target=\"_blank\">https://wandb.ai/evafan123/Project%20CNN_v1/runs/ezmhd20p</a><br/> View project at: <a href='https://wandb.ai/evafan123/Project%20CNN_v1' target=\"_blank\">https://wandb.ai/evafan123/Project%20CNN_v1</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240417_135058-ezmhd20p/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 100\n",
    "model = net\n",
    "for epoch in range(epochs):\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    for i,(images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i %100 == 0:\n",
    "          print(\"Epoch\", epoch+ 1, \" batch\", i+1, \". Training Loss: \", loss.item())\n",
    "          if enable_wandb:\n",
    "            wandb.log({\"loss\": loss})\n",
    "        wandb.log({\"train_loss\":loss.item()})\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    validation_loss = get_loss(val_loader, model, criterion, device)\n",
    "    validation_accuracy = get_accuracy(val_loader, model, device)\n",
    "    wandb.log({\"val_loss\": validation_loss, \"val_accuracy\": validation_accuracy})\n",
    "\n",
    "    print(f'Epoch {epoch+1}: Validation Loss: {validation_loss:.4f}, Validation Accuracy: {validation_accuracy:.2f}%')\n",
    "\n",
    "    if early_stopping.early_stop(validation_loss, model):\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CYQmq5FORqbI"
   },
   "source": [
    "------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "21rOVvnYRqV5"
   },
   "source": [
    "### CNN Model - 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Decreasing `epochs` from 100 to 25\n",
    "- Increasing `batch_size` from 64 to 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "mfTZpdJvRqTC"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c2b50b1fd1e4095aa5ec55a6ba46a59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112740722536627, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/projectnb/ba865/students/evafan/wandb/run-20240417_143325-w1j731qx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/evafan123/Project%20CNN_v1/runs/w1j731qx' target=\"_blank\">experiment_v2</a></strong> to <a href='https://wandb.ai/evafan123/Project%20CNN_v1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/evafan123/Project%20CNN_v1' target=\"_blank\">https://wandb.ai/evafan123/Project%20CNN_v1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/evafan123/Project%20CNN_v1/runs/w1j731qx' target=\"_blank\">https://wandb.ai/evafan123/Project%20CNN_v1/runs/w1j731qx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/evafan123/Project%20CNN_v1/runs/w1j731qx?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x150cbc34cee0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"Project CNN_v1\", name = 'experiment_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "uIMFwutlRqPs"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.config.update({\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"epochs\": 25,\n",
    "    \"batch_size\": 128\n",
    "})\n",
    "wandb.watch(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=128, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_data, batch_size=128, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(dataset_test, shuffle=True, batch_size = 128, num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout2d(p=0.2, inplace=False)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Dropout2d(p=0.3, inplace=False)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): Dropout2d(p=0.4, inplace=False)\n",
       "    (14): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (16): ReLU(inplace=True)\n",
       "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (21): Dropout2d(p=0.5, inplace=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=1024, out_features=1000, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=1000, out_features=256, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=256, out_features=43, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net1 = Net(num_classes=43)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net1.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net1.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "early_stopping = EarlyStopper(patience=5,delta = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "nZ3pCZQ7RqM9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1  batch 1 . Training Loss:  3.854710817337036\n",
      "Epoch 1  batch 101 . Training Loss:  2.9450109004974365\n",
      "Epoch 1  batch 201 . Training Loss:  2.075486183166504\n",
      "Epoch 1: Validation Loss: 1.8634, Validation Accuracy: 37.39%\n",
      "Epoch 2  batch 1 . Training Loss:  2.2888221740722656\n",
      "Epoch 2  batch 101 . Training Loss:  1.9419071674346924\n",
      "Epoch 2  batch 201 . Training Loss:  1.423435926437378\n",
      "Epoch 2: Validation Loss: 1.1884, Validation Accuracy: 57.85%\n",
      "Epoch 3  batch 1 . Training Loss:  1.5208704471588135\n",
      "Epoch 3  batch 101 . Training Loss:  1.1274008750915527\n",
      "Epoch 3  batch 201 . Training Loss:  0.9119271039962769\n",
      "Epoch 3: Validation Loss: 0.6026, Validation Accuracy: 78.66%\n",
      "Epoch 4  batch 1 . Training Loss:  1.120024561882019\n",
      "Epoch 4  batch 101 . Training Loss:  0.7450882196426392\n",
      "Epoch 4  batch 201 . Training Loss:  0.6549537777900696\n",
      "Epoch 4: Validation Loss: 0.3837, Validation Accuracy: 87.20%\n",
      "Epoch 5  batch 1 . Training Loss:  0.695164680480957\n",
      "Epoch 5  batch 101 . Training Loss:  0.5403280854225159\n",
      "Epoch 5  batch 201 . Training Loss:  0.5035582184791565\n",
      "Epoch 5: Validation Loss: 0.2520, Validation Accuracy: 91.61%\n",
      "Epoch 6  batch 1 . Training Loss:  0.39829206466674805\n",
      "Epoch 6  batch 101 . Training Loss:  0.3111746311187744\n",
      "Epoch 6  batch 201 . Training Loss:  0.3663254380226135\n",
      "Epoch 6: Validation Loss: 0.1758, Validation Accuracy: 94.44%\n",
      "Epoch 7  batch 1 . Training Loss:  0.39829909801483154\n",
      "Epoch 7  batch 101 . Training Loss:  0.35948920249938965\n",
      "Epoch 7  batch 201 . Training Loss:  0.3726517856121063\n",
      "Epoch 7: Validation Loss: 0.1272, Validation Accuracy: 95.93%\n",
      "Epoch 8  batch 1 . Training Loss:  0.21722356975078583\n",
      "Epoch 8  batch 101 . Training Loss:  0.21453669667243958\n",
      "Epoch 8  batch 201 . Training Loss:  0.2269514799118042\n",
      "Epoch 8: Validation Loss: 0.1275, Validation Accuracy: 95.88%\n",
      "Epoch 9  batch 1 . Training Loss:  0.3118630051612854\n",
      "Epoch 9  batch 101 . Training Loss:  0.19931529462337494\n",
      "Epoch 9  batch 201 . Training Loss:  0.15285523235797882\n",
      "Epoch 9: Validation Loss: 0.1199, Validation Accuracy: 95.69%\n",
      "Epoch 10  batch 1 . Training Loss:  0.2398720681667328\n",
      "Epoch 10  batch 101 . Training Loss:  0.16679804027080536\n",
      "Epoch 10  batch 201 . Training Loss:  0.1036018580198288\n",
      "Epoch 10: Validation Loss: 0.0992, Validation Accuracy: 96.81%\n",
      "Epoch 11  batch 1 . Training Loss:  0.11022711545228958\n",
      "Epoch 11  batch 101 . Training Loss:  0.2528921067714691\n",
      "Epoch 11  batch 201 . Training Loss:  0.18484868109226227\n",
      "Epoch 11: Validation Loss: 0.0785, Validation Accuracy: 97.40%\n",
      "Epoch 12  batch 1 . Training Loss:  0.09162359684705734\n",
      "Epoch 12  batch 101 . Training Loss:  0.1508580595254898\n",
      "Epoch 12  batch 201 . Training Loss:  0.12543313205242157\n",
      "Epoch 12: Validation Loss: 0.0779, Validation Accuracy: 97.56%\n",
      "Epoch 13  batch 1 . Training Loss:  0.3044300079345703\n",
      "Epoch 13  batch 101 . Training Loss:  0.17734867334365845\n",
      "Epoch 13  batch 201 . Training Loss:  0.1696525663137436\n",
      "Epoch 13: Validation Loss: 0.0630, Validation Accuracy: 98.09%\n",
      "Epoch 14  batch 1 . Training Loss:  0.08278990536928177\n",
      "Epoch 14  batch 101 . Training Loss:  0.16736362874507904\n",
      "Epoch 14  batch 201 . Training Loss:  0.15163137018680573\n",
      "Epoch 14: Validation Loss: 0.0592, Validation Accuracy: 98.19%\n",
      "Epoch 15  batch 1 . Training Loss:  0.2204219549894333\n",
      "Epoch 15  batch 101 . Training Loss:  0.1881529837846756\n",
      "Epoch 15  batch 201 . Training Loss:  0.18359899520874023\n",
      "Epoch 15: Validation Loss: 0.0565, Validation Accuracy: 98.27%\n",
      "Epoch 16  batch 1 . Training Loss:  0.10340706259012222\n",
      "Epoch 16  batch 101 . Training Loss:  0.1278529018163681\n",
      "Epoch 16  batch 201 . Training Loss:  0.2182907909154892\n",
      "Epoch 16: Validation Loss: 0.0513, Validation Accuracy: 98.57%\n",
      "Epoch 17  batch 1 . Training Loss:  0.11825232952833176\n",
      "Epoch 17  batch 101 . Training Loss:  0.1140456572175026\n",
      "Epoch 17  batch 201 . Training Loss:  0.14956115186214447\n",
      "Epoch 17: Validation Loss: 0.0421, Validation Accuracy: 98.67%\n",
      "Epoch 18  batch 1 . Training Loss:  0.10402627289295197\n",
      "Epoch 18  batch 101 . Training Loss:  0.15357759594917297\n",
      "Epoch 18  batch 201 . Training Loss:  0.11694458872079849\n",
      "Epoch 18: Validation Loss: 0.0469, Validation Accuracy: 98.48%\n",
      "Epoch 19  batch 1 . Training Loss:  0.08959630131721497\n",
      "Epoch 19  batch 101 . Training Loss:  0.15861979126930237\n",
      "Epoch 19  batch 201 . Training Loss:  0.06282872706651688\n",
      "Epoch 19: Validation Loss: 0.0379, Validation Accuracy: 98.98%\n",
      "Epoch 20  batch 1 . Training Loss:  0.04823574423789978\n",
      "Epoch 20  batch 101 . Training Loss:  0.10689842700958252\n",
      "Epoch 20  batch 201 . Training Loss:  0.11903122067451477\n",
      "Epoch 20: Validation Loss: 0.0433, Validation Accuracy: 98.65%\n",
      "Epoch 21  batch 1 . Training Loss:  0.07161493599414825\n",
      "Epoch 21  batch 101 . Training Loss:  0.1330019235610962\n",
      "Epoch 21  batch 201 . Training Loss:  0.22916877269744873\n",
      "Epoch 21: Validation Loss: 0.0367, Validation Accuracy: 98.94%\n",
      "Epoch 22  batch 1 . Training Loss:  0.09565196931362152\n",
      "Epoch 22  batch 101 . Training Loss:  0.09482132643461227\n",
      "Epoch 22  batch 201 . Training Loss:  0.05205780267715454\n",
      "Epoch 22: Validation Loss: 0.0378, Validation Accuracy: 98.72%\n",
      "Epoch 23  batch 1 . Training Loss:  0.06125681474804878\n",
      "Epoch 23  batch 101 . Training Loss:  0.046858109533786774\n",
      "Epoch 23  batch 201 . Training Loss:  0.08512814342975616\n",
      "Epoch 23: Validation Loss: 0.0353, Validation Accuracy: 99.12%\n",
      "Epoch 24  batch 1 . Training Loss:  0.08163134008646011\n",
      "Epoch 24  batch 101 . Training Loss:  0.10088887810707092\n",
      "Epoch 24  batch 201 . Training Loss:  0.045532889664173126\n",
      "Epoch 24: Validation Loss: 0.0359, Validation Accuracy: 99.07%\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad995eac958547e88dfc2fad197b3591",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.004 MB of 0.004 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>█▆▅▄▃▃▂▂▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▅▄▄▃▃▂▂▂▂▁▂▂▂▂▂▁▁▁▁▂▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▃▆▇▇▇██████████████████</td></tr><tr><td>val_loss</td><td>█▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.04553</td></tr><tr><td>train_loss</td><td>0.00129</td></tr><tr><td>val_accuracy</td><td>99.069</td></tr><tr><td>val_loss</td><td>0.03595</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">experiment_v2</strong> at: <a href='https://wandb.ai/evafan123/Project%20CNN_v1/runs/w1j731qx' target=\"_blank\">https://wandb.ai/evafan123/Project%20CNN_v1/runs/w1j731qx</a><br/> View project at: <a href='https://wandb.ai/evafan123/Project%20CNN_v1' target=\"_blank\">https://wandb.ai/evafan123/Project%20CNN_v1</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240417_143325-w1j731qx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 25\n",
    "model = net1\n",
    "for epoch in range(epochs):\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    for i,(images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i %100 == 0:\n",
    "          print(\"Epoch\", epoch+ 1, \" batch\", i+1, \". Training Loss: \", loss.item())\n",
    "          if enable_wandb:\n",
    "            wandb.log({\"loss\": loss})\n",
    "        wandb.log({\"train_loss\":loss.item()})\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    validation_loss = get_loss(val_loader, model, criterion, device)\n",
    "    validation_accuracy = get_accuracy(val_loader, model, device)\n",
    "    wandb.log({\"val_loss\": validation_loss, \"val_accuracy\": validation_accuracy})\n",
    "\n",
    "    print(f'Epoch {epoch+1}: Validation Loss: {validation_loss:.4f}, Validation Accuracy: {validation_accuracy:.2f}%')\n",
    "\n",
    "    if early_stopping.early_stop(validation_loss, model):\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yHBREy3FRqJx"
   },
   "source": [
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model - 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Balance the training data\n",
    "- Still using `batch_size` of 64 since it gives higher accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/projectnb/ba865/students/evafan/wandb/run-20240417_152458-wlftyppk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/evafan123/Project%20CNN_v1/runs/wlftyppk' target=\"_blank\">experiment_v3</a></strong> to <a href='https://wandb.ai/evafan123/Project%20CNN_v1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/evafan123/Project%20CNN_v1' target=\"_blank\">https://wandb.ai/evafan123/Project%20CNN_v1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/evafan123/Project%20CNN_v1/runs/wlftyppk' target=\"_blank\">https://wandb.ai/evafan123/Project%20CNN_v1/runs/wlftyppk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/evafan123/Project%20CNN_v1/runs/wlftyppk?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x150c25b04f70>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"Project CNN_v1\", name = 'experiment_v3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.config.update({\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"epochs\": 25,\n",
    "    \"batch_size\": 64\n",
    "})\n",
    "wandb.watch(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_data, batch_size=64, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(dataset_test, shuffle=True, batch_size = 64, num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout2d(p=0.2, inplace=False)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Dropout2d(p=0.3, inplace=False)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): Dropout2d(p=0.4, inplace=False)\n",
       "    (14): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (16): ReLU(inplace=True)\n",
       "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (21): Dropout2d(p=0.5, inplace=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=1024, out_features=1000, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=1000, out_features=256, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=256, out_features=43, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2 = Net(num_classes=43)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [total_train/sorted_train[str(i).zfill(2)] if str(i).zfill(2) in sorted_train else 1 for i in range(43)]\n",
    "class_weights = torch.FloatTensor(weights).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net2.parameters(), lr=0.001)\n",
    "early_stopping = EarlyStopper(patience=5,delta = 0.01)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1  batch 1 . Training Loss:  0.05538102611899376\n",
      "Epoch 1  batch 101 . Training Loss:  0.15883882343769073\n",
      "Epoch 1  batch 201 . Training Loss:  0.011291002854704857\n",
      "Epoch 1  batch 301 . Training Loss:  0.14571800827980042\n",
      "Epoch 1  batch 401 . Training Loss:  0.09036130458116531\n",
      "Epoch 1: Validation Loss: 0.0486, Validation Accuracy: 99.17%\n",
      "Epoch 2  batch 1 . Training Loss:  0.08589104562997818\n",
      "Epoch 2  batch 101 . Training Loss:  0.044697053730487823\n",
      "Epoch 2  batch 201 . Training Loss:  0.09368452429771423\n",
      "Epoch 2  batch 301 . Training Loss:  0.02099890261888504\n",
      "Epoch 2  batch 401 . Training Loss:  0.01709175668656826\n",
      "Epoch 2: Validation Loss: 0.0508, Validation Accuracy: 99.11%\n",
      "Epoch 3  batch 1 . Training Loss:  0.042652010917663574\n",
      "Epoch 3  batch 101 . Training Loss:  0.05108672007918358\n",
      "Epoch 3  batch 201 . Training Loss:  0.0346488282084465\n",
      "Epoch 3  batch 301 . Training Loss:  0.40025195479393005\n",
      "Epoch 3  batch 401 . Training Loss:  0.19807152450084686\n",
      "Epoch 3: Validation Loss: 0.0479, Validation Accuracy: 99.18%\n",
      "Epoch 4  batch 1 . Training Loss:  0.09982520341873169\n",
      "Epoch 4  batch 101 . Training Loss:  0.18970946967601776\n",
      "Epoch 4  batch 201 . Training Loss:  0.017398793250322342\n",
      "Epoch 4  batch 301 . Training Loss:  0.24551604688167572\n",
      "Epoch 4  batch 401 . Training Loss:  0.04971960932016373\n",
      "Epoch 4: Validation Loss: 0.0482, Validation Accuracy: 99.16%\n",
      "Epoch 5  batch 1 . Training Loss:  0.042018499225378036\n",
      "Epoch 5  batch 101 . Training Loss:  0.09299270808696747\n",
      "Epoch 5  batch 201 . Training Loss:  0.10502493381500244\n",
      "Epoch 5  batch 301 . Training Loss:  0.09126336872577667\n",
      "Epoch 5  batch 401 . Training Loss:  0.05925652012228966\n",
      "Epoch 5: Validation Loss: 0.0509, Validation Accuracy: 99.15%\n",
      "Epoch 6  batch 1 . Training Loss:  0.10589656233787537\n",
      "Epoch 6  batch 101 . Training Loss:  0.02740960568189621\n",
      "Epoch 6  batch 201 . Training Loss:  0.04379791021347046\n",
      "Epoch 6  batch 301 . Training Loss:  0.04169711470603943\n",
      "Epoch 6  batch 401 . Training Loss:  0.07442479580640793\n",
      "Epoch 6: Validation Loss: 0.0492, Validation Accuracy: 99.15%\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a801325243834347b0eed6378053f9c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.020 MB of 0.020 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>▂▄▁▃▂▂▂▂▁▁▂▂▁█▄▃▄▁▅▂▂▂▃▂▂▃▁▂▂▂</td></tr><tr><td>train_loss</td><td>▁▃▃▁██▄▃▂▂▂▁▁▃▂▄▂▂▆▂▁▁▂▂▂▂▁▄▃▃▃▁▂▁▃▁▃▁▁▅</td></tr><tr><td>val_accuracy</td><td>▇▁█▆▅▅</td></tr><tr><td>val_loss</td><td>▃█▁▂█▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.07442</td></tr><tr><td>train_loss</td><td>6e-05</td></tr><tr><td>val_accuracy</td><td>99.14552</td></tr><tr><td>val_loss</td><td>0.04917</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">experiment_v3</strong> at: <a href='https://wandb.ai/evafan123/Project%20CNN_v1/runs/wlftyppk' target=\"_blank\">https://wandb.ai/evafan123/Project%20CNN_v1/runs/wlftyppk</a><br/> View project at: <a href='https://wandb.ai/evafan123/Project%20CNN_v1' target=\"_blank\">https://wandb.ai/evafan123/Project%20CNN_v1</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240417_152458-wlftyppk/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 25\n",
    "model = net1\n",
    "for epoch in range(epochs):\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    for i,(images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i %100 == 0:\n",
    "          print(\"Epoch\", epoch+ 1, \" batch\", i+1, \". Training Loss: \", loss.item())\n",
    "          if enable_wandb:\n",
    "            wandb.log({\"loss\": loss})\n",
    "        wandb.log({\"train_loss\":loss.item()})\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    validation_loss = get_loss(val_loader, model, criterion, device)\n",
    "    validation_accuracy = get_accuracy(val_loader, model, device)\n",
    "    wandb.log({\"val_loss\": validation_loss, \"val_accuracy\": validation_accuracy})\n",
    "\n",
    "    print(f'Epoch {epoch+1}: Validation Loss: {validation_loss:.4f}, Validation Accuracy: {validation_accuracy:.2f}%')\n",
    "\n",
    "    if early_stopping.early_stop(validation_loss, model):\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "t1_mRxBrBq98"
   ],
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
