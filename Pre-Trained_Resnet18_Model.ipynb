{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b000e13",
   "metadata": {},
   "source": [
    "# Deep Learning for Deciphering Traffic Signs\n",
    "## Pre-trained Model Notebook\n",
    "_________________________________________________________________________________________________________________________________________________________________________________\n",
    "\n",
    "##### Contributors:\n",
    " Victor Floriano, Yifan Fan, Jose Salerno"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4347f5",
   "metadata": {},
   "source": [
    "## Problem Statement & Motivation\n",
    "As the world advances towards autonomous vehicles, our team has observed the remarkable efforts of large car manufacturers, who are working with data scientists to develop fully autonomous cars. Our team is excited to contribute to the development of this technology by creating a neural network model that will be able to classify different traffic signs. Our ultimate goal is to assist car makers in overcoming the challenges they may face in implementing neural network models that effectively read traffic signs and further their efforts toward a fully autonomous car or assisted driving. We believe autonomous driving to be an important problem to solve due to the great economic benefits it can generate for car manufacturers and the improvement of general driving safety.\n",
    "\n",
    "## Data Preparation\n",
    " We've selected the German Traffic Sign Recognition Benchmark (GTSRB) as our primary dataset. It's renowned for its complexity, featuring over 50,000 images across more than 40 classes of traffic signs. The GTSRB is publicly accessible through two resources. To efficiently manage the extensive and complex GTSRB dataset, our strategy integrates preprocessing for uniformity, data augmentation for robustness, and batch processing for computational efficiency. We'll employ distributed computing to parallelize operations, enhancing processing speed, and use stratified sampling for quick experimentation without compromising representativeness.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442da7e0",
   "metadata": {},
   "source": [
    "# Pre-Trained Models\n",
    "- We implemented the pre-trained model Resnet18, the reason why we choose Resnet18 was because of its strong performance in image classification. ResNet-18 originally uses an input size of 256x256 pixels, but it can automatically resize images to meet its input requirements. This allowed us to benefit from the models features on large dataset, enabling us to implement transfer learning in our particular task of classifying traffic signs. Finally, we adjusted the output layer to fit our number of classes when it came to classfication. \n",
    "\n",
    " \n",
    "________________________________________________________________________________________________________________________________________________\n",
    "\n",
    "Results: \n",
    "\n",
    "- Validation Accuracy = 99.66%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "944e8f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd030daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enable_wandb = True\n",
    "use_gpu = True\n",
    "gpu_available = torch.cuda.is_available()\n",
    "gpu_available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7950d439",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading images - from Datacamp CNN course (cloud example)\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((56,56))\n",
    "])\n",
    "\n",
    "dataset_train = ImageFolder(\n",
    "    'Train',\n",
    "    transform = train_transforms\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85c2e77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = random_split(dataset_train, [0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc774911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 56, 56])\n",
      "Label: tensor([13])\n",
      "tensor([13])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#Trying to display images\n",
    "dataloader_train = DataLoader(\n",
    "    dataset_train,\n",
    "    shuffle=True,\n",
    "    batch_size=1,\n",
    ")\n",
    "\n",
    "image, label = next(iter(dataloader_train))\n",
    "print(image.shape)\n",
    "print('Label:',label)\n",
    "print(label)\n",
    "\n",
    "image = image.squeeze().permute(1,2,0)\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7c3993a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights:\n",
      "Class 0: 93.3786\n",
      "Class 1: 8.8331\n",
      "Class 10: 9.7560\n",
      "Class 11: 14.8557\n",
      "Class 12: 9.3379\n",
      "Class 13: 9.0785\n",
      "Class 14: 25.1404\n",
      "Class 15: 31.1262\n",
      "Class 16: 46.6893\n",
      "Class 17: 17.6662\n",
      "Class 18: 16.3412\n",
      "Class 19: 93.3786\n",
      "Class 2: 8.7153\n",
      "Class 20: 54.4708\n",
      "Class 21: 59.4227\n",
      "Class 22: 50.2808\n",
      "Class 23: 38.4500\n",
      "Class 24: 72.6278\n",
      "Class 25: 13.0730\n",
      "Class 26: 32.6825\n",
      "Class 27: 81.7062\n",
      "Class 28: 36.3139\n",
      "Class 29: 72.6278\n",
      "Class 3: 13.9074\n",
      "Class 30: 43.5767\n",
      "Class 31: 25.1404\n",
      "Class 32: 81.7062\n",
      "Class 33: 28.4608\n",
      "Class 34: 46.6893\n",
      "Class 35: 16.3412\n",
      "Class 36: 50.2808\n",
      "Class 37: 93.3786\n",
      "Class 38: 9.4732\n",
      "Class 39: 65.3650\n",
      "Class 4: 9.9038\n",
      "Class 40: 54.4708\n",
      "Class 41: 81.7062\n",
      "Class 42: 81.7062\n",
      "Class 5: 10.5427\n",
      "Class 6: 46.6893\n",
      "Class 7: 13.6177\n",
      "Class 8: 13.9074\n",
      "Class 9: 13.3398\n"
     ]
    }
   ],
   "source": [
    "num_samples = 39219\n",
    "num_images_per_class = {\n",
    "    0: 210, 1: 2220, 10: 2010, 11: 1320, 12: 2100, 13: 2160, 14: 780, 15: 630,\n",
    "    16: 420, 17: 1110, 18: 1200, 19: 210, 2: 2250, 20: 360, 21: 330, 22: 390,\n",
    "    23: 510, 24: 270, 25: 1500, 26: 600, 27: 240, 28: 540, 29: 270, 3: 1410,\n",
    "    30: 450, 31: 780, 32: 240, 33: 689, 34: 420, 35: 1200, 36: 390, 37: 210,\n",
    "    38: 2070, 39: 300, 4: 1980, 40: 360, 41: 240, 42: 240, 5: 1860, 6: 420,\n",
    "    7: 1440, 8: 1410, 9: 1470\n",
    "}\n",
    "\n",
    "class_weights = {}\n",
    "for class_id, num_images in num_images_per_class.items():\n",
    "    weight_for_class = num_samples / (num_images * 2)\n",
    "    class_weights[class_id] = weight_for_class\n",
    "\n",
    "print(\"Class Weights:\")\n",
    "for class_id, weight in class_weights.items():\n",
    "    print(f\"Class {class_id}: {weight:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53d48c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = torch.tensor([\n",
    "    93.3786, 8.8331, 9.7560, 14.8557, 9.3379, 9.0785, 25.1404, 31.1262, 46.6893, 17.6662,\n",
    "    16.3412, 93.3786, 8.7153, 54.4708, 59.4227, 50.2808, 38.4500, 72.6278, 13.0730, 32.6825,\n",
    "    81.7062, 36.3139, 72.6278, 13.9074, 43.5767, 25.1404, 81.7062, 28.4608, 46.6893, 16.3412,\n",
    "    50.2808, 93.3786, 9.4732, 65.3650, 9.9038, 54.4708, 81.7062, 81.7062, 10.5427, 46.6893,\n",
    "    13.6177, 13.9074, 13.3398\n",
    "])\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(weight= class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "188687d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "configs = {\n",
    "    \"experiment_name\": \"Pre-trained Model\",\n",
    "    \"data_augmentation\":True,\n",
    "\n",
    "    # Data\n",
    "    \"img_dimensions\" : (3,56,56),\n",
    "    \"batch_size\" : 350,\n",
    "    \"num_classes\" : 43,\n",
    "\n",
    "    # CNN\n",
    "    \"filter_sizes\" : [4, 16, 32, 64],\n",
    "    \"kernel_size\" : 5,\n",
    "    \"stride\": 2,\n",
    "    \"padding\":2,\n",
    "\n",
    "    #Optimzation\n",
    "    \"learning_rate\" : 0.0001,\n",
    "    \"epochs\" : 25,\n",
    "    \"weight_decay\" : 0.00001,\n",
    "    \"epochs\" : 35\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74cb33fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_dataset, batch_size = configs['batch_size'], shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size = configs['batch_size'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7ab5686",
   "metadata": {},
   "outputs": [],
   "source": [
    "if configs[\"data_augmentation\"]:\n",
    "  transform = transforms.Compose([\n",
    "      transforms.RandomHorizontalFlip(0.5),\n",
    "      transforms.Resize(56),\n",
    "      transforms.RandomRotation(45),\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "else:\n",
    "  transform = transforms.Compose([\n",
    "      transforms.Resize(56),\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf293e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4cb1e780",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "422acdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "\n",
    "# Load the pre-trained ResNet-18 model with specified weights\n",
    "weights = ResNet18_Weights.IMAGENET1K_V1  # This is equivalent to the previously used pretrained=True\n",
    "model = resnet18(weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e809a0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24cdccd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "ResNet                                   --\n",
       "├─Conv2d: 1-1                            9,408\n",
       "├─BatchNorm2d: 1-2                       128\n",
       "├─ReLU: 1-3                              --\n",
       "├─MaxPool2d: 1-4                         --\n",
       "├─Sequential: 1-5                        --\n",
       "│    └─BasicBlock: 2-1                   --\n",
       "│    │    └─Conv2d: 3-1                  36,864\n",
       "│    │    └─BatchNorm2d: 3-2             128\n",
       "│    │    └─ReLU: 3-3                    --\n",
       "│    │    └─Conv2d: 3-4                  36,864\n",
       "│    │    └─BatchNorm2d: 3-5             128\n",
       "│    └─BasicBlock: 2-2                   --\n",
       "│    │    └─Conv2d: 3-6                  36,864\n",
       "│    │    └─BatchNorm2d: 3-7             128\n",
       "│    │    └─ReLU: 3-8                    --\n",
       "│    │    └─Conv2d: 3-9                  36,864\n",
       "│    │    └─BatchNorm2d: 3-10            128\n",
       "├─Sequential: 1-6                        --\n",
       "│    └─BasicBlock: 2-3                   --\n",
       "│    │    └─Conv2d: 3-11                 73,728\n",
       "│    │    └─BatchNorm2d: 3-12            256\n",
       "│    │    └─ReLU: 3-13                   --\n",
       "│    │    └─Conv2d: 3-14                 147,456\n",
       "│    │    └─BatchNorm2d: 3-15            256\n",
       "│    │    └─Sequential: 3-16             8,448\n",
       "│    └─BasicBlock: 2-4                   --\n",
       "│    │    └─Conv2d: 3-17                 147,456\n",
       "│    │    └─BatchNorm2d: 3-18            256\n",
       "│    │    └─ReLU: 3-19                   --\n",
       "│    │    └─Conv2d: 3-20                 147,456\n",
       "│    │    └─BatchNorm2d: 3-21            256\n",
       "├─Sequential: 1-7                        --\n",
       "│    └─BasicBlock: 2-5                   --\n",
       "│    │    └─Conv2d: 3-22                 294,912\n",
       "│    │    └─BatchNorm2d: 3-23            512\n",
       "│    │    └─ReLU: 3-24                   --\n",
       "│    │    └─Conv2d: 3-25                 589,824\n",
       "│    │    └─BatchNorm2d: 3-26            512\n",
       "│    │    └─Sequential: 3-27             33,280\n",
       "│    └─BasicBlock: 2-6                   --\n",
       "│    │    └─Conv2d: 3-28                 589,824\n",
       "│    │    └─BatchNorm2d: 3-29            512\n",
       "│    │    └─ReLU: 3-30                   --\n",
       "│    │    └─Conv2d: 3-31                 589,824\n",
       "│    │    └─BatchNorm2d: 3-32            512\n",
       "├─Sequential: 1-8                        --\n",
       "│    └─BasicBlock: 2-7                   --\n",
       "│    │    └─Conv2d: 3-33                 1,179,648\n",
       "│    │    └─BatchNorm2d: 3-34            1,024\n",
       "│    │    └─ReLU: 3-35                   --\n",
       "│    │    └─Conv2d: 3-36                 2,359,296\n",
       "│    │    └─BatchNorm2d: 3-37            1,024\n",
       "│    │    └─Sequential: 3-38             132,096\n",
       "│    └─BasicBlock: 2-8                   --\n",
       "│    │    └─Conv2d: 3-39                 2,359,296\n",
       "│    │    └─BatchNorm2d: 3-40            1,024\n",
       "│    │    └─ReLU: 3-41                   --\n",
       "│    │    └─Conv2d: 3-42                 2,359,296\n",
       "│    │    └─BatchNorm2d: 3-43            1,024\n",
       "├─AdaptiveAvgPool2d: 1-9                 --\n",
       "├─Linear: 1-10                           513,000\n",
       "=================================================================\n",
       "Total params: 11,689,512\n",
       "Trainable params: 11,689,512\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64958cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = configs['learning_rate'], weight_decay = configs['weight_decay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7566243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(dataloader, model):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    acc = torchmetrics.Accuracy(task=\"MULTICLASS\", num_classes=configs['num_classes']).to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            preds = torch.argmax(outputs, axis=1)\n",
    "            acc.update(preds, labels)\n",
    "\n",
    "    accuracy = acc.compute()\n",
    "    model.train()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "311ab0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(loader):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(loader):\n",
    "            if gpu_available and use_gpu:\n",
    "                images = images.cuda()\n",
    "                labels = labels.cuda()\n",
    "            outputs = model(images)\n",
    "            loss = loss + criterion(outputs, labels)\n",
    "    return loss / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19de227e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = float('inf')\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "            torch.save(model.state_dict(), \"./best_model.pt\")\n",
    "        elif validation_loss > self.min_validation_loss:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "early_stopper = EarlyStopper(patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2f2eb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels in training data: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42}\n"
     ]
    }
   ],
   "source": [
    "unique_labels = set()\n",
    "for _, labels in train_loader:\n",
    "    unique_labels.update(labels.numpy())\n",
    "print(\"Unique labels in training data:\", unique_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dfe2df4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 43)  # Ensure this matches the number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fbbc2786",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import Accuracy\n",
    "\n",
    "# Assuming device is defined as 'cuda' if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "accuracy_metric = Accuracy(num_classes=43, average='macro', task='multiclass').to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3f06a3d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 batch 1 . Training Loss:  0.060595255345106125\n",
      "Epoch [1/35], Train Accuracy: 0.9944\n",
      "Validation Accuracy: 0.9912\n",
      "Epoch 2 batch 1 . Training Loss:  0.01945233717560768\n",
      "Epoch [2/35], Train Accuracy: 0.9994\n",
      "Validation Accuracy: 0.9930\n",
      "Epoch 3 batch 1 . Training Loss:  0.01179986260831356\n",
      "Epoch [3/35], Train Accuracy: 0.9999\n",
      "Validation Accuracy: 0.9944\n",
      "Epoch 4 batch 1 . Training Loss:  0.006606792099773884\n",
      "Epoch [4/35], Train Accuracy: 0.9999\n",
      "Validation Accuracy: 0.9949\n",
      "Epoch 5 batch 1 . Training Loss:  0.005559645593166351\n",
      "Epoch [5/35], Train Accuracy: 0.9999\n",
      "Validation Accuracy: 0.9955\n",
      "Epoch 6 batch 1 . Training Loss:  0.004781764466315508\n",
      "Epoch [6/35], Train Accuracy: 1.0000\n",
      "Validation Accuracy: 0.9958\n",
      "Epoch 7 batch 1 . Training Loss:  0.003677635220810771\n",
      "Epoch [7/35], Train Accuracy: 1.0000\n",
      "Validation Accuracy: 0.9958\n",
      "Epoch 8 batch 1 . Training Loss:  0.002481186995282769\n",
      "Epoch [8/35], Train Accuracy: 1.0000\n",
      "Validation Accuracy: 0.9959\n",
      "Epoch 9 batch 1 . Training Loss:  0.0037411150988191366\n",
      "Epoch [9/35], Train Accuracy: 1.0000\n",
      "Validation Accuracy: 0.9960\n",
      "Epoch 10 batch 1 . Training Loss:  0.002446655184030533\n",
      "Epoch [10/35], Train Accuracy: 1.0000\n",
      "Validation Accuracy: 0.9955\n",
      "Epoch 11 batch 1 . Training Loss:  0.001604122924618423\n",
      "Epoch [11/35], Train Accuracy: 1.0000\n",
      "Validation Accuracy: 0.9962\n",
      "Epoch 12 batch 1 . Training Loss:  0.0014612269587814808\n",
      "Epoch [12/35], Train Accuracy: 1.0000\n",
      "Validation Accuracy: 0.9964\n",
      "Epoch 13 batch 1 . Training Loss:  0.0012992264237254858\n",
      "Epoch [13/35], Train Accuracy: 1.0000\n",
      "Validation Accuracy: 0.9963\n",
      "Epoch 14 batch 1 . Training Loss:  0.0013003773055970669\n",
      "Epoch [14/35], Train Accuracy: 1.0000\n",
      "Validation Accuracy: 0.9964\n",
      "Epoch 15 batch 1 . Training Loss:  0.0012921163579449058\n",
      "Epoch [15/35], Train Accuracy: 1.0000\n",
      "Validation Accuracy: 0.9960\n",
      "Epoch 16 batch 1 . Training Loss:  0.0009342683479189873\n",
      "Epoch [16/35], Train Accuracy: 1.0000\n",
      "Validation Accuracy: 0.9964\n",
      "Epoch 17 batch 1 . Training Loss:  0.0009390144841745496\n",
      "Epoch [17/35], Train Accuracy: 1.0000\n",
      "Validation Accuracy: 0.9966\n",
      "Epoch 18 batch 1 . Training Loss:  0.0009682222153060138\n",
      "Epoch [18/35], Train Accuracy: 1.0000\n",
      "Validation Accuracy: 0.9968\n",
      "Epoch 19 batch 1 . Training Loss:  0.0007424869108945131\n",
      "Epoch [19/35], Train Accuracy: 1.0000\n",
      "Validation Accuracy: 0.9967\n",
      "Epoch 20 batch 1 . Training Loss:  0.0007208964671008289\n",
      "Epoch [20/35], Train Accuracy: 1.0000\n",
      "Validation Accuracy: 0.9967\n",
      "Epoch 21 batch 1 . Training Loss:  0.0007396045839414\n",
      "Epoch [21/35], Train Accuracy: 1.0000\n",
      "Validation Accuracy: 0.9963\n",
      "Epoch 22 batch 1 . Training Loss:  0.0006499577430076897\n",
      "Epoch [22/35], Train Accuracy: 1.0000\n",
      "Validation Accuracy: 0.9966\n",
      "Epoch 23 batch 1 . Training Loss:  0.0004961623926647007\n",
      "Epoch [23/35], Train Accuracy: 1.0000\n",
      "Validation Accuracy: 0.9966\n",
      "Epoch 24 batch 1 . Training Loss:  0.0005411219317466021\n",
      "Epoch [24/35], Train Accuracy: 1.0000\n",
      "Validation Accuracy: 0.9966\n",
      "Epoch 25 batch 1 . Training Loss:  0.00043105491204187274\n",
      "Epoch [25/35], Train Accuracy: 1.0000\n",
      "Validation Accuracy: 0.9968\n",
      "Epoch 26 batch 1 . Training Loss:  0.00041648829937912524\n",
      "Epoch [26/35], Train Accuracy: 1.0000\n",
      "Validation Accuracy: 0.9969\n",
      "Epoch 27 batch 1 . Training Loss:  0.00046550692059099674\n",
      "Epoch [27/35], Train Accuracy: 1.0000\n",
      "Validation Accuracy: 0.9966\n",
      "Epoch 28 batch 1 . Training Loss:  0.00046523421769961715\n",
      "Epoch [28/35], Train Accuracy: 1.0000\n",
      "Validation Accuracy: 0.9969\n",
      "Epoch 29 batch 1 . Training Loss:  0.0004270709468983114\n",
      "Epoch [29/35], Train Accuracy: 1.0000\n",
      "Validation Accuracy: 0.9971\n",
      "Epoch 30 batch 1 . Training Loss:  0.000335817807354033\n",
      "Epoch [30/35], Train Accuracy: 1.0000\n",
      "Validation Accuracy: 0.9968\n",
      "Epoch 31 batch 1 . Training Loss:  0.00038302186294458807\n",
      "Epoch [31/35], Train Accuracy: 1.0000\n",
      "Validation Accuracy: 0.9969\n",
      "Epoch 32 batch 1 . Training Loss:  0.00032991531770676374\n",
      "Epoch [32/35], Train Accuracy: 1.0000\n",
      "Validation Accuracy: 0.9954\n",
      "Epoch 33 batch 1 . Training Loss:  0.00035585876321420074\n",
      "Epoch [33/35], Train Accuracy: 0.9959\n",
      "Validation Accuracy: 0.9898\n",
      "Epoch 34 batch 1 . Training Loss:  0.002432066947221756\n",
      "Epoch [34/35], Train Accuracy: 0.9990\n",
      "Validation Accuracy: 0.9960\n",
      "Epoch 35 batch 1 . Training Loss:  0.010140079073607922\n",
      "Epoch [35/35], Train Accuracy: 0.9996\n",
      "Validation Accuracy: 0.9966\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(configs['epochs']):\n",
    "    model.train()\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        if gpu_available and use_gpu:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            model = model.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Both preds and labels need to be on the same device\n",
    "        preds = preds.to(device)\n",
    "        labels = labels.to(device)  # Redundant if already on GPU, but ensures consistency\n",
    "\n",
    "        # Update metric\n",
    "        accuracy_metric.update(preds, labels)\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(\"Epoch\", epoch + 1, \"batch\", i + 1, \". Training Loss: \", loss.item())\n",
    "    train_acc = accuracy_metric.compute()\n",
    "    print(f'Epoch [{epoch + 1}/{configs[\"epochs\"]}], Train Accuracy: {train_acc.item():.4f}')\n",
    "    accuracy_metric.reset()\n",
    "    # Assuming get_accuracy and get_loss are updated to handle device transfers\n",
    "    val_acc = get_accuracy(val_loader, model)\n",
    "    validation_loss = get_loss(val_loader)\n",
    "\n",
    "    print(f'Validation Accuracy: {val_acc.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc2c8f9",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf50daa1",
   "metadata": {},
   "source": [
    "## Sources\n",
    "- Generative AI was utilized for Debugging, code improvement, sentence structure and grammar.\n",
    "- Transfer Learning Notebook "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
